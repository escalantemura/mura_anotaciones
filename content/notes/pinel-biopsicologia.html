<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>Biopsicologia</title>
  <meta content="John Pinel" name="author">
  <meta content="neurologia, medicina" name="keywords">
  <link href="../../css/style.css" rel="stylesheet">
  <link href="../../css/notes.css" rel="stylesheet">
</head>
<body>
<h1>Introducción</h1>
<h2>Definición</h2>
<p>La <strong>biopsicología</strong> es el estudio científico de la
  biología de la conducta (véase Dewsbury, 1991). Algunos denominan este
  campo psicobiología, biología comportamental o neurociencia
  comportamental; pero yo prefiero el término biopsicología, porque indica
  un enfoque biológico del estudio de la psicología más que un enfoque
  psicológico del estudio de la biología: la psicología se sitúa en primer
  plano en este texto.</p>
<p>La <strong>psicología</strong> es el estudio científico de la
  conducta, el estudio científico de todas las actividades manifiestas del
  organismo, así como de todos los procesos internos que supuestamente
  subyacen a estas actividades (p.ej., el aprendizaje, la memoria, la
  motivación, la percepción y la emoción).</p>
<p>Con el fin de describir la investigación psicobiológica, este
  apartado analiza tres dimensiones principales en las que varían los
  enfoques de la investigación biopsicológica.</p>
<ul>
  <li>Ésta puede implicar tanto sujetos humanos como no humanos,</li>
  <li>puede hacerse como experimentos formales</li>
  <li>o como estudios no experimentales,</li>
  <li>y puede ser básica o aplicada.</li>
</ul>
<p>La investigación básica está motivada básicamente por la curiosidad
  del investigador —se hace sólo con el propósito de adquirir
  conocimientos—. Por el contrario, la investigación aplicada es
  investigación encaminada a lograr algún beneficio directo para la
  humanidad.</p>
<h2>Ramas</h2>
<p>La biopsicología y su diversidad al describirle seis de sus
  principales ramas:</p>
<ol>
  <li>Psicología fisiológica.</li>
  <li>Psicofarmacología.</li>
  <li>Neuropsicología.</li>
  <li>Psicofisiología.</li>
  <li>Neurociencia cognitiva.</li>
  <li>Psicología comparada.</li>
</ol>
<p>Para simplificarlo, se presentan como aproximaciones distintas, pero
  se solapan en gran medida y muchos biopsicólogos siguen a menudo más de
  una aproximación.</p>
<figure class="tablap normal">
  <table>
    <thead>
    <tr>
      <th>Las seis especialidades de la biopsicología</th>
      <th>Ejemplos de cómo los seis enfoques han abordado el estudio de la memoria</th>
    </tr>
    </thead>
    <tbody>
    <tr>
      <td>
        <strong>Psicología Fisiológica</strong>: Estudio de los mecanismos neurales de la conducta mediante la
        intervención en la actividad del sistema nervioso de animales en experimentos controlados.
      </td>
      <td>
        Los psicólogos fisiológicos han estudiado cómo contribuye el hipocampo a la memoria extirpándolo quirúrgicamente
        en ratas y evaluando luego la capacidad de éstas para realizar diversas tareas de memoria.
      </td>
    </tr>
    <tr>
      <td>
        <strong>Psicofarmacología</strong>: estudio de los efectos de los fármacos sobre el cerebro y la conducta.
      </td>
      <td>
        Los psicofarmacólogos han tratado de mejorar la memoria de pacientes con enfermedad de Alzheimer
        administrándoles fármacos que aumentan los niveles del neurotransmisor acetilcolina.
      </td>
    </tr>
    <tr>
      <td>
        <strong>Neuropsicología</strong>: estudio de los efectos psicológicos del daño cerebral en pacientes humanos.
      </td>
      <td>
        Los neuropsicólogos han demostrado que los pacientes con daño cerebral producido por el alcohol tienen una
        marcada dificultad para recordar los sucesos recientes.
      </td>
    </tr>
    <tr>
      <td>
        <strong>Psicofisiología</strong>: estudio de la relación entre la actividad fisiológica y los procesos
        psicológicos en sujetos humanos mediante registros fisiológicos no lesivos.
      </td>
      <td>
        Los psicofisiólogos han demostrado que ver una cara conocida provoca los cambios habituales en la actividad del
        sistema nervioso neurovegetativo incluso en pacientes con daño cerebral que dicen no reconocer una cara.
      </td>
    </tr>
    <tr>
      <td>
        <strong>Neurociencia cognitiva</strong>: estudio de los mecanismos neurales de la cognición humana, empleando
        principalmente técnicas de neuroimagen funcional.
      </td>
      <td>
        Los neurocientíficos cognitivos han utilizado tecnología de neuroimagen para observar los cambios que ocurren en
        diversas regiones del encéfalo mientras que voluntarios humanos realizan tareas de memoria.
      </td>
    </tr>
    <tr>
      <td>
        <strong>Psicología comparada</strong>: estudio de la evolución, genética y capacidad de adaptación de la
        conducta, valiéndose principalmente del método comparativo.
      </td>
      <td>
        Los psicólogos comparativos han demostrado que las especies de aves que esconden sus semillas suelen tener el
        hipocampo muy desarrollado, lo que confirma que éste está implicado en la memoria de lugar.
      </td>
    </tr>
    </tbody>
  </table>
</figure>
<h2>Dicotomía heredado u
  aprendido</h2>
<p>Tendemos a no prestar atención a las sutilezas, incoherencias y
  complejidades de nuestra existencia, y a pensar en términos de simples
  dicotomías, mutuamente excluyentes: verdadero-falso, bueno-malo,
  atractivo-poco atractivo, etc. Lo que atrae de esta forma de pensar es
  su simplicidad.</p>
<p>Hay dos tipos de preguntas que se suelen hacer sobre la conducta, las
  cuales son un ejemplo de la tendencia a pensar en ella en términos de
  dicotomías: (1) ¿Es orgánico o psicógeno? (2) ¿Es heredado o aprendido?
  Se ha comprobado que ambas preguntas no están bien orientadas; sin
  embargo, figuran entre las que se hacen con más frecuencia en clase de
  biopsicología.</p>
<p>Descartes (1596-1650) propuso una filosofía que, en cierto sentido,
  asignaba una parte del universo a la ciencia y otra a la Iglesia.
  Argumentó que el universo se compone de dos elementos: (1) la materia
  física, que se comporta conforme a las leyes de la naturaleza y por lo
  tanto es un objetivo de estudio apropiado para la investigación
  científica, y (2) la mente humana (el alma, el yo o el espíritu), que
  carece de sustancia física, controla la conducta humana, no obedece a
  leyes naturales y por lo tanto es el terreno apropiado de la
  Iglesia.</p>
<p>Se asumió que el organismo humano, incluyendo el cerebro, era algo
  totalmente físico, al igual que lo eran los animales. El
  <strong>dualismo cartesiano</strong> , como se llegó a conocer a la
  filosofía de Descartes, fue tolerado por la Iglesia Católica, y así la
  idea de que el cerebro humano y la mente son entidades distintas fue
  aceptada por una gran mayoría. Pese a que han transcurrido siglos de
  avances científicos, ha persistido hasta nuestros días.</p>
<p>La mayor parte de las personas entienden ahora que la conducta humana
  tiene una base fisiológica, pero muchos siguen aferrados al postulado
  dualista de que hay una clase de actividad humana que de algún modo va
  más allá del cerebro humano (Searle, 2000).</p>
<p>Cada vez que se ha desacreditado, ha vuelto a surgir en una forma
  algo modificada. En primer lugar, se comprobó que, además de la genética
  y el aprendizaje, hay otros factores que influyen en el desarrollo de la
  conducta. Se demostró que también influyen factores tales como el medio
  ambiente fetal, la alimentación, el estrés y la estimulación sensorial.
  Esto llevó a ampliar el concepto de medio ambiente de modo que incluyera
  una serie de factores relacionados con la experiencia, además del
  aprendizaje.</p>
<p>De
  hecho, hizo que la dicotomía herencia o medio ambiente pasara de
  referirse a «factores genéticos o aprendizaje» a aludir a los «factores
  genéticos o la experiencia». Luego se argumentó de modo convincente que
  la conducta siempre se desarrolla bajo el control conjunto de la
  herencia y del medio ambiente (véanse Johnston, 1987; Rutter, 1997), y
  no bajo el control de uno o de otro. Frente a este descubrimiento,
  muchos simplemente sustituyeron un tipo de ideología herencia o medio
  ambiente por otra similar. Dejaron de preguntarse: «¿Es genético o es
  resultado de la experiencia?» y empezaron a plantearse: «¿En qué medida
  es genético y en qué medida es resultado de la experiencia?»</p>
<p>Al igual que las primeras versiones de la pregunta herencia o
  ambiente, la versión de «cuánto es genético» y «cuánto es resultado de
  la experiencia» básicamente está mal planteada. El problema es que se
  basa en la premisa de que los factores genéticos y los relacionados con
  la experiencia [factores ambientales] se combinan de forma aditiva —que
  una capacidad comportamental, como la inteligencia, se genera combinando
  o mezclando tantas partes de genética y tantas de experiencia, en lugar
  de por la interacción de la genética y la experiencia—.</p>
<h2>Evolución</h2>
<p>La evolución no progresa hacia una perfección predeterminada —la
  evolución es un diablillo, no un arquitecto—. Los aumentos de la
  capacidad de adaptación se dan mediante cambios en programas de
  desarrollo existentes; y los resultados, aunque representan mejoras en
  su contexto ambiental particular, nunca son un diseño perfecto (véase
  Nesse y Williams, 1998). Por ejemplo, el hecho de que el esperma de
  mamífero no se desarrolle eficazmente a la temperatura corporal llevó a
  la evolución del escroto —el cual no es precisamente una solución
  perfecta para un problema de diseño—.</p>
<p>No todas las conductas ni las estructuras existentes son adaptativas.
  A menudo la evolución ocurre mediante cambios en los programas de
  desarrollo que desembocan en varias características relacionadas, de las
  cuales puede que sólo una sea adaptativa —los productos secundarios
  incidentales evolutivos que no contribuyen a la adaptación se denominan
  <strong>spandrels</strong></p>
<p>—. Asimismo, las conductas y estructuras que en un momento fueron
  adaptativas pueden llegar a ser no adaptativas, o incluso
  desadaptativas, si cambia el medio ambiente. El ombligo del ser humano
  es un spandrel: no tiene una función adaptativa y no es más que un
  subproducto del cordón umbilical.</p>
<p>No todas las características adaptativas existentes evolucionaron
  para desempeñar su función actual. Algunas características, llamadas
  <strong>exaptaciones</strong> , evolucionaron para cumplir una función y
  más tarde fueron reclutadas para realizar otra (Buss et al., 1998;
  Tattersall, 2001). Por ejemplo, las alas de los pájaros son exaptaciones
  —se trata de extremidades que en un principio evolucionaron con el fin
  de servir para caminar—.</p>
<h2>Apareamiento</h2>
<p>La mayoría de los mamíferos tienden a establecer vínculos de
  apareamiento. ¿Por qué? Una influyente teoría, propuesta originalmente
  por <strong>Trivers</strong> (1972), atribuye la evolución del
  establecimiento de estos vínculos en los mamíferos al hecho de que sus
  hembras paren una cantidad relativamente pequeña de crías indefensas y
  que se desarrollan lentamente. Como resultado, para los mamíferos macho
  resulta adaptativo permanecer con las hembras que portan su descendencia
  y favorecer que ésta se desarrolle satisfactoriamente. Un mamífero macho
  que se comporta así, tiene más posibilidades de traspasar sus
  características hereditarias a las generaciones venideras. Por
  consiguiente, la selección natural ha promovido la evolución en los
  mamíferos macho de la tendencia a vincularse con las hembras con las que
  han copulado.</p>
<p>De igual modo, existe una presión de selección sobre los mamíferos
  hembra para comportarse de manera que induzca a los machos a vincularse
  con ellas, ya que esto aumenta sus posibilidades de transmitir sus
  propias características hereditarias a las generaciones futuras.</p>
<p>En muchas especies, los vínculos de apareamiento duran toda la vida.
  El modelo de vínculo de apareamiento más prevalente entre los mamíferos
  es la poligamia, un arreglo en el que un macho establece vínculos de
  apareamiento con más de una hembra. ¿Cómo evolucionó la poligamia en
  tantas especies de mamíferos? Las pruebas sugieren que evolucionó como
  el sistema predominante de apareamiento en los mamíferos porque los
  mamíferos hembra hacían una contribución mucho mayor que los machos a la
  crianza de su prole (Trivers, 1972). En los mamíferos, las madres llevan
  a sus crías en desarrollo en el interior de sus cuerpos, a veces durante
  muchos meses, y luego les amamantan y cuidan de ellos después de que
  hayan nacido. Por lo contrario, los padres de los mamíferos a menudo no
  contribuyen a la reproducción más que con el esperma.</p>
<p>Una de las principales consecuencias de esta disposición parental
  unilateral es que las hembras de los mamíferos sólo pueden tener unos
  cuantos descendientes durante su vida, mientras que los machos pueden
  engendrar muchos descendientes. Ya que cada mamífero hembra sólo puede
  tener unos cuantos descendientes, tiene que asegurarse de que sus
  características hereditarias van a transmitirse a futuras generaciones
  en la cantidad suficiente. En particular, es importante que se aparee
  con machos especialmente aptos. Aparearse con machos aptos aumenta la
  posibilidad de que su descendencia sea apta y pase sus genes, junto con
  los de su pareja, a la siguiente generación; también aumenta la
  probabilidad de que, por pequeño que sea el apoyo parental que su
  descendencia reciba del padre, será eficaz. Así pues, según la teoría
  actual, la tendencia a establecer vínculos de apareamiento sólo con los
  machos más aptos evolucionó en las hembras de muchas especies de
  mamíferos.</p>
<p>Por lo contrario, dado que los mamíferos macho pueden engendrar
  tantos descendientes, ha habido poca presión evolutiva sobre ellos para
  que sean selectivos en su apareamiento —los machos de la mayoría de las
  especies de mamíferos establecerán vínculos de apareamiento con tantas
  hembras como puedan—. La consecuencia inevitable del apareamiento
  selectivo de los mamíferos hembra y del La prueba más sólida a favor de
  la teoría que la <strong>poligamia</strong> evoluciona cuando las
  hembras contribuyen más que los machos a la reproducción procede de los
  estudios de <strong>poliandria</strong>. Ésta es un plan de apareamiento
  en el cual una hembra establece vínculos de apareamiento con más de un
  macho.</p>
<p>La poliandria no se da en los mamíferos, sólo ocurre en especies en
  las que la contribución de los machos a la reproducción es mayor que la
  de las hembras. Por ejemplo, en una especie que se ajusta a la
  poliandria, el caballito de mar, la hembra deposita sus huevos en la
  bolsa del macho, él las fertiliza y las lleva consigo hasta que han
  madurado lo suficiente para valerse por sí mismas (véase Daly y Wilson,
  1983).</p>
<p>La opinión actual es que tanto el aumento de talla corporal como la
  tendencia a entablar peleas evolucionaron en los machos de los mamíferos
  porque las hembras de los mamíferos tienden a ser más selectivas en su
  vínculo reproductor. Debido a la selectividad de las hembras, la
  competitividad entre los machos por las parejas para reproducirse se
  hace violenta, y sólo los contendientes que ganan transmiten sus genes.
  Por lo contrario, las hembras de la mayoría de las especies tienen pocos
  problemas en encontrar una pareja para reproducirse. Aunque la mayoría
  de los mamíferos son polígamos, el 3% de las especies de mamíferos,
  incluidos los seres humanos, son básicamente monógamos. La monogamia es
  un modelo de vínculo de apareamiento en el que se establecen vínculos
  duraderos entre un macho y una hembra.</p>
<p>A pesar de que la monogamia es el sistema de vínculo de apareamiento
  más frecuente en los seres humanos, es importante recordar que no es el
  sistema predominante en los mamíferos.</p>
<h2>La elección de parejas en
  humanos</h2>
<p>La precedente teoría evolucionista de elección de pareja es una
  teoría que ha llevado a muchas predicciones sobre aspectos actuales de
  la elección de pareja en seres humanos. Buss (1992) ha confirmado varias
  de ellas;</p>
<ol>
  <li>Los hombres de la mayoría de las culturas valoran la juventud y el
    atractivo (ambos son índices de fertilidad) en sus parejas más de lo que
    lo hacen las mujeres; en contraposición, las mujeres valoran el poder y
    la capacidad de ingresos económicos más que los hombres.
  </li>
  <li>El atractivo físico es lo que mejor predice qué mujeres se unirán
    con hombres de alto nivel profesional.
  </li>
  <li>La principal estrategia de las mujeres para atraer a una pareja es
    aumentar su atractivo físico; la de los hombres, hacer alarde de su
    poder y sus recursos.
  </li>
  <li>Los hombres son más propensos que las mujeres a ser adúlteros.</li>
</ol>
<p>La etapa del desarrollo, por lo general una edad temprana, durante la
  cual una experiencia determinada ha de ocurrir para que tenga un efecto
  importante sobre el desarrollo de un rasgo, es <strong>el período
    sensible</strong> [o de susceptibilidad] a ese rasgo.</p>
<h2>Los
  genotipos similares buscan experiencias similares</h2>
<p>Una cuestión, que frecuentemente se pasa por alto, acerca de la
  importancia de los factores genéticos en el desarrollo de las
  diferencias psicológicas entre seres humanos es que las diferencias
  genéticas inducen diferencias psicológicas al influir sobre la
  experiencia (véase Plomin y Neiderhiser, 1992). Al principio esta
  afirmación resulta sorprendente, ya que estamos acostumbrados a pensar
  en los genes y en la experiencia como influencias evolutivas
  independientes. Sin embargo, en la actualidad existen muchas pruebas de
  que los individuos con una dotación genética similar tienden a buscar
  ambientes y experiencias similares.</p>
<p>Por ejemplo, los individuos cuya dotación genética les inclina a la
  agresividad son más propensos a implicarse en actividades agresivas (por
  ejemplo, fútbol o luchas competitivas), y estas experiencias contribuyen
  al desarrollo de tendencias agresivas.</p>
<h1>Anatomía del sistema
  nervioso</h1>
<h2>Sistema nervioso periférico</h2>
<p>El <strong>sistema nervioso somático (SNS)</strong> es la parte del
  SNP que se relaciona con el medio ambiente externo. Está formado por</p>
<ul>
  <li>nervios <strong>aferentes</strong> , que transmiten las señales
    <strong>sensitivas</strong> desde la <em>piel, los músculos
      esqueléticos, las articulaciones, los ojos, los oídos, etc</em>., hacia
    el sistema nervioso central;
  </li>
  <li>y los nervios <strong>eferentes</strong> , que conducen las señales
    <strong>motoras</strong> desde el sistema nervioso central hasta los
    <em>músculos esqueléticos</em>.
  </li>
</ul>
<p>El <strong>sistema nervioso neurovegetativo [o autónomo
  (SNA)]</strong> es la parte del sistema nervioso periférico que regula
  el medio ambiente interno del organismo.</p>
<ul>
  <li>Está formado por nervios <strong>aferentes</strong> , que llevan las
    señales <strong>sensitivas</strong> desde los <em>órganos internos</em>
    al SNC,
  </li>
  <li>y de nervios <strong>eferentes</strong> , que conducen las señales
    <strong>motoras</strong> desde el SNC hasta los <em>órganos
      internos</em>.
    <ul>
      <li>Los nervios <strong>simpáticos</strong> son los nervios motores
        neurovegetativos que proyectan desde el SNC hasta la zona lumbar (zona
        inferior de la espalda) y la torácica (zona del tórax o pecho) de la
        médula espinal.
      </li>
      <li>Los nervios <strong>parasimpáticos</strong> son los nervios motores
        neurovegetativos que proyectan desde el encéfalo y la región sacra (zona
        más baja de la espalda) de la médula espinal.
      </li>
    </ul>
  </li>
</ul>
<p>El enfoque tradicional de las funciones respectivas de los sistemas
  simpático y parasimpático destaca tres principios fundamentales:</p>
<ol>
  <li>que los nervios simpáticos estimulan, organizan y movilizan los
    recursos energéticos ante situaciones de emergencia; mientras que los
    nervios parasimpáticos actúan conservando la energía;
  </li>
  <li>que cada órgano de actuación neurovegetativo recibe un input
    simpático y parasimpático opuesto, por lo que su actividad está
    controlada por el nivel relativo de actividad simpática y parasimpática;
    y
  </li>
  <li>que los cambios simpáticos indican activación psicológica, mientras
    que los cambios parasimpáticos indican descanso psicológico.
  </li>
</ol>
<p><em>Algunas funciones de la activación simpática y de la
  parasimpática</em></p>
<figure class="tablap normal">
  <table>
    <thead>
    <tr>
      <th>Órgano</th>
      <th>Efecto simpático</th>
      <th>Efecto parasimpático</th>
    </tr>
    </thead>
    <tbody>
    <tr>
      <td>Glándula salival</td>
      <td>Disminuye la secreción</td>
      <td>Aumenta la secreción</td>
    </tr>
    <tr>
      <td>Corazón</td>
      <td>Aumenta la frecuencia cardíaca</td>
      <td>Disminuye la frecuencia cardiaca</td>
    </tr>
    <tr>
      <td>Vasos sanguíneos</td>
      <td>Contrae los vasos sanguíneos en la mayoría de los órganos</td>
      <td>Dilata los vasos sanguíneos en unos cuantos órganos</td>
    </tr>
    <tr>
      <td>Pene</td>
      <td>Eyaculación</td>
      <td>Erección</td>
    </tr>
    <tr>
      <td>Músculos radiales del iris</td>
      <td>Dilata la pupila</td>
      <td>Sin efecto</td>
    </tr>
    <tr>
      <td>Músculos orbiculares del iris</td>
      <td>Sin efecto</td>
      <td>Contrae la pupila</td>
    </tr>
    <tr>
      <td>Glándula lagrimal</td>
      <td>Sin efecto</td>
      <td>Estimula la secreción</td>
    </tr>
    <tr>
      <td>Glándula sudorípara</td>
      <td>Estimula la secreción</td>
      <td>Sin efecto</td>
    </tr>
    <tr>
      <td>Estómago e intestino</td>
      <td>Sin efecto</td>
      <td>Estimula la secreción</td>
    </tr>
    <tr>
      <td>Pulmones</td>
      <td>Dilata los bronquiolos, inhibe la secreción mucosa</td>
      <td>Contrae los bronquiolos, estimula la secreción mucosa</td>
    </tr>
    <tr>
      <td>Músculos piloerectores</td>
      <td>Eriza el vello y produce «piel de gallina»</td>
      <td>Sin efecto</td>
    </tr>
    </tbody>
  </table>
</figure>
<p>La mayor parte de los nervios del sistema nervioso periférico surgen
  de la médula espinal, pero hay 12 pares de excepciones: los 12 pares de
  nervios craneales, que surgen del encéfalo. Se les numera de modo
  secuencial, desde la parte de delante hacia la de atrás. Los pares
  craneales incluyen nervios puramente sensitivos, tales como el nervio
  olfativo (I par) y el nervio óptico (II par), pero la mayoría contienen
  tanto fibras sensitivas como fibras motoras. El nervio vago (X par) es
  el de mayor longitud; engloba fibras sensitivas y motoras que van hasta
  el intestino y proceden de él.</p>
<p><em>Funciones de los pares craneales</em></p>
<figure class="tablap normal">
  <table>
    <tr>
      <th>Número</th>
      <th>Nombre</th>
      <th>Función general</th>
      <th>Funciones específicas</th>
    </tr>
    <tr>
      <th>I</th>
      <td>Olfativo</td>
      <td>Sensitiva</td>
      <td>Olfato</td>
    </tr>
    <tr>
      <th>II</th>
      <td>Óptico</td>
      <td>Sensitiva</td>
      <td>Vista</td>
    </tr>
    <tr>
      <th>III</th>
      <td>Motor ocular común</td>
      <td>Motora/Sensitiva</td>
      <td>Movimiento ocular y constricción de la pupila/Señales sensitivas de ciertos músculos oculares</td>
    </tr>
    <tr>
      <th>IV</th>
      <td>Patético</td>
      <td>Motora/Sensitiva</td>
      <td>Movimiento ocular/Señales sensitivas de ciertos músculos oculares</td>
    </tr>
    <tr>
      <th>V</th>
      <td>Trigémino</td>
      <td>Sensitiva/Motora</td>
      <td>Sensibilidad facial/Masticación</td>
    </tr>
    <tr>
      <th>VI</th>
      <td>Motor ocular externo</td>
      <td>Motora/Sensitiva</td>
      <td>Movimiento ocular/Señales sensitivas de ciertos músculos oculares</td>
    </tr>
    <tr>
      <th>VII</th>
      <td>Facial</td>
      <td>Sensitiva/Motora</td>
      <td>Gusto de los dos tercios anteriores de la lengua/Expresión facial, secreción de lágrimas, salivación,
        dilatación de los vasos sanguíneos craneales
      </td>
    </tr>
    <tr>
      <th>VIII</th>
      <td>Estato-acústico</td>
      <td>Sensitiva</td>
      <td>Audición, señales sensitivas de los órganos del equilibrio en el oído interno</td>
    </tr>
    <tr>
      <th>IX</th>
      <td>Glosofaríngeo</td>
      <td>Sensitiva/Motora</td>
      <td>Gusto del tercio posterior de la lengua/Salivación, deglución</td>
    </tr>
    <tr>
      <th>X</th>
      <td>Vago</td>
      <td>Sensitiva/Motora</td>
      <td>Sensibilidad de los órganos abdominales y torácicos/Control de los órganos abdominales y torácicos y de los
        músculos de la garganta
      </td>
    </tr>
    <tr>
      <th>XI</th>
      <td>Espinal accesorio</td>
      <td>Motora/Sensitiva</td>
      <td>Movimiento del cuello, hombros y cabeza/Señales sensitivas de los músculos del cuello</td>
    </tr>
    <tr>
      <th>XII</th>
      <td>Hipogloso</td>
      <td>Motora/Sensitiva</td>
      <td>Movimientos de la lengua/Señales sensitivas de los músculos de la lengua</td>
    </tr>
  </table>
</figure>
<h2>Sistema nervioso central</h2>
<p>El líquido cefalorraquídeo sostiene y amortigua al cerebro. Estas dos
  funciones son muy evidentes en pacientes a quienes se les ha extraído
  líquido cefalorraquídeo: sufren agudos dolores de cabeza y sienten
  punzadas de dolor cada vez que mueven la cabeza. El líquido
  cefalorraquídeo es producido continuamente por el plexo coroideo —una
  red de capilares (pequeños vasos sanguíneos) que sobresalen de la
  cubierta piamadre y se proyectan en los ventrículos—- El exceso de
  líquido cefalorraquídeo es absorbido constantemente del espacio
  subaracnoideo hasta amplias cavidades repletas de sangre, los senos
  durales, que se extienden por la duramadre y vierten su contenido en las
  grandes venas yugulares del cuello.</p>
<h3>Barrera hematoencefálica</h3>
<p>El encéfalo es un órgano electroquímico delicadamente afinado cuya
  función puede alterarse gravemente debido a la introducción de ciertas
  sustancias químicas. Por fortuna, hay un mecanismo que impide el paso de
  muchas sustancias tóxicas desde la sangre al encéfalo: la barrera
  hematoencefálica. Esta barrera es una de las consecuencias de la
  estructura propia de los vasos sanguíneos cerebrales. En el resto del
  organismo, las células que componen las paredes de los vasos sanguíneos
  están laxamente unidas, de manera que la mayoría de las moléculas pasan
  fácilmente a su través al tejido circundante. En el encéfalo, sin
  embargo, las células de las paredes de los vasos sanguíneos están
  compactamente unidas, formando una barrera que frena el paso de muchas
  moléculas —en particular, de proteínas y otras moléculas de gran
  tamaño—.</p>
<h3>Neuronas</h3>
<p>Las
  neuronas son células especializadas en recibir, conducir y transmitir
  señales electroquímicas. Presentan una sorprendente diversidad de formas
  y tamaños (véanse Maccaferri y Lacaille, 2003; Mott y Dingledine, 2003;
  Silberberg, Gupta y Markram, 2002); pero muchas son similares a las que
  se ilustran en las Figuras 3.5 y 3.6.</p>
<h4>Tipos
  de neuronas</h4>
<ul>
  <li>Una neurona que tiene más de dos procesos se denomina
    <strong>neurona multipolar</strong> ; la mayoría de las neuronas son
    multipolares.
  </li>
  <li>Una neurona con un proceso se denomina <strong>neurona
    unipolar</strong> ,
  </li>
  <li>y una neurona con dos procesos se clasifica como <strong>neurona
    bipolar</strong>.
  </li>
  <li>Las neuronas con axones cortos, o sin axón, se llaman
    <strong>interneuronas</strong> ; su función consiste en integrar la
    actividad neural que ocurre dentro de una única estructura cerebral, no
    en transmitir señales de una estructura a otra.
  </li>
</ul>
<h4>Neurogliocitos</h4>
<p>Existen cuatro tipos de neurogliocitos (Fields y Stevens-Graham,
  2002).</p>
<ol>
  <li>Los
    <strong>oligodendrocitos</strong> son un tipo de neurogliocitos. Emiten
    prolongaciones que se enrollan en torno a los axones de algunas de las
    neuronas del sistema nervioso central. Estas prolongaciones son ricas en
    <strong>mielina, una sustancia grasa aislante</strong> ; y la vaina de
    mielina que forman aumenta la velocidad y eficacia de la conducción
    axónica.
  </li>
  <li>Una función similar es llevada a cabo en el sistema nervioso
    periférico por <strong>las células de Schwann</strong> , un segundo tipo
    de neurogliocitos. Obsérvese que cada célula de Schwann
    <strong>constituye un segmento de mielina</strong> , mientras que cada
    oligodendrocito aporta varios segmentos de mielina, a menudo a más de un
    axón. Otra diferencia importante entre las células de Schwann y los
    oligodendrocitos es que sólo las primeras pueden guiar el proceso de
    regeneración (volver a crecer) ( <strong>postmitótica</strong> ) de los
    axones tras una lesión. Esta es la razón de que la regeneración axónica
    eficaz en el sistema nervioso de los mamíferos únicamente se dé en el
    SNP.
  </li>
  <li>Un tercer tipo de neurogliocitos son los
    <strong>astrocitos</strong>. Son los más grandes de los neurogliocitos y
    se les llama así porque tienen forma de estrella (astro significa
    «estrella»). Las prolongaciones con forma de brazos de algunos
    astrocitos <strong>recubren la superficie de los vasos
      sanguíneos</strong> que recorren el cerebro y también establecen
    contacto con los cuerpos celulares de las neuronas (véase la Figura
    3.10). Estos astrocitos específicos intervienen en el paso de sustancias
    químicas desde la sangre a las neuronas del SNC, pero otros astrocitos
    realizan una serie de funciones diferentes.
  </li>
  <li>Y un cuarto tipo de neurogliocitos son los
    <strong>microgliocitos</strong>. Éstos <strong>responden a las lesiones
      o a las enfermedades</strong> absorbiendo los desechos celulares y
    desencadenando las respuestas inflamatorias.
  </li>
</ol>
<p>Durante décadas se ha supuesto que la función de los neurogliocitos
  era simplemente la de proporcionar soporte a las neuronas —aportándoles
  sustancias nutritivas, limpiando los desechos y formando un entramado
  para mantener ensamblados los circuitos neurales—(glía significa
  «pegamento»). Pero este limitado punto de vista sobre la función de los
  neurogliocitos está desapareciendo rápidamente. En los últimos años se
  ha demostrado que participan en la transmisión de señales, enviando
  señales a las neuronas y recibiendo señales de ellas; y también que
  controlan el establecimiento y mantenimiento de sinapsis entre neuronas;
  asimismo se ha comprobado que intervienen en los circuitos neurogliales
  (Haydon, 2001).</p>
<h3>Médula
  espinal</h3>
<p>Cuando se hace una sección transversal, resulta evidente que la
  médula espinal contiene dos zonas diferentes (véase la Figura3.17): una
  zona interna formada por sustancia gris con forma de H, rodeada por una
  zona de sustancia blanca. En su mayor parte, la sustancia gris está
  compuesta por cuerpos celulares e interneuronas amielínicas; mientras
  que la sustancia blanca lo está por axones mielínicos. (Es la mielina lo
  que le da a la sustancia blanca su brillo blanco satinado.) Los dos
  brazos dorsales de la sustancia gris de la médula se designan astas
  dorsales y los dos brazos ventrales, astas ventrales.</p>
<ul>
  <li>Todos
    los axones que componen la <strong>raíz dorsal</strong> , ya sean
    somáticos o neurovegetativos, proceden de <strong>neuronas sensitivas
      unipolares (aferentes)</strong>; sus cuerpos celulares se agrupan justo
    fuera de la médula, formando los ganglios de la raíz dorsal. Muchos de
    sus terminales sinápticos se encuentran en las astas dorsales de la
    sustancia gris medular (véase la Figura 3.18).
  </li>
  <li>En contraposición, los axones que forman la <strong>raíz
    ventral</strong> vienen de <strong>neuronas motoras multipolares
    (eferentes)</strong>, cuyos cuerpos celulares se localizan en las astas
    ventrales.
    <ul>
      <li>Las neuronas que forman parte del <em>sistema nervioso somático</em>
        proyectan a músculos esqueléticos;
      </li>
      <li>las que pertenecen al <em>sistema nervioso neurovegetativo</em>
        proyectan a ganglios, donde establecen sinapsis con neuronas que, a su
        vez, proyectan a órganos internos (corazón, estómago, hígado,
        etc.).
      </li>
    </ul>
  </li>
</ul>
<h2>Cinco
  divisiones principales del encéfalo</h2>
<p>Adviértase que en los seres humanos, al igual que en otros
  vertebrados superiores, el <strong>telencéfalo</strong> (los hemisferios
  cerebrales izquierdo y derecho) es el que experimenta el mayor grado de
  evolución durante el desarrollo. A las otras cuatro partes del encéfalo
  a menudo se les denomina, en conjunto, el <strong>tronco del
    encéfalo</strong> , —el tronco sobre el que se asientan los hemisferios
  cerebrales—. Al mielencéfalo se le suele designar bulbo raquídeo.</p>
<figure class="tablap no-bordes">
  <table>
    <tbody style="background: #5B3E00">
    <tr>
      <th rowspan=7>Telencéfalo</th>
      <td>Corteza cerebral</td>
      <td>
        Neocorteza<br>Hipocampo
      </td>
    </tr>
    <tr>
      <td>Principales cisuras</td>
      <td>
        Cisura central<br>Cisura lateral<br>Cisura longitudinal
      </td>
    </tr>
    <tr>
      <td>Principales circunvoluciones</td>
      <td>
        Circunvolución precentral<br>Circunvolución poscentral<br>Circunvolución temporal superior<br>Circunvolución
        cingulada
      </td>
    </tr>
    <tr>
      <td>Cuatro lóbulos</td>
      <td>
        Lóbulo frontal<br>Lóbulo temporal<br>Lóbulo parietal<br>Lóbulo occipital
      </td>
    </tr>
    <tr>
      <td>Sistema límbico</td>
      <td>
        Amígdala<br>Hipocampo<br>Trígono cerebral<br>Corteza cingulada<br>Septum pellucidum<br>Cuerpos mamilares
      </td>
    </tr>
    <tr>
      <td>Ganglios basales</td>
      <td>
        Amígdala<br>Caudado (neoestriado)<br>Putamen (neoestriado)<br>Globo pálido
      </td>
    </tr>
    <tr>
      <td>Comisuras cerebrales</td>
      <td>
        Cuerpo calloso
      </td>
    </tr>
    </tbody>
    <tbody style="background: #794904">
    <tr>
      <th rowspan=4>Diencéfalo</th>
      <td>Tálamo</td>
      <td>
        Masa intermedia<br>Núcleo geniculados laterales<br>Núcleos geniculados mediales<br>Núcleos ventrales posteriores
      </td>
    </tr>
    <tr>
      <td>Hipotálamo</td>
      <td>
        Cuerpos mamilares
      </td>
    </tr>
    <tr>
      <td colspan=2>Quiasma óptico</td>
    </tr>
    <tr>
      <td colspan=2>Hipófisis</td>
    </tr>
    </tbody>
    <tbody style="background: #365871">
    <tr>
      <th rowspan=2>Mesencéfalo</th>
      <td>Téctum</td>
      <td>
        Tubérculos cuadrigéminos superiores<br>Tubérculos cuadrigéminos inferiores
      </td>
    </tr>
    <tr>
      <td>Tegmentum</td>
      <td>
        Formación reticular<br>Acueducto cerebral<br>Sustancia gris periacueductal<br>Sustancia negra<br>Núcleo rojo
      </td>
    </tr>
    </tbody>
    <tbody style="background: #355900">
    <tr>
      <th>Metencéfalo</th>
      <td colspan=2>Formación reticular<br>Protuberancia<br>Cerebelo</td>
    </tr>
    </tbody>
    <tbody style="background: #9E4095">
    <tr>
      <th>Mielencéfalo o bulbo raquídeo</th>
      <td colspan=2>Formación reticular</td>
    </tr>
    </tbody>
  </table>
</figure>
<h3>Mielencéfalo (bulbo raquídeo)</h3>
<p>Desde el punto de vista psicológico, una parte interesante del
  mielencéfalo es la formación reticular (véase la Figura 3.21). Se trata
  de una compleja red compuesta por unos 100 núcleos diminutos, que ocupa
  la parte central del tronco encefálico desde el límite posterior del
  mielencéfalo hasta el extremo anterior del mesencéfalo. Se le llama así
  porque parece una red (retículo significa «pequeña red»).</p>
<p>En ocasiones, a la formación reticular se le denomina <strong>sistema
  reticular activador</strong> , ya que parece que algunas de sus partes
  intervienen en la activación [arousal]. No obstante, los diversos
  núcleos de la formación reticular están implicados en una serie de
  funciones —incluyendo</p>
<ul>
  <li>el sueño,</li>
  <li>la atención,</li>
  <li>el movimiento,</li>
  <li>el mantenimiento del tono muscular y</li>
  <li>varios reflejos cardíacos, circulatorios y respiratorios.</li>
</ul>
<p>Según esto, referirse a este conjunto de núcleos como a un sistema
  puede llevar a error.</p>
<h3>Metencéfalo</h3>
<h4>Protuberancia</h4>
<p>El
  metencéfalo, así como el mielencéfalo, alberga múltiples fascículos
  ascendentes y descendentes, y también parte de la formación reticular.
  Dichas estructuras forman una prominencia, conocida como
  <strong>protuberancia</strong> [o puente], sobre la superficie ventral
  del tronco cerebral. La protuberancia es una de las principales partes
  del metencéfalo; la otra es el <strong>cerebelo</strong> (pequeño
  cerebro) —véase la Figura 3.21—.</p>
<h4>Cerebelo</h4>
<p>El cerebelo es la estructura, grande y lobulada, que se sitúa sobre
  la superficie dorsal del tronco del encéfalo. Es una estructura
  <strong>sensitivomotriz</strong> de gran importancia: una lesión del
  cerebelo anula la capacidad de controlar con precisión los movimientos y
  adaptarlos a los cambios de circunstancias. No obstante, el hecho de que
  las lesiones cerebelosas también produzcan una serie de alteraciones
  cognitivas sugiere que las funciones del cerebelo no se restringen al
  control sensitivomotor.</p>
<h3>Mesencéfalo</h3>
<p>El mesencéfalo, al igual que el metencéfalo, consta de dos partes.
  Estas son el téctum y el tegmentum (véase la Figura 3.22 en la página
  72).</p>
<h4>Téctum</h4>
<p>El
  <strong>téctum</strong> (techo) es la zona dorsal del mesencéfalo. En
  los mamíferos, incluye dos pares de prominencias: los tubérculos
  cuadrigéminos (pequeñas colinas).</p>
<ul>
  <li>El par posterior, al que se llama <strong>tubérculos cuadrigéminos
    inferiores</strong> , tiene una <strong>función auditiva</strong> ;
  </li>
  <li>el par anterior, al que se denomina <strong>tubérculos cuadrigéminos
    superiores</strong> , tiene una <strong>función visual</strong>. En los
    vertebrados inferiores, la función del téctum es íntegramente visual,
    por lo que se conoce como téctum óptico.
  </li>
</ul>
<h4>Tegmentum</h4>
<p>El <strong>tegmentum</strong> es la división del mesencéfalo ventral
  al téctum. Además de la formación reticular y de los fascículos que lo
  atraviesan, el tegmentum contiene tres estructuras «coloreadas» que
  interesan mucho a los biopsicólogos: la <strong>sustancia gris
    periacueductal</strong> , la <strong>sustancia negra</strong> y el
  <strong>núcleo rojo</strong> (véase la Figura 3.22).</p>
<ul>
  <li>La sustancia gris periacueductal es la sustancia gris que se
    localiza en torno al acueducto cerebral, el conducto que comunica el
    tercer ventrículo con el cuarto. Resulta de especial interés debido a
    que interviene como mediador de los <strong>efectos analgésicos</strong>
    (de reducción del dolor) de los fármacos opioides. Ambos, la sustancia
    negra y el núcleo rojo, son componentes importantes del <strong>sistema
      sensitivomotor</strong>.
  </li>
</ul>
<h3>Diencéfalo</h3>
<p>El diencéfalo contiene dos estructuras: el tálamo y el hipotálamo
  (véase la Figura 3.23 en la página 72).</p>
<h4>Tálamo</h4>
<p>El <strong>tálamo</strong> es la gran estructura, compuesta por dos
  lóbulos [o partes], que constituye la porción superior del tronco
  encefálico. Cada lóbulo se asienta a uno de los lados del tercer
  ventrículo, y los dos están unidos por la masa intermedia, que atraviesa
  el ventrículo. En la superficie del tálamo se pueden observar láminas
  (capas) blancas, formadas por axones mielinizados. El tálamo incluye
  muchos pares diferentes de núcleos, la mayoría de los cuales proyectan a
  la corteza. Algunos son <strong>núcleos de relevo sensorial</strong>
  —núcleos que reciben señales de los receptores sensitivos, las procesan
  y luego las transmiten a las zonas apropiadas de la corteza sensitiva—.
  Por ejemplo,</p>
<ul>
  <li>los núcleos geniculados laterales,</li>
  <li>los núcleos geniculados mediales y</li>
  <li>los núcleos ventrales posteriores son importantes centros de relevo
    de <strong>los sistemas visual, auditivo y somatosensitivo</strong> ,
    respectivamente.
  </li>
</ul>
<h4>Hipotálamo</h4>
<p>El
  <strong>hipotálamo</strong> se localiza justo debajo del tálamo anterior
  (hipo significa «debajo»). Representa un papel importante en el control
  de varias <strong>conductas de motivación.</strong> Hasta cierto punto,
  ejerce sus efectos regulando la liberación de <strong>hormonas</strong>
  por parte de la <strong>hipófisis</strong> , que pende del hipotálamo en
  la superficie ventral del cerebro. Además de la hipófisis, en la cara
  inferior del hipotálamo pueden verse otras dos estructuras: el quiasma
  óptico y los cuerpos mamilares.</p>
<ul>
  <li>El quiasma óptico es el punto en el que convergen los
    <strong>nervios ópticos</strong> , procedentes de cada ojo. Su forma de
    X se debe a que algunos axones del nervio óptico decusan (cruzan al lado
    opuesto del cerebro) a través del quiasma óptico. A las fibras que
    decusan se les llama contralaterales (pasan de un lado del cuerpo al
    otro) y a las que no decusan, homolaterales (permanecen en el mismo lado
    del cuerpo).
  </li>
  <li>Los cuerpos mamilares, que a menudo se consideran parte del
    hipotálamo, son un par de núcleos esféricos que se sitúan en la cara
    inferior del hipotálamo, justo detrás de la hipófisis.
  </li>
</ul>
<h3>Telencéfalo</h3>
<p>El telencéfalo, la mayor de las divisiones del encéfalo humano, media
  sus funciones más complejas.</p>
<ul>
  <li>Inicia el movimiento voluntario,</li>
  <li>interpreta la información sensitiva</li>
  <li>y media procesos cognitivos complejos tales como aprender, hablar y
    solucionar problemas.
  </li>
</ul>
<h4>Corteza cerebral</h4>
<p>Los
  hemisferios cerebrales están cubiertos por una capa de tejido llamada
  corteza cerebral. En los seres humanos, la corteza cerebral está muy
  plegada (arrugada) —véase la Figura 3.25—. Estas circunvoluciones hacen
  que aumente la cantidad de corteza cerebral sin que aumente el volumen
  cerebral total. No todos los mamíferos tienen una corteza con
  circunvoluciones; la mayoría de ellos son <strong>lisencéfalos</strong>
  (con un encéfalo liso). Antes se pensaba que la cantidad y el tamaño de
  las circunvoluciones determinaban la capacidad intelectual de una
  especie; sin embargo, parece ser que estos atributos se relacionan más
  con el tamaño corporal.</p>
<p>Todos los mamíferos grandes tienen una corteza cerebral muy plegada.
  Las grandes hendiduras de una corteza plegada se denominan
  <strong>cisuras</strong> , y las pequeñas, <strong>surcos</strong>. Las
  prominencias entre las cisuras y los surcos se llaman
  <strong>circunvoluciones</strong>.</p>
<p>Como indica la Figura 3.26, las dos delimitaciones principales en la
  cara lateral de cada hemisferio son la <strong>cisura central</strong> y
  la <strong>cisura lateral</strong>. Estas cisuras dividen parcialmente
  cada hemisferio en cuatro lóbulos:</p>
<ul>
  <li>el lóbulo frontal,</li>
  <li>el lóbulo parietal,</li>
  <li>el lóbulo temporal y</li>
  <li>el lóbulo occipital.</li>
</ul>
<p>Entre las circunvoluciones más grandes figuran</p>
<ul>
  <li>la <strong>circunvolución precentral</strong> , que contiene la
    corteza <strong>motora</strong> ;
  </li>
  <li>la <strong>circunvolución poscentral</strong> , que abarca la
    corteza <strong>somatosensitiva</strong> (sensibilidad corporal), y
  </li>
  <li>la <strong>circunvolución superior temporal</strong> , que incluye
    la corteza <strong>auditiva</strong>.
  </li>
  <li>La función de la <strong>corteza occipital</strong> es enteramente
    <strong>visual</strong>.
  </li>
</ul>
<p>Alrededor del noventa por ciento de la corteza cerebral humana es
  neocorteza (corteza nueva); es decir: corteza formada por seis capas, de
  evolución relativamente reciente (Northcutt y Kaas, 1995).</p>
<h4>Tipos de neuronas corticales</h4>
<ol>
  <li>En primer lugar, resulta obvio que hay dos tipos básicamente
    diferentes de neuronas corticales: piramidales (con forma de pirámide) y
    estrelladas (con forma de estrella).
  </li>
</ol>
<ul>
  <li>Las <strong>células piramidale</strong> s son grandes neuronas
    multipolares, con un cuerpo celular en forma de pirámide, una gruesa
    dendrita, llamada dendrita apical, que se extiende directamente desde el
    ápice de la pirámide a la superficie de la corteza, y un axón muy
    largo.
  </li>
  <li>En contraposición, las <strong>células estrelladas</strong> son
    pequeñas interneuronas (neuronas con axón corto o sin axón), en forma de
    estrella.
  </li>
</ul>
<ol>
  <li>En segundo lugar, resulta evidente que las seis capas de la
    neocorteza se diferencian en cuanto al tamaño y la densidad de cuerpos
    celulares, así como en la proporción relativa de cuerpos celulares
    estrellados y piramidales que contienen.
  </li>
  <li>En tercer lugar, puede apreciarse que muchas dendritas y axones
    largos atraviesan la neocorteza en sentido vertical (esto es, en ángulo
    recto respecto a las capas corticales). Este flujo vertical de
    información es la base de la <strong>organización columnar</strong> de
    la neocorteza: las neuronas de una determinada columna vertical de la
    neocorteza suelen formar un minicircuito, el cual lleva a cabo una
    función particular (Laughlin y Sejnowski, 2003).
  </li>
  <li>Una cuarta característica importante de la anatomía neocortical no
    puede verse en la Figura 3.27: aunque toda la neocorteza consta de seis
    capas, las capas varían de un área a otra (Brown y Bowman, 2002;
    Passingham, Stephan y Kotter, 2002). Por ejemplo, ya que las células
    estrelladas de la capa IV están especializadas en recibir señales
    sensitivas del tálamo, esta capa está muy desarrollada en las áreas de
    la corteza sensitiva. A la inversa, como las células piramidales de la
    capa V conducen señales desde la neocorteza al tronco del encéfalo y la
    médula espinal, la capa V tiene un grosor considerable en las áreas de
    la corteza motora.
  </li>
</ol>
<h4>El sistema límbico</h4>
<p>El
  sistema límbico es un circuito de estructuras de la línea media que
  rodean el tálamo (límbico significa «anillo»). Participa en la
  <strong>regulación de las conductas motivadas</strong> —que incluyen las
  cuatro F [en inglés] de la motivación:</p>
<ul>
  <li>huir («fleeing»),</li>
  <li>comer («feeding»)</li>
  <li>luchar («fighting») y</li>
  <li>tener sexo («sexual behavior»).</li>
</ul>
<p>Además de otras estructuras ya mencionadas aquí (p.ej., los cuerpos
  mamilares y el hipocampo, las principales estructuras del sistema
  límbico incluyen a la amígdala, el trígono cerebral, la corteza
  cingulada y el septum pellucidum.</p>
<ul>
  <li>Comenzaremos a trazar el circuito límbico (véase la Figura 3.28) por
    la <strong>amígdala</strong> —un núcleo con forma de almendra localizado
    en el polo anterior del lóbulo temporal (amígdala significa «almendra»)
    (véase Swanson y Petrovich, 1998)—.
  </li>
  <li>Posterior a la amígdala está el <strong>hipocampo</strong> , que
    atraviesa el lóbulo temporal medio bajo el tálamo.
  </li>
  <li>La <strong>corteza cingulada</strong> es una amplia región de la
    neocorteza de la circunvolución del cíngulo (o del cuerpo calloso) en la
    cara medial de los hemisferios cerebrales, justo en el plano superior
    del cuerpo calloso. Rodea a la superficie dorsal del tálamo (cingulado
    significa «que rodea»).
  </li>
  <li>El <strong>trígono cerebral [o fórnix],</strong> el fascículo
    principal del sistema límbico, también rodea al tálamo dorsal. Parte del
    extremo dorsal del hipocampo y gira hacia arriba, describiendo un arco
    que recorre la cara superior del tercer ventrículo, y acaba en el septum
    y los cuerpos mamilares (fórnix significa «arco»).
  </li>
  <li>El <strong>septum</strong> es un núcleo de la línea media, situado
    en el polo anterior de la corteza cingulada. Varios fascículos de fibras
    conectan el septum y los cuerpos mamilares con la amígdala y el
    hipocampo, completando así el anillo límbico.
  </li>
</ul>
<h4>Los
  ganglios basales</h4>
<p>Los núcleos basales se ilustran en la Figura 3.29. Como hemos hecho
  con el sistema límbico, empecemos a examinarlos por la amígdala, que se
  considera parte de ambos sistemas.</p>
<ul>
  <li>Extendiéndose desde cada <strong>amígdala</strong> , primero en
    dirección posterior y luego en dirección anterior, se encuentra el gran
    núcleo <strong>caudado</strong> parecido a una cola (caudado significa
    «con forma de cola »).
  </li>
  <li>Cada núcleo caudado forma un círculo casi completo; en el centro,
    conectado a él por una serie de puentes de fibras, está el
    <strong>putamen</strong>. En conjunto, el caudado y el putamen, ambos
    con aspecto estriado o rayado, se conocen como el
    <strong>neoestriado</strong> («estructura estriada»).
  </li>
  <li>La otra estructura de los núcleos basales es la pálida estructura
    circular conocida como <strong>globo pálido</strong>. El globo pálido se
    sitúa en un plano medial respecto al putamen, entre el putamen y el
    tálamo.
  </li>
</ul>
<p>Los <strong>núcleos basales</strong> desempeñan un papel fundamental
  en la ejecución de las <strong>respuestas motoras voluntarias.</strong>
  Especialmente interesante es una vía que proyecta al neoestriado desde
  la sustancia negra del mesencéfalo. La enfermedad de Parkinson, un
  trastorno caracterizado por rigidez, temblores y escasez de movimientos
  voluntarios, se asocia con degeneración de esta vía.</p>
<h1>Conducción neural y
  transmisión sináptica</h1>
<p>Cuando las neuronas disparan señales liberan de sus botones
  terminales sustancias químicas, denominadas neurotransmisores, que se
  difunden a través de la hendidura sináptica (o espacio sináptico) e
  interactúan con moléculas receptoras especializadas de las membranas
  receptoras de la siguiente neurona del circuito. Al unirse las moléculas
  del neurotransmisor con los receptores postsinápticos, normalmente se
  producen uno de dos efectos, dependiendo de la estructura tanto del
  neurotransmisor como de la del receptor implicados.</p>
<ul>
  <li>Pueden <strong>despolarizar</strong> (disminuir el potencial de
    membrana en reposo -de 70 a -67 mV, por ejemplo—) o
  </li>
  <li>pueden <strong>hiperpolarizar</strong> (aumentar el potencial de
    membrana en reposo —de -70 a -72 mV, por ejemplo—) a la membrana
    receptora.
  </li>
</ul>
<p>A las despolarizaciones postsinápticas se le llama potenciales
  excitadores postsinápticos (PEPs), porque, como pronto se verá, aumentan
  la probabilidad de que la neurona descargue. Las hiperpolarizaciones
  postsinápticas se denominan potenciales inhibidores postsinápticos
  (PIPs) debido a que disminuyen la probabilidad de que la neurona
  dispare.</p>
<p>Tanto los PEPs como los PIPs son respuestas graduadas. Esto significa
  que la amplitud de los PEPs y de los PIPs es proporcional a la
  intensidad de las señales que los provocan: las señales débiles provocan
  potenciales postsinápticos reducidos y las señales fuertes provocan
  potenciales amplios. Los PEPs y los PIPs se propagan pasivamente desde
  el lugar donde se generan en las sinapsis, por lo general, las dendritas
  o el cuerpo celular, de un modo muy parecido a como lo hacen las señales
  eléctricas a través de un cable. Conforme a ello, la transmisión de
  potenciales postsinápticos tiene dos características importantes.</p>
<ul>
  <li>En primer lugar, es rápida —tan rápida que puede considerarse
    instantánea para la mayoría de sus efectos—. Es importante no confundir
    la duración de los PEPs y de los PIPs con su velocidad de transmisión:
    aunque la duración de los PEPs y los PIPs varía considerablemente, todos
    los potenciales postsinápticos, ya sean breves o duraderos, se
    transmiten a gran velocidad.
  </li>
  <li>En segundo lugar, la transmisión de los PEPs y de los PIPs es
    decreciente: la amplitud de los PEPs y los PIPs disminuye a medida que
    se transmiten a lo largo de la neurona, igual que la de una onda sonora
    va decayendo a medida que se transmite por el aire
  </li>
</ul>
<p>La importancia de los neurogliocitos en la función cerebral puede
  verse reflejada en que estas células predominan en los organismos
  inteligentes. Muchos organismos simples tienen más neuronas que células
  gliales, pero los neurogliocitos superan en número a las neuronas en el
  cerebro humano en una proporción de 10/1. ¿Resultará ser neurociencia un
  término equivocado? ¿Alguien apoya el de neurogliociencia? (¿o
  gliociencia?)</p>
<h2>Sustancias transmisoras</h2>
<p>Existen cuatro clases de neurotransmisores de molécula pequeña:</p>
<ol>
  <li>los aminoácidos,</li>
  <li>las monoaminas,</li>
  <li>los gases solubles y</li>
  <li>la acetilcolina.</li>
</ol>
<p>Además, hay una clase de neurotransmisores de molécula grande:</p>
<ol>
  <li>los neuropéptidos.</li>
</ol>
<p>La mayoría de los neurotransmisores producen ya sea excitación, ya
  inhibición; pero no ambas; no obstante unos cuantos producen excitación
  cuando se unen a algunos de sus subtipos de receptor, e inhibición
  cuando se unen a otros.</p>
<figure class="tablap no-bordes">
  <table>
    <tbody style="background: #433300">
    <tr>
      <th colspan=2>Aminoácidos</th>
      <td>
        Glutamato<br>Aspartato<br>Glicina<br>GABA
      </td>
    </tr>
    </tbody>
    <tbody style="background: #30411F">
    <tr>
      <th rowspan=2>Monoaminas</th>
      <td>Catecolaminas</td>
      <td>
        Dopamina<br>Adrenalina<br>Noradrenalina
      </td>
    </tr>
    <tr>
      <td>Indolaminas</td>
      <td>Serotonina</td>
    </tr>
    </tbody>
    <tbody style="background: #365871">
    <tr>
      <th colspan=2>Gases solubles</th>
      <td>
        Monóxido de nitrógeno<br>Monóxido de carbono
      </td>
    </tr>
    </tbody>
    <tbody style="background: #4C2928">
    <tr>
      <th colspan=2>Acetilcolina</th>
      <td>Acetilcolina</td>
    </tr>
    </tbody>
    <tbody style="background: #4C4C4C">
    <tr>
      <th rowspan=2>Neuropéptidos</th>
      <td colspan=2>Endorfinas</td>
    </tr>
    <tr>
      <td colspan=2>Otros neuropéptidos</td>
    </tr>
    </tbody>
  </table>

</figure>
<h3> Aminoácidos</h3>
<p>Los neurotransmisores de la inmensa mayoría de las sinapsis rápidas,
  dirigidas, del sistema nervioso central son aminoácidos —los «ladrillos»
  moleculares de las proteínas—. Los cuatro neurotransmisores aminoácidos
  más ampliamente reconocidos son <strong>glutamato, aspartato, glicina y
    ácido gamma-aminobutírico (GABA)</strong>. Los tres primeros se
  encuentran habitualmente en las proteínas que consumimos, mientras que
  el GABA se sintetiza a partir de una sencilla modificación de la
  estructura del glutamato.</p>
<ul>
  <li>El glutamato es el neurotransmisor <strong>excitador</strong>
    predominante en el sistema nervioso central de los mamíferos;
  </li>
  <li>el GABA es el neurotransmisor <strong>inhibidor</strong>
    predominante.
  </li>
</ul>
<h3>Monoaminas</h3>
<p>Las monoaminas son otra clase de neurotransmisores de molécula
  pequeña. Todas ellas se sintetizan a partir de un único aminoácido —de
  ahí el nombre de monoamina (una amina)—. Las monoaminas son ligeramente
  más grandes que los aminoácidos y sus efectos tienden a ser más difusos
  (véase Bunin y Wightman, 1999).</p>
<p>Las monoaminas están presentes en pequeños grupos de neuronas cuyos
  cuerpos celulares se localizan, en su gran mayoría, en <strong>el tronco
    del encéfalo</strong>. Estas neuronas suelen tener axones muy
  ramificados con muchas varicosidades (sinapsis engarzadas o con forma de
  sarta de cuentas), desde las que se liberan de forma difusa las
  monoaminas al líquido extracelular.</p>
<p>Existen cuatro monoaminas transmisoras:</p>
<ul>
  <li>dopamina,</li>
  <li>adrenalina,</li>
  <li>noradrenalina y
  </li>
  <li>serotonina.</li>
</ul>
<p>Se subdividen en dos grupos en función de su estructura:</p>
<ol>
  <li>catecolaminas e</li>
  <li>indolaminas.</li>
</ol>
<p>La dopamina, la noradrenalina y la adrenalina son catecolaminas. Se
  sintetizan a partir del aminoácido tirosina.</p>
<p>La tirosina se convierte en L-dopa, que a su vez se convierte en
  dopamina. Las neuronas que liberan noradrenalina poseen una enzima
  adicional (una que no está presente en las neuronas dopaminérgicas), la
  cual convierte en ellas la dopamina en noradrenalina. De un modo
  similar, las neuronas que liberan adrenalina tienen todas las enzimas
  que se encuentran en las neuronas que liberan noradrenalina, junto con
  una enzima adicional, que convierte la noradrenalina en adrenalina
  (véase la Figura 4.14). A diferencia de las otras monoaminas, la
  serotonina (también llamada 5-hidroxitriptamina o 5-HT) se sintetiza a
  partir del aminoácido triptófano y se cataloga como indolamina. Las
  neuronas que liberan noradrenalina reciben el nombre de noradrenérgicas;
  las que liberan adrenalina, adrenérgicas.</p>
<h3>Gases solubles</h3>
<p>Otra clase de neurotransmisores de moléculas pequeña, los gases
  solubles, incluye al</p>
<ul>
  <li>monóxido de nitrógeno [u óxido nítrico (NO)] y al</li>
  <li>monóxido de carbono.</li>
</ul>
<p>Los gases solubles no actúan como los demás neurotransmisores
  (Boehning y Snyder, 2003). Se producen en el citoplasma neuronal; y tras
  ser producidos se difunden inmediatamente a través de la membrana
  celular al líquido extracelular y luego a las células vecinas. Los gases
  solubles atraviesan fácilmente la membrana celular ya que son
  liposolubles. Una vez que se encuentran en otras células, estimulan la
  producción de un segundo mensajero, y en pocos segundos son inactivados
  y convertidos en otras moléculas. Estudiarlos es difícil, puesto que
  sólo duran un par de segundos.</p>
<p>Se ha demostrado que los gases solubles transmisores están
  <strong>implicados en la transmisión retrógrada</strong>. Es decir, en
  algunas sinapsis, el monóxido de nítrógeno transmite señales de
  retroalimentación, de vuelta desde la neurona postsináptica a la neurona
  presináptica (Ludwig y Pittman, 2003). Se ha comprobado que otros
  neurotransmisores se valen de transmisión retrógrada, pero parece ser
  que esto es menos frecuente (Blakely, 2001; Falkenburger, Barstow y
  Mintz, 2001).</p>
<h3>Acetilcolina</h3>
<p>La acetilcolina (cuya abreviatura es ACh) consiste en un
  neurotransmisor de molécula pequeña que se parece en algo importante a
  un profesor que llega tarde a clase: representa por sí mismo una
  categoría. Se origina al añadirse un grupo acetilo a una molécula de
  colina. La acetilcolina es el neurotransmisor que actúa en</p>
<ul>
  <li>las uniones neuromusculares,</li>
  <li>en muchas de las sinapsis del sistema nervioso neurovegetativo
    y
  </li>
  <li>en sinapsis de diversas partes del sistema nervioso central.</li>
</ul>
<p>Como se ha visto en el apartado anterior, la enzima
  acetilcolinesterasa degrada la acetilcolina a nivel sináptico.</p>
<p>A las neuronas que liberan acetilcolina se les llama <strong>neuronas
  colinérgicas.</strong></p>
<h3>Neuropéptidos</h3>
<p>Se denomina neuropéptidos a los péptidos que desempeñan un papel en
  la neurotransmisión. Se han identificado cerca de 100 (Greengard, 2001).
  Entre los neuropéptidos más interesantes figuran las
  <strong>endorfinas</strong> (véase Stefano et al., 2000); las endorfinas
  son opiáceos endógenos (sustancias químicas similares al opio que se
  producen en el organismo). La existencia de endorfinas se sospechó
  inicialmente partir del descubrimiento de que los opiáceos (p.ej., el
  opio, la morfina y la heroína) se unen a receptores del encéfalo;
  probablemente, no habría receptores en el encéfalo para sustancias que
  no produjera el propio organismo. Esta sospecha se confirmó
  posteriormente mediante el descubrimiento de la existencia de varias
  endorfinas diferentes y de varios subtipos diferentes del receptor de
  las endorfinas. Las endorfinas activan sistemas neurales que producen
  analgesia (supresión del dolor) y sistemas neuronales que median la
  sensación de placer. Es de suponer que estos efectos son la razón de que
  los opiáceos sean tan adictivos.</p>
<h2>Psicofármacos: cinco ejemplos</h2>
<p>En capítulos posteriores el lector se topará con muchos
  psicofármacos, sus efectos psicológicos y sus mecanismos de acción. He
  aquí cinco ejemplos para terminar esta sección: dos agonistas, la
  cocaína y las benzodiacepinas; y tres antagonistas, la atropina, el
  curare y el Botox).</p>
<h3>Cocaína</h3>
<p>La cocaína es un potente agonista de las catecolaminas, muy adictivo.
  Aumenta la actividad tanto de la dopamina como de la noradrenalina al
  impedir que sea recaptada de la sinapsis e ingresada en el botón
  presináptico. Conforme a ello, cuando los niveles de cocaína en el
  encéfalo son altos, una vez que se han liberado en la sinapsis las
  moléculas de dopamina y noradrenalina éstas siguen activando los
  receptores postsinápticos debido a que su medio principal de
  inactivación ha sido bloqueado. Esto origina una serie de efectos
  psicológicos, entre ellos euforia, pérdida de apetito e insomnio.
  También explica la capacidad de la cocaína para provocar adicción.</p>
<h3>Benzodiacepinas</h3>
<p>El clordiacepóxido (comercializado con el nombre de Librium) y el
  diacepam (comercializado con el nombre de Valium) forman parte de un
  tipo de fármacos designados benzodiacepinas.</p>
<p>Las benzodiacepinas tienen efectos ansiolíticos (reducen la
  ansiedad), sedantes (inducen el sueño) y anticonvulsivos. Parece ser que
  ejercen sus efectos ansiolíticos actuando como agonistas del GABA. Las
  benzodiacepinas se unen a un subtipo de receptor del GABA, el receptor
  ionotrópico GABAA (véase Macdonald y Olsen, 1994), pero no ejercen su
  efecto agonista mimetizando las acciones del GABA. Las moléculas de
  benzodiacepina no se fijan al receptor GABAA en el mismo lugar en que lo
  hacen las moléculas de GABA. En vez de ello, se ligan a otra parte de la
  molécula; al hacer esto, aumentan la fijación de las moléculas de GABA
  al receptor, incrementando así los efectos inhibidores del GABA al
  aumentar la entrada de iones Cl- e hiperpolarizar a la neurona.</p>
<h3>Atropina</h3>
<p>Muchos de los fármacos que se utilizan en investigación y en medicina
  son extractos de plantas que se han utilizado desde hace tiempo con
  fines médicos y recreativos. Por ejemplo, en la época de Hipócrates los
  griegos consumían extractos de la planta de belladona para tratar
  dolencias estomacales y para estar más atractivos. Las mujeres griegas
  pensaban que sus efectos dilatadores de la pupila realzaban su belleza
  (belladona significa «mujer hermosa»).</p>
<p>La atropina es el ingrediente activo de la belladona. Es un
  bloqueante de receptor que ejerce su efecto antagonista uniéndose a un
  subtipo de receptores metabotrópicos de la acetilcolina, llamados
  receptores muscarínicos; con lo que impide que la acetilcolina ejerza
  sus efectos sobre ellos. Muchos receptores muscarínicos se localizan en
  el encéfalo; el efecto perjudicial de las dosis altas de atropina sobre
  la memoria fue uno de los primeros indicios de que en la memoria están
  implicados mecanismos colinérgicos.</p>
<h3>Curare</h3>
<p>Los indios de América del Sur han utilizado durante mucho tiempo el
  curare —extracto de una determinada clase de enredadera leñosa— para
  matar a los animales que cazan y, en ocasiones, a sus enemigos. Al igual
  que la atropina, el curare es un bloqueante del receptor en las sinapsis
  colinérgicas, si bien actúa sobre un subtipo diferente de receptores de
  acetilcolina: un subtipo ionotrópico, denominado receptor nicotínico. Al
  unirse a receptores nicotínicos, el curare bloquea la transmisión en las
  uniones neuromusculares, paralizando así a quienes lo reciben y
  matándolos, al impedir la respiración.</p>
<p>Puede entonces que el lector se sorprenda al saber que a veces se
  utiliza el ingrediente activo del curare en pacientes humanos durante
  intervenciones quirúrgicas, con el fin de asegurarse de que sus músculos
  no se contraigan al hacerles una incisión. Cuando se utiliza el curare
  con este fin, la respiración del paciente debe mantenerse
  artificialmente mediante un respirador.</p>
<h3>Botox</h3>
<p>El botox (abreviatura de toxina botulínica), una neurotoxina liberada
  por una bacteria que se encuentra a menudo en los alimentos que no se
  han conserva do bien, es también un antagonista nicotínico: bloquea la
  liberación de acetilcolina en la unión neuromuscular y es, por lo tanto,
  un veneno mortal. No obstante, tiene una aplicación en medicina si se
  inyecta en dosis ínfimas (p.ej., reduce el temblor) y en estética
  (p.ej., reduce las arrugas).</p>
<h1>Métodos de
  investigación en biopsicología</h1>
<p>Las bases fisiológicas de los cambios en la conductibilidad de la
  piel no se conocen por completo, pero existen muchas pruebas que
  implican a las glándulas sudoríparas (véase Boucsein, 1992). Aunque la
  principal función de estas glándulas es enfriar el cuerpo, tienden a
  activarse en caso de emoción. Las glándulas sudoríparas se distribuyen
  por la mayor parte de la superficie corporal; pero, como el lector está
  casi totalmente seguro, las más sensibles a los estímulos emocionales
  son las de las manos, los pies, las axilas y la frente.</p>
<p>Si se piensa que todas las lesiones calificadas de «lesiones de
  amígdala» no conllevan daños a otras estructuras cerebrales, podrían
  atribuirse erróneamente a la lesión de la amígdala todos los efectos
  comportamentales observados. A la inversa, si se piensa que todas las
  lesiones calificadas de «lesiones de amígdala» afectan a la totalidad de
  la amígdala, se podría concluir erróneamente que la amígdala no está
  implicada en los comportamientos en los que no ha influido la
  lesión.</p>
<h2>Lateralización del lenguaje</h2>
<p>Es habitual que uno de los hemisferios cerebrales participe más que
  el otro en las actividades relacionadas con el lenguaje. En la mayoría
  de las personas, el hemisferio izquierdo es el dominante en el lenguaje,
  pero en algunas el dominante es el derecho. A menudo se incluye una
  prueba de lateralización del lenguaje en la batería habitual de pruebas
  ya que a menudo resulta útil saber cuál es el hemisferio dominante en el
  lenguaje al interpretar los resultados de otras pruebas. Es más, a los
  pacientes se les aplica prácticamente siempre una prueba de
  lateralización del lenguaje antes de cualquier intervención quirúrgica
  que pueda afectar a las áreas corticales del lenguaje. Los resultados se
  utilizan para planificar la cirugía, tratando de evitar en la medida de
  lo posible las áreas del lenguaje.</p>
<p>Kimura descubrió que los sujetos decían correctamente una mayor
  cantidad de dígitos escuchados por el oído contralateral a su hemisferio
  dominante en el lenguaje, según se había determinado mediante la prueba
  del amital sódico.</p>
<h2>Aversión condicionada al
  gusto</h2>
<p>Una aversión condicionada al gusto es la respuesta que se instaura al
  sabor de alimentos a cuyo consumo sigue una enfermedad (véase García y
  Koelling, 1966). En el caso típico del experimento de aversión
  condicionada al gusto, las ratas reciben un vomitivo (un fármaco que
  induce náuseas) después de haber consumido un alimento de sabor
  desconocido. A partir de este único ensayo de condicionamiento, las
  ratas aprenden a evitar el sabor.</p>
<p>En primer lugar, puso en tela de juicio el punto de vista de que el
  condicionamiento animal es siempre un proceso gradual que se da paso a
  paso: se pueden establecer intensas aversiones condicionadas al gusto
  con un único ensayo. En segundo lugar, demostró que la contigüidad
  temporal no es imprescindible para el condicionamiento: las ratas
  adquieren aversiones al gusto aun cuando no enfermen hasta varias horas
  después de haber comido. En tercer lugar, puso a prueba el principio de
  equipotencialidad —la idea de que el condicionamiento opera básicamente
  de la misma manera, independientemente de los estímulos y las respuestas
  concretos que se investigan—. Parece ser que las ratas han evolucionado
  para aprender con facilidad asociaciones entre sabores y enfermedades;
  les cuesta mucho aprender a relacionar el color de la comida con las
  náuseas, o el sabor con una descarga eléctrica en las patas.</p>
<h1>El sistema visual</h1>
<p>La luz se define a veces como ondas de energía electromagnética
  comprendidas entre longitudes de onda de 380 a 760 nanómetros (la mil
  millonésima parte de un metro) (véase la Figura 6.2). Estas longitudes
  de onda no tienen nada de especial, excepto que el sistema visual
  responde a ellas.</p>
<h2>Papila óptica</h2>
<p>Luego, una vez que los receptores han sido activados, la señal neural
  se transmite de vuelta a través de las capas de la retina hasta las
  células ganglionares retinianas, cuyos axones se proyectan cruzando el
  interior de la retina antes de reunirse formando un haz y salir del
  globo ocular. Esta disposición invertida genera dos problemas visuales.
  Uno es que la luz que incide es distorsionada por el tejido de la retina
  que tiene que atravesar antes de alcanzar los receptores. El otro es que
  para que el haz de axones de células ganglionares retinianas pueda
  abandonar el ojo ha de haber una abertura en la capa de receptores; esta
  abertura se llama <strong>papila óptica</strong> [también conocida como
  «punto ciego»].</p>
<h2>Conclusión visual</h2>
<p>En esta demostración el lector experimentará la conclusión visual. El
  sistema visual utiliza la información proporcionada por los receptores
  que rodean a la papila óptica para completar los vacíos en las imágenes
  retinianas. Cuando el sistema visual detecta una barra recta que entra
  por un lado de la papila óptica y otra barra recta que sale por el otro
  lado, completa para nosotros el trozo que falta; y lo que vemos es una
  barra recta continua, independientemente de lo que haya en realidad. El
  fenómeno de conclusión es una de las demostraciones más convincentes de
  que el sistema visual hace mucho más que crear una copia fidedigna del
  mundo exterior.</p>
<p>Es un error pensar que la <strong>conclusión visual</strong> no es
  más que una respuesta a las papilas ópticas (véase Ramachandran, 1992;
  Spillman y Werner, 1996). De hecho, la conclusión es un aspecto
  fundamental de la función del sistema visual. Cuando se mira un objeto,
  el sistema visual no transmite una imagen de dicho objeto desde la
  retina a la corteza. En vez de ello, extrae la información clave acerca
  del objeto —básicamente, información sobre sus contornos y su situación—
  y transmite esa información a la corteza, donde se crea una percepción
  del objeto íntegro a partir de información parcial. Por ejemplo, el
  color y la luminosidad de las grandes superficies lisas no se perciben
  directamente, sino que se completan (concluyen) mediante un proceso de
  conclusión, en este caso denominado interpolación de superficie.</p>
<h2>Imágenes estabilizadas</h2>
<p>¿Por qué desaparecen las imágenes estabilizadas? La respuesta se basa
  en que las neuronas del sistema visual responden más a los cambios que a
  una entrada constante de información. La mayoría de las neuronas del
  sistema visual responden enérgicamente cuando un estímulo aparece, se
  mueve o finaliza; pero responden sólo débilmente a un estímulo continuo,
  sin cambios. Al parecer, una de las funciones de los movimientos
  oculares es mantener la imagen retiniana moviéndose hacia delante y
  atrás de un lado a otro de los receptores, asegurando así que los
  receptores y las neuronas con las que están conectados reciban un patrón
  de estimulación que cambia constantemente. Cuando una imagen retiniana
  se estabiliza, partes del sistema visual dejan de responder a la imagen,
  y ésta desaparece.</p>
<h2>Constancia del color</h2>
<p>La constancia del color se refiere al hecho de que el color que se
  percibe de un objeto no es simplemente una función de las longitudes de
  onda que refleja.</p>
<p>Aunque el fenómeno de la constancia del color va en contra de lo que
  pudiera intuirse, su ventaja es obvia. La constancia del color mejora
  nuestra capacidad para distinguir unos objetos de otros de modo que
  podamos recordarlos, y así podamos responder adecuadamente a ellos;
  nuestra capacidad para reconocer objetos se vería gravemente afectada si
  el color cambiara cada vez que lo hiciese la iluminación. En esencia, si
  no hubiera constancia de color, la visión cromática tendría escaso valor
  de supervivencia. Aunque la constancia del color es un aspecto
  importante de nuestra visión, normalmente no somos conscientes de ello.
  En condiciones cotidianas no tenemos modo alguno de apreciar exactamente
  en qué medida pueden variar las longitudes de onda reflejadas por un
  objeto sin que cambie su color. Únicamente bajo las condiciones
  controladas de un laboratorio se puede apreciar por completo que la
  constancia del color es algo más que un factor importante en la visión
  cromática: es la esencia de la visión cromática.</p>
<h2>Proceso creativo de la
  visión</h2>
<p>Uno de los principales objetivos de este capítulo era ayudar al
  lector a entender que la visión es un proceso creativo. El sistema
  retino-genículo-estriado no transmite imágenes visuales intactas a la
  corteza. Transmite información sobre unas cuantas características claves
  del campo visual — por ejemplo, información sobre localización,
  movimiento contraste de luminosidad y contraste de color—y a partir de
  estos bitios (bits) de información crea una percepción que es mejor que
  la imagen retiniana en todos los aspectos y mejor que la realidad
  externa en algunos. Podría decirse que el estudio del sistema visual es
  el mejor ejemplo de cómo se emplean las operaciones convergentes en
  biopsicología —de la convergencia de la investigación neuroanatómica,
  neuroquímica, neurofisiológica y comportamental han derivado
  conocimientos significativos acerca de las bases neurales de los
  procesos psicológicos—.</p>
<h1>Mecanismos
  de la percepción, la consciencia y la atención</h1>
<h2>Organización jerárquica</h2>
<p>Los
  sistemas sensitivos se caracterizan por una organización jerárquica. Una
  jerarquía es un sistema cuyos miembros pueden ser asignados a niveles o
  rangos específicos los unos respecto de los otros.</p>
<p>La organización jerárquica de los sistemas sensitivos resulta
  evidente cuando se comparan los efectos de lesiones a distintos niveles:
  cuanto más alto es el nivel de la lesión, más específica y compleja es
  la alteración. Por ejemplo, la destrucción de los receptores de un
  sistema sensitivo produce una pérdida completa de la capacidad de
  percibir mediante ese sistema sensitivo (p.ej., ceguera o sordera
  total); por el contrario, la destrucción de un área de la corteza de
  asociación o de la corteza secundaria sensitiva produce alteraciones
  sensitivas complejas y específicas, mientras que las capacidades
  sensitivas básicas permanecen inalteradas. El Dr.P., el hombre que
  confundió a su mujer con un sombrero (Sacks, 1985), presentaba uno de
  estos tipos de alteraciones.</p>
<p>Los psicólogos, reconociendo la organización jerárquica de los
  sistemas sensitivos, a veces dividen el proceso general de la percepción
  en dos fases generales: sensación y percepción.</p>
<ul>
  <li>La <strong>sensación</strong> es el proceso de detectar la presencia
    de estímulos, y
  </li>
  <li>la <strong>percepción</strong> es el proceso de nivel superior que
    incluye integrar, reconocer e interpretar modelos completos de
    sensaciones.
  </li>
</ul>
<h2>Separación funcional</h2>
<p>Al principio se suponía que las áreas primarias, secundarias y de
  asociación de un sistema sensitivo eran todas ellas funcionalmente
  homogéneas. Esto es, se daba por hecho que todas las áreas de la corteza
  de cualquier nivel de la jerarquía sensitiva actuaban conjuntamente para
  llevar a cabo la misma función. Sin embargo, las investigaciones han
  demostrado que es la <strong>separación funcional</strong> , en vez de
  la homogeneidad funcional, lo que caracteriza la organización de los
  sistemas sensitivos.</p>
<p>Ahora está claro que cada uno de los tres niveles de la corteza
  cerebral —primario, secundario y de asociación— de cada sistema
  sensitivo contiene varias áreas funcionalmente distintas, que están
  especializadas en distintos tipos de análisis.</p>
<h2>Procesamiento paralelo</h2>
<p>Sin embargo, en la actualidad hay pruebas de que los sistemas
  sensitivos son sistemas paralelos —sistemas en los que la información
  fluye a través de los componentes por múltiples vías—. Los sistemas
  paralelos se caracterizan por un procesamiento paralelo —análisis
  simultáneo de una señal, de diferente modo, por las múltiples vías
  paralelas de una red neural—. Parece haber dos tipos fundamentalmente
  distintos de corrientes paralelas de análisis en nuestros sistemas
  sensitivos:</p>
<ul>
  <li>una capaz de influir en nuestra conducta sin que seamos conscientes
    de ello, y
  </li>
  <li>otra que influye en ella implicando nuestra percepción
    consciente.
  </li>
</ul>
<h2>Modelo
  actual de la organización del sistema sensitivo</h2>
<p>Los sistemas sensitivos se caracterizan porque en ellos se divide el
  trabajo:</p>
<ul>
  <li>constan de múltiples áreas especializadas,</li>
  <li>a múltiples niveles,</li>
  <li>interconectadas por múltiples vías paralelas.</li>
</ul>
<p>Aun así, los estímulos complejos normalmente se perciben como un todo
  integrado, no como una combinación de atributos independientes. ¿Cómo
  combina el cerebro atributos Sensitivos individuales para producir una
  percepción integrada? Esto se conoce como el <strong>problema de la
    integración</strong> (Bernstein y Robertson, 1998; De Gelder, 2000;
  Friedman-Hill, Robertson y Treisman, 1995).</p>
<p>Una solución posible del problema de la integración es que exista una
  única área en la corteza en el nivel superior de la jerarquía sensitiva
  que reciba señales de todas las demás áreas del sistema sensitivo y las
  reúna para formar percepciones. Sin embargo, no hay un área de la
  corteza a la cual envíen información todas las áreas de un solo sistema
  sensitivo. Parece ser, pues, que las percepciones han de ser el
  resultado de la actividad combinada de muchas áreas corticales
  interconectadas.</p>
<p>Por ejemplo, se denominan vías <strong>corticofugales</strong> a
  grupos de neuronas que conducen información desde áreas sensitivas
  corticales a áreas subcorticales. Las vías corticofugales son uno de los
  medios por los que los procesos cognitivos, tales como la atención,
  pueden influir en la percepción —esto se llama <strong>influencia de
    arriba abajo</strong> (véase Engel, Fries y Singer, 2001; Gao y Suga,
  2000)—.</p>
<h1>Mecanismos corticales de la
  visión</h1>
<p>Los
  seres humanos somos animales visuales. Intervienen en la visión la
  totalidad de la corteza occipital así como amplias regiones de la
  corteza temporal y la parietal (véase la Figura 7.3). La corteza visual
  primaria se localiza en la región posterior de los lóbulos occipitales,
  gran parte de ella oculta tras la cisura longitudinal.</p>
<p>Las áreas de corteza visual secundaria se sitúan en dos regiones
  generales: la corteza preestriada y la corteza inferotemporal.</p>
<ul>
  <li>La corteza preestriada es la banda de tejido del lóbulo occipital
    que rodea a la corteza visual primaria.
  </li>
  <li>La corteza inferotemporal es la corteza de la región inferior del
    lóbulo temporal.
  </li>
  <li>En varias partes de la corteza cerebral se encuentran áreas de
    corteza asociativa que reciben input visual, pero el área más amplia
    está en la corteza parietal posterior.
  </li>
</ul>
<p>Conforme a la organización jerárquica general de la corteza
  sensitiva, el principal flujo de información visual va desde la corteza
  visual primaria hasta diversas áreas de la corteza visual secundaria y
  de ahí a áreas de la corteza de asociación. A medida que se asciende por
  esta jerarquía visual, los campos receptores de las neuronas son más
  grandes, y los estímulos a los que responden las neuronas son más
  específicos y complejos (véase Zeki, 1993b).</p>
<h2>Escotomas: visión ciega</h2>
<p>La visión ciega es otro fenómeno que presentan los pacientes con
  escotomas debidos a una lesión en la corteza visual primaria. La visión
  ciega es la capacidad que tienen tales pacientes de responder a
  estímulos visuales que inciden en sus escotomas, aun cuando no son
  conscientes de los estímulos (Weiskrantz, 2004). De todas las
  capacidades visuales, la percepción del movimiento es la que tiene más
  probabilidad de persistir tras un daño de la corteza visual primaria
  (Intriligator, Xie y Barton, 2002). Por ejemplo, un sujeto puede
  extender el brazo y alcanzar un objeto que se mueva en su escotoma, aun
  cuando asegura no verlo.</p>
<h2>La
  corriente dorsal y ventral</h2>
<p>La corriente dorsal fluye desde la corteza visual primaria a la
  corteza preestriada dorsal, y de ahí a la corteza parietal posterior. La
  corriente ventral fluye desde la corteza visual primaria a la corteza
  preestriada ventral y de ahí a la corteza inferotemporal (véase la
  Figura 7.9). Ungerleider y Mishkin (1982) propusieron que las corrientes
  visuales dorsal y ventral realizan funciones visuales diferentes.
  Sugirieron que</p>
<ul>
  <li>la corriente <strong>dorsal</strong> está implicada en la percepción
    de «dónde» se localizan los objetos, y
  </li>
  <li>la corriente <strong>ventral</strong> lo está en la percepción de
    «qué» son los objetos.
  </li>
</ul>
<p>El mayor respaldo de la teoría del «control del comportamiento»
  frente a la «percepción consciente» es la confirmación de sus dos
  premisas básicas:</p>
<ol>
  <li>que algunos pacientes con lesiones bilaterales que afectan a la
    corriente ventral no tienen una experiencia consciente de ver y, aun
    así, pueden interaccionar con los objetos bajo guía visual, y
  </li>
  <li>que algunos pacientes con lesiones bilaterales de la corriente
    dorsal pueden ver objetos de manera consciente, pero no son capaces de
    interactuar con ellos bajo orientación visual. A continuación se
    describen dos de estos casos.
  </li>
</ol>
<h1>El oído</h1>
<p>Esto
  nos lleva al principal misterio sin resolver del procesamiento auditivo.
  Imagínese el lector en un ambiente acústico complejo, como una fiesta.
  La música está sonando, la gente baila, come y bebe, y se mantienen
  numerosas conversaciones en torno suyo. Dado que las frecuencias
  componentes de cada sonido individual activan muchos puntos a lo largo
  de su membrana basilar, la cantidad de puntos activados simultáneamente
  en un momento dado por los ruidos de la fiesta es enorme. Pero de alguna
  forma su sistema auditivo se las arregla para clasificar estos mensajes
  de frecuencia individuales en categorías por separado y combinarlas, de
  modo que usted oiga cada fuente de sonidos complejos independientemente
  (véase Feng y Ratnam, 2000). Por ejemplo, usted oye la conversación de
  la persona que está cerca suyo como una secuencia de sonidos por
  separado, pese a que contiene muchas de las mismas frecuencias
  componentes procedentes de otras fuentes.</p>
<p>Así pues, parece ser que la función general de los tubérculos
  cuadrigéminos superiores es localizar el origen del input sensorial en
  el espacio. Sorprendentemente, las lesiones bilaterales totales de la
  corteza auditiva primaria en mamíferos de laboratorio no producen
  alteraciones permanentes en su capacidad para detectar la presencia de
  sonidos.</p>
<h1>Somatestesia: tacto y dolor</h1>
<p>Sin duda el lector ha experimentado una amplia variedad de
  sensaciones que emanan de su cuerpo. Éstas se conocen por lo general
  como somatestesia. El sistema que media estas sensaciones corporales —el
  sistema somatosensitivo— consiste de hecho en tres sistemas distintos
  aunque relacionados:</p>
<ol>
  <li>un sistema de <strong>exterosensibilidad</strong> [a veces designado
    exteroceptivo], que detecta los estímulos externos aplicados a la
    piel;
  </li>
  <li>un sistema de <strong>propiosensibilidad</strong> [o propioceptivo],
    el cual registra la información concerniente a la posición del cuerpo
    que proviene de los músculos, articulaciones y órganos del equilibrio,
    y
  </li>
  <li>un sistema de <strong>interosensibilidad</strong> [o interoceptivo]
    (véase Craig, 2002), que proporciona información general sobre el estado
    en el interior del cuerpo (p.ej., temperatura y tensión arterial). Esta
    exposición trata casi exclusivamente del sistema de exterosensibilidad,
    el cual abarca tres divisiones algo distintas: una para percibir
    estímulos mecánicos (tacto), otra para estímulos térmicos (temperatura)
    y otra para estímulos dolorosos (dolor).
  </li>
</ol>
<p>La mayor parte de las neuronas del núcleo ventral posterior se
  proyectan a la corteza somatosensitiva primaria (SI); otras se proyectan
  a la corteza somatosensitiva secundaria (SII) o
  a la
  corteza parietal posteriol.</p>
<h2>Efectos
  del daño de la corteza somatosensitiva primaria</h2>
<p>Como ocurre con los efectos del daño de la corteza auditiva, los
  efectos del daño de la corteza somatosensitiva primaria suelen ser
  sorprendentemente moderados. Corkin, Milner y Rasmussen (1970) evaluaron
  las capacidades somatosensitivas de pacientes con epilepsia antes y
  después de una ablación unilateral que incluía a SI. Tras la
  intervención, los pacientes manifestaron dos alteraciones
  contralaterales leves: una disminución de la capacidad para detectar un
  roce suave y una disminución de la capacidad para reconocer los objetos
  mediante el tacto (esto es, una deficiente estereognosia). Estas
  anomalías eran bilaterales sólo en los casos en los que la lesión
  unilateral invadía SII.</p>
<h2>Agnosias somatosensitivas</h2>
<p>Existen dos tipos principales de agnosia somatosensitiva. Una de
  ellas es la estereoagnosia (incapacidad para reconocer los objetos por
  el tacto). Los casos de estereognosia pura —los que tienen lugar sin que
  haya anomalías sensitivas simples— son poco frecuentes (Corkin, Milner y
  Rasmussen, 1970). El otro tipo de agnosia somatosensitiva es la
  somatoagnosia [o autotopoagnosia], la incapacidad para reconocer las
  partes del propio cuerpo. La somatoagnosia habitualmente es unilateral:
  afecta sólo al lado izquierdo del cuerpo, y suele asociarse a lesiones
  extensas del lóbulo parietal posterior derecho.</p>
<h2>Las paradojas del dolor</h2>
<p>Una paradoja es una contradicción lógica. La percepción del dolor es
  paradójica en tres aspectos importantes, razón por la cual se ha
  escogido el dolor para estudiarlo particularmente.</p>
<ol>
  <li><strong>El potencial de adaptación del dolor:</strong> Una de las
    paradojas del dolor es que una experiencia que en todos los aspectos
    parece ser tan mala, de hecho es extremadamente importante para nuestra
    supervivencia. Para el dolor no existe un estímulo especial; es una
    respuesta ante una estimulación (potencialmente dañina) excesiva de
    cualquier tipo (véase Craig, 2003).
  </li>
  <li><strong>Ausencia de representación cortical evidente del
    dolor</strong> : La segunda paradoja del dolor es que no tiene una
    representación cortical obvia (Rainville, 2002). Los estímulos dolorosos
    por lo general activan áreas de la corteza, pero las áreas de activación
    han variado marcadamente de un estudio a otro (Apkarian, 1995). Los
    estímulos dolorosos habitualmente inducen respuestas en SI y SII. Sin
    embargo, la ablación de SI y SII en seres humanos no se asocia con
    cambio alguno en el umbral del dolor. De hecho, los pacientes
    hemisferotomizados (aquellos a los que se les ha extirpado uno de los
    hemisferios cerebrales) pueden seguir percibiendo dolor procedente de
    ambos lados del cuerpo. El área cortical que se ha relacionado más
    frecuentemente con la experiencia de dolor es la corteza cingulada
    anterior (la corteza de la región anterior de la circunvolución del
    cíngulo; (véase la Figura 7.21). La evidencia sugiere que la corteza
    cingulada anterior participa en la reacción emocional al dolor más que
    en la percepción del dolor en sí misma (Panksepp, 2003; Price, 2000).
    Por ejemplo, la lobulotomía prefrontal, que daña la corteza cingulada
    anterior y sus conexiones, reduce por lo general la reacción emocional
    al dolor sin variar el umbral del dolor.
  </li>
  <li><strong>Control descendente del dolor</strong> : La tercera paradoja
    del dolor es que siendo la forma más contundente de todas las
    experiencias sensoriales pueda suprimirse tan eficazmente mediante
    factores cognitivos y emocionales. Por ejemplo, hombres que participan
    en una determinada ceremonia religiosa se balancean colgados de una
    cuerda enganchada a la espalda por medio de un gancho de colgar carne,
    con pocos signos de dolor; heridas graves sufridas por soldados en
    batalla se asocian a menudo con escaso dolor; y personas heridas durante
    una situación vital amenazante no suelen sentir dolor hasta que ha
    pasado el peligro. Melzack y Wall (1965) propusieron la teoría de la
    puerta de control para explicar la capacidad de los factores cognitivos
    y emocionales de bloquear el dolor. Postularon que las señales que
    descienden del encéfalo pueden activar circuitos neurales de compuerta
    de la médula espinal para bloquear las señales de dolor aferentes.
  </li>
</ol>
<h1>Sentidos químicos: Olfato y
  gusto</h1>
<p>Melzack y Wall (1965) propusieron la teoría de la puerta de control
  para explicar la capacidad de los factores cognitivos y emocionales de
  bloquear el dolor. Postularon que las señales que descienden del
  encéfalo pueden activar circuitos neurales de compuerta de la médula
  espinal para bloquear las señales de dolor aferentes.</p>
<p>Posiblemente, el aspecto más interesante de los sentidos químicos es
  el papel que representan en el comportamiento social de muchas especies
  (véase, p.ej., DeCatanzaro, et al., 2000; Luo, Fee y Katz, 2003). Los
  miembros de muchas especies liberan feromonas —sustancias químicas que
  influyen en la fisiología y el comportamiento de los congéneres
  (miembros de una misma especie)—. Por ejemplo, Murphy y Schneider (1970)
  demostraron que la conducta sexual y la agresiva del hámster están
  controladas por las feromonas. El hámster macho normal ataca y mata a
  los machos desconocidos que se introducen en su colonia, mientras que
  montan y fecundan a las hembras desconocidas sexualmente receptivas.</p>
<p>Otra particularidad de los sentidos químicos que ha atraído la
  atención es el hecho de que intervienen en algunas formas de
  aprendizaje. Como se aprendió en el Capítulo 5, los animales que sufren
  problemas gastrointestinales tras haber ingerido un alimento determinado
  adquieren una aversión condicionada a ese gusto. A la inversa, se ha
  comprobado que las ratas manifiestan preferencias por los sabores que
  encontraban en la leche materna o en el aliento de sus congéneres
  (Galef, 1989). Y que las ratas macho adultas que fueron criadas al nacer
  por hembras que olían a limón copulaban más vigorosamente con ratas que
  oliesen a limón (Fillion y Blass, 1986 —fenómeno que acertadamente se ha
  denominado quiero una chica que sea justo como la que se casó con mi
  viejo papá (Diamond, 1986)—.</p>
<h2>Sistema
  olfativo</h2>
<p>Se han identificado aproximadamente un millar de tipos de receptores
  acoplados a proteínas, cada uno sensible a diferentes olores (véase
  Gibson y Garbers, 2000). En los mamíferos, cada célula receptora
  olfativa contiene un tipo de molécula proteica receptora (Serizawa et
  al., 2003). A esto se alude como la regla de un receptor olfativo-una
  neurona (Lewcock y Reed, 2003). Los investigadores han intentado
  descubrir el principio funcional por el cual los diversos receptores se
  distribuyen en la mucosa olfativa. Si tal principio existe, todavía no
  se ha descubierto. Parece ser que cada tipo de receptor está disperso
  por toda la mucosa, lo que no aporta indicios sobre la organización del
  sistema.</p>
<p>Las células receptoras olfativas difieren de las células receptoras
  de otros sistemas sensitivos en algo importante. A lo largo de la vida
  de cada individuo se originan nuevos receptores olfativos para
  reemplazar a los que se han deteriorado (Doty, 2001). Una vez creados,
  la nueva célula receptora desarrolla axones, los cuales crecen hasta que
  alcanzan el punto apropiado en el bulbo olfativo. Cada cintilla olfativa
  proyecta a varias estructuras del lóbulo temporal medial, incluyendo la
  amígdala y la corteza piriforme —un área de la corteza temporal medial
  adyacente a la amígdala—. La corteza piriforme se considera corteza
  olfativa primaria. El sistema olfativo es el único sistema sensitivo
  cuyas vías sensitivas principales llegan a la corteza cerebral sin pasar
  antes por el tálamo.</p>
<p>Se
  piensa que la proyección límbica media la respuesta emocional a los
  olores y que la proyección talámica-orbitofrontal interviene en su
  percepción consciente. Poco se sabe acerca de cómo las neuronas que
  responden a diferentes olores se organizan en la corteza (véase Savic.
  2002).</p>
<h2>Sistema gustativo</h2>
<p>Los receptores del gusto se encuentran en la lengua y en partes de la
  cavidad bucal; suelen hallarse en grupos de unos cincuenta formando
  botones gustativos. En la superficie de la lengua, los botones
  gustativos con frecuencia se sitúan alrededor de pequeños abultamientos,
  llamados papilas. La relación entre los receptores gustativos, los
  botones gustativos y las papilas, se ilustra en la Figura 7.24 (véase
  Gilbertson, Damak y Margolskee, 2000). A diferencia de los receptores
  olfativos, los receptores del gusto no poseen axones propios: cada
  neurona que transmite impulsos desde un botón gustativo recibe input de
  muchos receptores.</p>
<p>En un principio se pensaba que existen cuatro sabores primarios
  —dulce, ácido, amargo y salado— y cuatro clases de receptores
  gustativos, uno para cada sabor primario. Se asumía que la percepción de
  cada sabor era el resultado del grado de actividad relativo producido en
  estos cuatro tipos de receptores. Esta simple teoría del procesamiento
  de los componentes del gusto presentaba varios problemas importantes
  (véase Smith y Margolskee, 2001). Uno es que actualmente está claro que
  al menos existen cinco sabores primarios; el umami (sustancioso o
  sabroso) es el quinto.</p>
<p>Otro problema es que muchos sabores no pueden crearse combinando los
  básicos (Schiffman y Erickson, 1980). Otro más, que no parece haber
  receptores específicos para ciertos sabores (salado y amargo); en cambio
  se ha comprobado que influyen en la actividad de algunos receptores
  gustativos actuando directamente sobre sus canales iónicos (Montmayeur y
  Matsunami, 2002).</p>
<h2>Atención selectiva</h2>
<p>Sólo percibimos conscientemente un pequeño subgrupo de los muchos
  estímulos que excitan nuestros órganos de los sentidos en un momento
  determinado y en gran medida ignoramos el resto. El proceso por lo que
  esto ocurre es la atención selectiva. La atención selectiva presenta dos
  aspectos: mejora la percepción de los estímulos que son su objetivo e
  interfiere en la percepción de los estímulos que no son de su interés.
  Por ejemplo, si se centra la atención en un aviso de megafonía
  potencialmente importante en un aeropuerto aumenta la posibilidad de
  captarlo, pero a la vez disminuye la posibilidad de captar un comentario
  hecho por un compañero de viaje.</p>
<p>La atención puede centrarse de dos modos distintos:</p>
<ul>
  <li>mediante procesos cognitivos internos (atención endógena) o</li>
  <li>mediante sucesos externos (atención exógena) —véase Treue
    (2003)—.
  </li>
</ul>
<p>Por ejemplo, la atención puede concentrarse en la superficie de una
  mesa porque se están buscando las llaves (atención endógena) o puede
  retirarse de allí porque el gato ha volcado una lámpara (atención
  exógena). Se piensa que la atención endógena está mediada por mecanismos
  neurales de arriba a abajo (desde los niveles superiores a los
  inferiores), mientras que la atención exógena se supone mediada por
  mecanismos neurales de abajo a arriba (desde los niveles inferiores a
  los superiores).</p>
<p>¿Cómo operan los mecanismos de la atención selectiva? Conforme a las
  teorías actuales, las representaciones neurales de diversos aspectos de
  una presentación visual compiten uno con otro. Se piensa que la atención
  selectiva opera reforzando las representaciones de los aspectos que se
  esperaban y debilitando los otros (Chun y Marois, 2002). En general, la
  anticipación de un estímulo aumenta la actividad neural en los mismos
  circuitos afectados por el estímulo en sí mismo (Carlsson et al.,
  2000).</p>
<p>Una última característica importante de la atención selectiva es el
  fenómeno de la fiesta (véase Feng y Ratnam, 2000). El <strong>fenómeno
    de la fiesta</strong> consiste en el hecho de que incluso cuando se está
  tan centrado en una conversación que se es totalmente inconsciente del
  contenido de otras conversaciones que tienen lugar alrededor, la mención
  de nuestro nombre en una de las otras conversaciones accederá
  inmediatamente a nuestra consciencia. Este fenómeno sugiere que nuestro
  cerebro puede impedir el paso a la percepción consciente a todos los
  estímulos, excepto a aquellos de una clase en particular, mientras sigue
  controlando de modo inconsciente los estímulos bloqueados por si surge
  alguno que requiere atención.</p>
<h1>Desarrollo del sistema
  nervioso</h1>
<h2>El output
  motor está guiado por el input sensitivo</h2>
<p>Las
  empresas eficaces supervisan continuamente los efectos de sus
  actividades y utilizan esta información para regularlas. El sistema
  sensitivomotor hace lo mismo (Dietz, 2002b). Los ojos, los órganos del
  equilibrio y los receptores de la piel, músculos y articulaciones
  registran todos ellos las respuestas del cuerpo y devuelven la
  información a los circuitos sensitivomotores. En la mayoría de los
  casos, esta retroalimentación sensitiva desempeña un papel importante
  dirigiendo la continuidad de las respuestas que ha producido. Las únicas
  respuestas que habitualmente no están influidas por la retroalimentación
  sensitiva son los movimientos balísticos —movimientos muy rápidos,
  breves, de «todo o nada», como aplastar una mosca—.</p>
<h2>El
  aprendizaje cambia la naturaleza y el locus sensitivomotor</h2>
<p>Durante el aprendizaje sensitivomotor se dan cambios parecidos (véase
  Willingham, 1999). A lo largo de las etapas iniciales del aprendizaje
  motor, cada respuesta individual se lleva a cabo bajo control
  consciente; luego, después de mucha práctica, las respuestas
  individuales se organizan en secuencias de acción integradas y continuas
  que fluyen suavemente y que se modulan mediante retroalimentación
  sensitiva, sin control consciente. Si se piensa un momento en las
  habilidades sensitivomotoras que se han adquirido (p.ej.,
  mecanografiar, nadar, hacer punto, jugar al baloncesto, bailar, tocar el
  piano) podrá comprenderse que la mayor parte del aprendizaje
  sensitivomotor se caracteriza por la organización de las respuestas
  individuales en programas motores continuos, así como por la
  transferencia de su control a los niveles inferiores del sistema
  nervioso.</p>
<h2>Corteza de asociación
  sensitivomotora</h2>
<h3>Corteza de asociación
  parietal posterior</h3>
<p>Antes
  de que pueda iniciarse un movimiento eficaz se requiere cierta
  información. El sistema nervioso necesita saber:</p>
<ul>
  <li>la posición inicial de las partes del cuerpo que van a moverse
    y
  </li>
  <li>necesita saber la posición de cualquier objeto externo con el que
    vaya a interaccionar el cuerpo.
  </li>
</ul>
<p>La corteza de asociación parietal posterior desempeña una función
  importante integrando estos dos tipos de información y dirigiendo la
  atención (véase Andersen y Buneo, 2003, Assad, 2003; Cohen y Andersen,
  2002). En el Capítulo 7 se ha visto que la corteza parietal posterior se
  clasifica como corteza de asociación porque recibe input de más de un
  sistema sensitivo. Recibe información de los tres sistemas sensitivos
  que participan en la localización del cuerpo y de los objetos externos
  en el espacio: el sistema visual, el sistema auditivo y el sistema
  somatosensitivo (véase Andersen y Buneo, 2003; Macaluso, Driver y Frith,
  2003). A su vez, una gran parte del output de la corteza parietal
  posterior se dirige a zonas de la corteza motora, las cuales se sitúan
  en la corteza frontal: a la corteza de asociación prefrontal
  dorsolateral, a las distintas zonas de corteza motora secundaria y al
  campo ocular frontal —una pequeña zona de la corteza prefrontal que
  controla los movimientos oculares (véase la Figura 8.2)—.</p>
<p>La
  <strong>izquierda egocéntrica</strong> se define en parte por
  coordenadas gravitacionales porque cuando los pacientes inclinan la
  cabeza, su campo de negligencia no se inclina normalmente con él (véase
  la parte superior de la Figura 8.3). Además de no poder responder a los
  objetos en su izquierda egocéntrica, muchos pacientes suelen no
  responder a la parte izquierda de los objetos, independientemente de si
  los objetos están en su campo visual. En la corteza parietal del primate
  se han encontrado neuronas que tienen campos receptores egocéntricos y
  otras con campos receptores basados en el objeto (Olson, 2003; Pouget y
  Driver, 2000).</p>
<h3>Corteza de
  asociación prefrontal dorsolateral</h3>
<p>Parece
  ser que la corteza prefrontal dorsolateral interviene en la evaluación
  de los estímulos externos y el inicio de las reacciones voluntarias a
  ellos (Christoff y Gabrieli, 2000; Ohbayashi, Ohki y Miyashita, 2003).
  Este supuesto se basa en las características de respuesta de neuronas en
  esta área de la corteza de asociación.</p>
<p>Las propiedades de respuesta de las neuronas prefrontales
  dorsolaterales y el patrón de conexiones entre esta área y otras áreas
  de corteza sensitivomotora sugieren que la decisión de iniciar un
  movimiento voluntario puede ser tomada en dicha área de la corteza (Rowe
  et al., 2000; Tanji y Hoshi, 2001). No obstante, es más probable que
  tales decisiones provengan de una interacción entre la corteza
  prefrontal dorsolateral y la corteza parietal posterior (Connolly,
  Andersen y Goodale, 2003; Jeannerod y Farne, 2003; Rushworth et al.,
  2003).</p>
<h2>Corteza motora secundaria</h2>
<p>Las regiones de la corteza motora secundaria son aquellas que reciben
  una gran parte de su input de la corteza de asociación y que envían una
  gran parte de su output a la corteza motora primaria (véase la Figura
  8.5). Durante muchos años sólo se conocían dos regiones de corteza
  motora secundaria: el área motora suplementaria y la corteza premotora.
  Las dos amplias áreas pueden verse claramente en la superficie lateral
  del lóbulo frontal, justo delante de la corteza motora primaria. El área
  motora suplementaria rodea la parte superior del lóbulo frontal y se
  extiende hacia abajo por la cara media dentro
  de la cisura longitudinal, y la corteza premotora discurre formando una
  banda desde el área motora suplementaria hasta la cisura lateral.</p>
<p>En general, se cree que las regiones de la corteza motora secundaria
  participan en la planificación de patrones específicos de movimientos
  tras recibir instrucciones generales de la corteza prefrontal
  dorsolateral. Las pruebas a favor de dicha función proceden de estudios
  de neuroimagen cerebral en los que se han medido los patrones de la
  actividad cerebral mientras el sujeto se imaginaba a sí mismo realizando
  una serie particular de movimientos o planificando la realización de
  esos movimientos (véase Kosslyn, Ganis y Thompson, 2001; Sirigu y
  Duhamel, 2001) Por ejemplo, Parsons y colaboradores (1995) observaron
  que se daba un aumento de la actividad registrada con TEP en el área
  motora suplementaria, en la corteza premotora y en las áreas motoras
  cinguladas cuando los sujetos imaginaban que alcanzaban y asían un
  objeto.</p>
<h2>Corteza motora primaria</h2>
<p>La
  corteza motora primaria se halla en la circunvolución precentral del
  lóbulo frontal (véanse las Figuras 8.5 y 8.6). Constituye el principal
  punto de convergencia del input sensitivomotor cortical, y es el
  principal punto de partida de las señales sensitivomotoras que emanan de
  la corteza cerebral. En 1937, Penfield y Boldrey cartografiaron la
  corteza motora primaria de pacientes humanos conscientes durante una
  intervención neuroquirúrgica aplicando estimulación eléctrica en
  diversos puntos de la superficie cortical y observando qué partes del
  cuerpo se movían en respuesta a cada estimulación. Advirtieron que la
  corteza motora primaria está organizada somatotópicamente. A esta
  disposición somatotópica (se dispone ateniéndose a un mapa del cuerpo)
  de la corteza motora primaria humana se alude corrientemente como al
  homúnculo motor (véase la Figura 8.6). Repárese en que la mayor parte de
  la corteza motora primaria se dedica al control de las partes del cuerpo
  capaces de realizar movimientos complejos, como las manos y la boca.</p>
<p>Cada región general de la corteza motora primaria controla el
  movimiento de grupos determinados de músculos y cada una recibe
  retroalimentación somatosensitiva, a través de la corteza
  somatosensitiva, de los receptores de dichos músculos y de las
  articulaciones en las que influyen.</p>
<p>Las <strong>lesiones extensas</strong> de la corteza motora primaria
  del ser humano tienen menos efecto del que podría esperarse,
  considerando que esta corteza es el principal punto de partida de las
  fibras motoras desde la corteza cerebral. Las lesiones extensas de la
  corteza motora primaria pueden alterar la capacidad del paciente para
  mover una parte del cuerpo (p.ej., un dedo) independientemente de
  otras: puede producir estereoagnosia (falta de estereognosia) y pueden
  reducir la velocidad, precisión y fuerza de los movimientos del
  paciente. No suprimen, sin embargo, el movimiento voluntario,
  supuestamente porque existen vías que descienden directamente de las
  áreas motoras secundarias hasta los circuitos motores subcorticales sin
  pasar por la corteza motora primaria.</p>
<h2>Cerebelo y ganglios basales</h2>
<h3>Cerebelo</h3>
<p>Las consecuencias de una lesión cerebelosa difusa sobre la función
  motora son devastadoras. El paciente pierde su capacidad para controlar
  con precisión la dirección, fuerza, velocidad y amplitud de sus
  movimientos, así como la capacidad para adaptar los patrones de output
  motor al cambio de condiciones. Le resulta difícil mantener una postura
  estacionaria (por ejemplo, permanecer de pie) y los intentos de lograrlo
  frecuentemente desembocan en temblores. También se dan graves anomalías
  del equilibrio, la marcha, el habla y el control de los movimientos
  oculares. Aprender nuevas secuencias motoras resulta muy difícil (Shin e
  Ivry, 2003; Thach y Bastian, 2004).</p>
<p>La idea tradicional de que la función del cerebelo se limita al
  aprendizaje y sintonía precisa de las respuestas motoras se ha puesto en
  tela de juicio. La base de esta controversia deriva de la observación de
  la actividad del cerebelo mediante neuroimagen funcional durante la
  ejecución de una serie de tareas cognitivas no motoras por parte de
  sujetos humanos sanos (véase, p.ej.,Lotze et al.1999) así como de la
  verificación de alteraciones cognitivas en pacientes con daño en el
  cerebelo (véase, p.ej.,Fabbro et al., 2004; Townsend et al., 1999). Se
  han propuesto diversas teorías alternativas, pero las más parcas suelen
  argumentar que el cerebelo interviene en el ajuste y aprendizaje de las
  respuestas cognitivas de la misma manera que lo hace en el ajuste y
  aprendizaje de las respuestas motoras (véase, p.ej., Doya, 2000).</p>
<h3>Ganglios basales</h3>
<p>En experimentos llevados a cabo con ratas, se ha demostrado que los
  ganglios basales intervienen en el aprendizaje de la respuesta correcta
  a asociaciones aprendidas, un tipo de aprendizaje de respuesta de que de
  modo característico progresa gradualmente, ensayo a ensayo (véase,
  p.ej., MacDonald y White, 1993). No obstante, no parece que las
  funciones cognitivas de los ganglios basales se restrinjan a este tipo
  de aprendizaje de respuestas (véase, p.ej., Ravizza e Ivry, 2001).</p>
<h2>Vías
  motoras descendentes</h2>
<p>¿Qué nos dicen estos experimentos sobre el papel de los diversos
  fascículos sensitivomotores descendentes en el control del movimiento?
  Sugieren que los dos fascículos ventromediales están implicados en el
  control de la postura y de los movimientos globales del cuerpo (p.ej.,
  andar y trepar) y que pueden ejercer un control sobre el movimiento de
  las extremidades que intervienen en dichas actividades. Por el
  contrario, ambos fascículos dorsolaterales —el corticoespinal y el
  corticorrubroespinal— controlan los movimientos de las extremidades.
  Esta redundancia constituyó probablemente la base de la buena
  recuperación del movimiento de las extremidades tras las lesiones
  iniciales del fascículo dorsolateral corticoespinal. No obstante, sólo
  la división corticoespinal del sistema dorsolateral es capaz de mediar
  los movimientos independientes de los dedos.</p>
<h2>Circuitos medulares
  sensitivomotores</h2>
<h3>Músculos</h3>
<p>Las unidades motoras constituyen las unidades más pequeñas de la
  actividad motora. Cada unidad motora incluye una única neurona motora y
  todas las fibras musculares esqueléticas individuales que inerva (véase
  la Figura 8.9). Cuando la neurona motora dispara, todas las fibras de su
  unidad se contraen al mismo tiempo. Las unidades motoras difieren
  considerablemente unas de otras en la cantidad de fibras musculares que
  contienen; las unidades con menor número de fibras —las de los dedos y
  la cara— son las que permiten el mayor grado de control motor
  selectivo.</p>
<p>Un músculo esquelético incluye cientos de miles de fibras musculares
  filiformes unidas por una fuerte membrana y ligadas al hueso por un
  tendón. La acetilcolina, que es liberada por las neuronas motoras en las
  uniones neuromusculares, activa la placa terminal motora en cada fibra
  muscular y hace que la fibra se contraiga. Todas las neuronas motoras
  que inervan las fibras de un único músculo constituyen el conjunto
  motor.</p>
<ul>
  <li>Los <strong>flexores</strong> actúan para doblar o flexionar una
    articulación y
  </li>
  <li>los <strong>extensores</strong> para estirarla o extenderla. En la
    Figura 8.10 se ilustran el bíceps y el tríceps —el flexor y el extensor,
    respectivamente, de la articulación del codo—.
  </li>
  <li>A dos músculos cuya contracción produzca el mismo movimiento, ya sea
    flexión o extensión, se les denomina <strong>músculos
      sinérgicos</strong> ;
  </li>
  <li>a los que actúan de manera opuesta, como el bíceps y el tríceps, se
    les llama músculos <strong>antagonistas</strong>.
  </li>
</ul>
<h3>Órganos
  receptores de los tendones y músculos</h3>
<p>La actividad de los músculos esqueléticos es controlada por dos tipos
  de receptores:</p>
<ul>
  <li>los órganos tendinosos de Golgi y</li>
  <li>los husos musculares.</li>
</ul>
<p>Los
  órganos tendinosos de Golgi están insertados en los tendones, los cuales
  conectan cada músculo esquelético al hueso; los husos musculares están
  insertados en el tejido muscular mismo. Debido su diferente
  localización, los órganos tendinosos de Golgi y los husos musculares
  responden a distintos aspectos de la contracción muscular.</p>
<p>Los órganos tendinosos de Golgi responden a un incremento de la
  tensión muscular (esto es, al tirón del músculo sobre el tendón), pero
  son completamente insensibles a los cambios de longitud del músculo. Por
  lo contrario, los husos musculares responden a cambios de longitud
  muscular, pero no a los de la tensión muscular.</p>
<p>En condiciones normales, la función de los órganos tendinosos de
  Golgi es proporcionar información acerca de la tensión muscular al
  sistema nervioso central, pero también desempeñan una función
  protectora. Cuando la contracción del músculo es tan intensa que hay
  riesgo de lesión, los órganos tendinosos de Golgi excitan a las
  interneuronas inhibidoras de la médula espinal que hacen que el músculo
  se relaje.</p>
<h2>Reflejo miotático</h2>
<p>En la
  vida real, la función del reflejo miotático consiste en evitar que una
  fuerza externa altere la postura intencionada del cuerpo. Cuando una
  fuerza externa, tal como un empujón en el brazo mientras se sostiene una
  taza de café, provoca un inesperado estiramiento muscular extrafusal, el
  circuito de retroalimentación del huso muscular produce una contracción
  compensatoria inmediata del músculo que contrarresta la fuerza y evita
  que se derrame el café —menos, por supuesto, cuando llevamos puesta
  nuestra mejor ropa—.</p>
<h2>Reflejo de retirada</h2>
<p>Seguro
  que en alguna ocasión todos hemos tocado algo doloroso —un recipiente
  caliente, por ejemplo— y hemos retirado de golpe la mano. Esto es un
  reflejo de retirada. A diferencia del reflejo miotático, el reflejo de
  retirada no es monosináptico. Cuando se aplica a la mano un estímulo
  doloroso, las primeras reacciones se registran en las neuronas motoras
  de los músculos flexores del brazo unos 1.6 milisegundos después,
  aproximadamente el tiempo que tarda una señal neural para traspasar dos
  sinapsis. Así pues, la vía más corta en el circuito del reflejo de
  retirada implica una <strong>interneurona</strong>. Otras respuestas se
  registran en las neuronas motoras de los músculos flexores del brazo
  tras la descarga inicial; estas respuestas son desencadenadas por
  señales que han viajado por vías multisinápticas —algunas de las cuales
  implican a la corteza—. (Véase la Figura 8.15.).</p>
<h3>Inervación recíproca</h3>
<p>La inervación recíproca representa un principio importante de los
  circuitos de la médula espinal. Se refiere al hecho de que los músculos
  antagonistas están inervados de modo que permitan una respuesta motora
  suave y sin impedimentos. Cuando uno se contrae, el otro se relaja.</p>
<p>Las
  interneuronas excitadoras excitan a las neuronas motoras de los músculos
  flexores del codo. Las interneuronas inhibidoras inhiben las neuronas
  motoras de los músculos extensores del codo. Así pues, un input
  sensitivo individual produce un patrón coordinado de output motor: las
  actividades de los agonistas y los antagonistas son coordinadas
  automáticamente por los circuitos internos de la médula espinal.</p>
<h3>Inhibición colateral
  recurrente</h3>
<p>Como la mayoría de los trabajadores, las fibras musculares y las
  neuronas motoras que las inervan necesitan descansar de vez en cuando, y
  existen neuronas inhibidoras en la médula espinal que se ocupan de que
  puedan hacerlo. Cada neurona motora se ramifica justo antes de salir de
  la médula espinal y la ramificación forma sinapsis con una pequeña
  interneurona inhibidora, la cual inhibe a la misma neurona motora de la
  que recibe su input (véase Illert y Kummel, 1999). La inhibición
  producida por estos circuitos de retroalimentación local se designa
  inhibición colateral recurrente, y las pequeñas interneuronas
  inhibidoras que median la inhibición colateral recurrente se llaman
  <strong>células de Renshaw</strong>.</p>
<p>Como consecuencia de la inhibición colateral recurrente, cada vez que
  una neurona motora dispara se inhibe momentáneamente a sí misma y
  transfiere la responsabilidad de la contracción de un músculo en
  particular a otros miembros del conjunto motor muscular.</p>
<h3>Andar: un complejo
  reflejo sensitivomotor</h3>
<p>Grillner (1985) demostró que la locomoción puede estar controlada por
  circuitos de la médula espinal. Los sujetos de Grillner eran gatos a los
  que se les había separado la médula espinal del encéfalo mediante
  sección medular. Colocó a los gatos en un cabestrillo sobre una cinta
  sin fin [«tapiz rodante»]; sorprendentemente, cuando la cinta empezó a
  moverse y los gatos recibieron retroalimentación sensitiva del tipo que
  normalmente acompaña a la locomoción, éstos empezaron a andar (véase
  Drew, Jiang y Widajewicz. 2002)</p>
<h2>Programas sensitivomotores
  centrales</h2>
<p>Una de las teorías sobre la función sensitivomotora es que el sistema
  sensitivomotor incluye una jerarquía de programas sensitivomotores
  centrales (véase Brooks, 1986; Georgopoulos, 1991). La teoría del
  programa sensitivomotor central sugiere que todos los niveles del
  sistema sensitivomotor, excepto los superiores, tienen por sí mismos
  determinadas pautas de actividad programada y que los movimientos
  complejos se producen activando la combinación adecuada de tales
  programas (véase Swinnen, 2002; Tresch et al., 2002). Según esto, si la
  corteza de asociación decide que a uno le puede apetecer hojear una
  revista, activa los programas corticales de los niveles superiores, los
  cuales a su vez activan los programas de los niveles inferiores —quizá
  localizados en el tronco del encéfalo— para andar, inclinarse, tomar la
  revista y hojearla. Dichos programas activan a su vez programas
  espinales específicos que controlan los diversos elementos de las
  secuencias y hacen que los músculos consigan el objetivo.</p>
<h3>Los
  programas sensitivomotores centrales tienen capacidad de equivalencia
  motora</h3>
<p>Al igual que una gran y eficaz empresa, el sistema sensitivo motor no
  realiza siempre una tarea determinada exactamente del mismo modo. El
  hecho de que puedan llevarse a cabo los mismos movimientos básicos de
  modos diferentes que implican a músculos diferentes se denomina
  equivalencia motora. Por ejemplo, hemos aprendido a firmar con nuestro
  nombre mediante movimientos estereotipados de los dedos y la mano; aun
  cuando firmemos con el pie en la arena de la playa, la firma conservará
  muchas de sus características típicas. Este ejemplo de equivalencia
  motora sugiere que los programas sensitivomotores centrales para firmar
  no están almacenados en circuitos neurales que controlan directamente la
  mano que habitualmente utilizamos, sino a un nivel superior de la
  jerarquía motora. ¿Pero dónde?</p>
<p>En un estudio de RMf, Rijntjes y colaboradores (1999) encontraron que
  los programas sensitivomotores centrales para firmar parecen estar
  almacenados en áreas de la corteza motora secundaria que controlan la
  mano de preferencia. Es de sorprender que las mismas áreas de la mano se
  activaron asimismo cuando se firmó con el pie.</p>
<h3>La
  información sensitiva que controla los programas sensitivomotores
  centrales no es necesariamente consciente</h3>
<p>En el Capítulo 7 se estudió que los mecanismos neurales de la
  percepción visual consciente (corriente ventral) no son necesariamente
  los mismos que los que median el control visual de la conducta
  (corriente dorsal). El apoyo inicial de esta teoría provino de pacientes
  neuropsicológicos que podían responder a estímulos visuales de los que
  no tenían consciencia y de otros pacientes que no podían interactuar
  eficazmente con objetos que percibían conscientemente.</p>
<h3>Los
  programas sensitivomotores centrales pueden desarrollarse sin
  práctica</h3>
<p>Aunque los programas sensitivomotores centrales de algunas conductas
  pueden establecerse practicando dicha conducta, los programas
  sensitivomotores centrales de muchas conductas típicas de especie se
  establecen sin una práctica explícita de ese comportamiento. Esta
  cuestión quedó bien clara a partir del estudio clásico de Fentress
  (1973). Dicho autor demostró que ratones adultos criados desde el
  nacimiento sin patas delanteras seguían haciendo los patrones de
  movimientos de omóplatos —típicos del acicalamiento en su especie— y que
  estos movimientos estaban bien coordinados con los de la lengua, la
  cabeza y los ojos. Por ejemplo, el ratón parpadeaba cada vez que
  realizaba el movimiento de omóplatos que hubiera hecho al restregarse
  los ojos con las patas delanteras. El estudio de Fentress demostró
  igualmente la importancia de la retroalimentación sensitiva en el
  funcionamiento de los programas sensitivomotores centrales. Los ratones
  que no tenían patas delanteras, privados del contacto habitual entre la
  zarpa y la lengua al acicalarse la cara, a menudo interrumpían una
  aparente secuencia de acicalamiento para lamer a un compañero de jaula o
  incluso el suelo.</p>
<h3>La
  práctica puede producir programas sensitivomotores centrales</h3>
<p>Aunque los programas sensitivomotores centrales de muchas conductas
  típicas de especies se desarrollan sin práctica, la práctica es un modo
  seguro de generar o modificar tales programas. Las teorías del
  aprendizaje sensitivomotor resaltan dos tipos de procesos que influyen
  en el aprendizaje de programas sensitivomotores centrales: integración
  de fragmentos de respuesta y transferencia del control a los niveles
  inferiores del sistema sensitivomotor.</p>
<ul>
  <li><strong>Integración de la respuesta</strong>: Según la hipótesis de la
    integración de la respuesta, la práctica combina los programas
    sensitivomotores centrales que controlan respuestas individuales
    formando programas que controlan secuencias (fragmentos) de conducta. Un
    principio importante de la integración de fragmentos es que los
    fragmentos mismos pueden combinarse en fragmentos de un nivel superior.
    Por ejemplo, las respuestas requeridas para mecanografiar cada una de
    las letras y los dígitos de una dirección pueden agruparse en secuencias
    más largas necesarias para formar las palabras y las cifras
    individuales, y estos fragmentos pueden combinarse a su vez de modo que
    pueda escribirse la dirección completa como una unidad.
  </li>
  <li><strong>Transferencia del control a niveles inferiores</strong> :
    Durante el proceso de aprendizaje de un programa sensitivomotor central,
    el control se transfiere de los niveles superiores de la jerarquía
    sensitivomotora a los inferiores (véase Ramnami y Passingham, 2001;
    Sanes, 2003). El traspaso del nivel de control a los niveles inferiores
    del sistema sensitivomotor durante el entrenamiento (véase Seitz et al.,
    1990) ofrece dos ventajas. Una es que libera a los niveles superiores
    para que puedan ocuparse de otros aspectos más enigmáticos. Por ejemplo,
    los pianistas virtuosos pueden concentrarse al interpretar una pieza
    musical porque no tienen que centrarse de manera consciente en presionar
    la tecla adecuada. La otra ventaja de la transferencia del nivel de
    control es que permite una gran velocidad, ya que los diferentes
    circuitos de los niveles inferiores de la jerarquía pueden actuar
    simultáneamente, sin interferir unos con otros. Es posible mecanografiar
    120 palabras por minuto sólo porque los circuitos responsables de
    activar cada presión de tecla se activan antes de que se haya completado
    la respuesta precedente.
  </li>
</ul>
<h3>Neuroimagen
  cerebral funcional del aprendizaje sensitivomotor</h3>
<p>El cerebelo se activó bilateralmente durante la ejecución tanto de
  las secuencias recién aprendidas como de las ya practicadas, pero se
  activó más durante la secuencia recién aprendida. Esto es coherente con
  la idea de que el cerebelo desempeña una función primordial en el
  aprendizaje motor.</p>
<h1>Desarrollo del sistema
  nervioso</h1>
<h2>Fases del desarrollo neural</h2>
<ol>
  <li>En primer lugar, las células deben diferenciarse: algunas deben
    convertirse en células musculares, otras en neuronas multipolares, otras
    en neurogliocitos, y así sucesivamente.
  </li>
  <li>En segundo lugar, las células han de dirigirse a los lugares
    adecuados y alinearse con las células en torno suyo para formar
    estructuras concretas.
  </li>
  <li>Y en tercer lugar, las células tienen que establecer relaciones
    funcionales adecuadas con otras células (Kozloski, Hamzei-Sichani y
    Yuste, 2001).
  </li>
</ol>
<p>En este apartado se describe cómo las neuronas en desarrollo llevan a
  cabo esto a lo largo de cinco fases: 1) inducción de la placa neural, 2)
  proliferación neuronal, 3) migración y agrupamiento, 4) crecimiento del
  axón y formación de sinapsis, y 5) muerte neuronal y nueva disposición
  sináptica.</p>
<h3>Inducción de la placa neural</h3>
<p>Tres semanas después de la concepción, el tejido que está destinado a
  formar el sistema nervioso humano puede reconocerse en forma de placa
  neural —un pequeño fragmento de tejido ectodérmico situado en la
  superficie dorsal del embrión en desarrollo—. El ectodermo es la capa
  más externa de las tres capas de células embrionarias: ectodermo,
  mesodermo y endodermo. El desarrollo de la placa neural constituye la
  primera fase importante del desarrollo nervioso en todos los
  vertebrados.</p>
<p>Las células del sistema nervioso en desarrollo sufren un cambio
  importante aproximadamente en la misma etapa en que se hace visible la
  placa neural. Las primeras células del embrión humano son
  <strong>plenipotenciales</strong> —es decir, tienen la capacidad de
  convertirse en cualquier tipo de célula del organismo si se transplantan
  al lugar apropiado—. Sin embargo, a medida que el embrión se desarrolla
  se va especificando más el destino de diversas células. Con el
  desarrollo de la placa neural, sus células pierden gran parte de su
  potencial para convertirse en diferentes tipos de células. Cada célula
  de la placa neural conserva aún la posibilidad de convertirse en
  cualquier tipo de célula del sistema nervioso maduro, pero normalmente
  no puede transformarse en otro tipo de células. A tales células se les
  llama <strong>pluripotenciales</strong> , en vez de
  plenipotenciales.</p>
<h3>Proliferación neuronal</h3>
<p>Una vez que se han fusionado los labios del surco neural para
  originar el tubo neural, las células del tubo comienzan a proliferar (su
  cantidad aumenta extraordinariamente). Esta proliferación neuronal no se
  produce de modo simultáneo o de la misma forma en todas las partes del
  tubo. En cada especie, las células de distintas partes del tubo neural
  proliferan siguiendo una secuencia característica, la cual es
  responsable de la configuración de abultamientos y pliegues que dan al
  encéfalo su forma característica de especie. La mayor parte de la
  división de las células del tubo neural tiene lugar en la zona
  ventricular —la región adyacente al ventrículo (el centro del tubo
  repleto de líquido)—.</p>
<h3>Migración y agrupamiento</h3>
<h4>Migración</h4>
<p>Una vez que se han generado células mediante división celular en la
  zona ventricular del tubo neural, éstas migran hasta el lugar de destino
  apropiado. Durante este período de migración, las células están todavía
  en un estado inmaduro: carecen de las prolongaciones (esto es, de los
  axones y las dendritas) que caracterizan a las neuronas maduras.</p>
<p>La cresta neural es una estructura que se sitúa justo en el plano
  dorsal al tubo neural (véase la Figura 9.1). Está compuesta por células
  que se desprenden del tubo neural cuando éste se está formando. Las
  células de la cresta neural se convierten en neuronas y en
  neurogliocitos del sistema nervioso periférico; por ello, muchas de
  ellas tienen que migrar a distancias considerables. Por esta razón, son
  motivo preferente de estudio sobre la migración neural.</p>
<p>Se ha descubierto una gran cantidad de sustancias químicas que guían
  la migración de las neuronas, ya sea atrayéndolas o repeliéndolas (Marin
  y Rubenstein, 2003). Algunas de estas sustancias son liberadas por los
  neurogliocitos (véase Auld, 2001; Marin et al.2001).</p>
<h4>Agrupamiento</h4>
<p>Una vez que las neuronas en desarrollo han migrado deben alinearse
  con otras neuronas que han migrado a la misma zona para formar las
  estructuras del sistema nervioso. Este proceso se denomina agrupamiento.
  Se piensa que tanto la migración como el agrupamiento están mediados por
  <strong>moléculas de adherencia celular</strong> [«cell-adhesión
  molecules»] (MACs), las cuales se localizan en la superficie de las
  neuronas y de otras células. Las moléculas de adherencia celular tienen
  la capacidad de reconocer moléculas de otras células y adherirse a
  ellas.</p>
<h3>Crecimiento del
  axón y formación de sinapsis</h3>
<h4>Crecimiento del axón</h4>
<p>Una vez
  que las neuronas han migrado a su lugar adecuado y se han agrupado en
  estructuras nerviosas comienzan a surgir de ellas axones y dendritas.
  Para que el sistema nervioso funcione, estas proyecciones han de
  extenderse hasta sus objetivos adecuados. En cada extremo en crecimiento
  de un axón o dendrita se encuentra una estructura con forma de ameba,
  denominada cono de crecimiento, que extiende y retrae extensiones
  citoplásmicas parecidas a dedos, llamadas filopodios, como si buscara el
  itinerario correcto.</p>
<p>Según esta nueva hipótesis, una neurona en crecimiento no es atraída
  hasta su objetivo por un solo factor atrayente específico liberado por
  el objetivo, como supuso Sperry. En lugar de ello, parece ser que el
  crecimiento axónico está influido por una serie de señales químicas a lo
  largo de la ruta. Algunas de estas moléculas de orientación atraen a los
  axones en crecimiento, mientras que otras los repelen (véase Guan y Rao,
  2003). Se han identificado varias familias de moléculas de orientación;
  incluso los neurotransmisores pueden servir de moléculas de orientación
  en el sistema nervioso en desarrollo (véase Holmberg y Frisén 2002;
  Inantani et al., 2003; Markus, Patel y Snider, 2002; Owens y Kriegstein,
  2002). Es de resaltar que varias moléculas de orientación son liberadas
  por la neuroglia (Lemke, 2001).</p>
<p>Las moléculas de orientación no son la única señal que guía a los
  axones en crecimiento hasta sus objetivos. Otras señales proceden de los
  axones en crecimiento adyacentes. Se supone que los conos de crecimiento
  pioneros —los primeros conos de crecimiento que viajan a lo largo de una
  ruta determinada en un sistema nervioso en desarrollo— siguen la pista
  correcta interactuando con moléculas de orientación a lo largo de la
  ruta. Posteriormente, los conos de crecimiento siguientes que emprenden
  el mismo viaje siguen la ruta abierta por los pioneros. La tendencia de
  los axones en desarrollo a desarrollarse a lo largo de las vías
  establecidas por los axones precedentes se denomina
  <strong>fasciculación</strong>. Cuando se destruyeron con láser los
  axones pioneros de la médula espinal de un pez, los axones posteriores
  de los mismos nervios no llegaron a sus destinos habituales.</p>
<p>Gran parte del desarrollo axónico en sistemas nerviosos complejos
  implica el crecimiento desde un conjunto topográfico de neuronas a otro.
  Las neuronas de un conjunto proyectan al otro, manteniendo la misma
  relación topográfica que tenían con el primero; por ejemplo, el mapa
  topográfico de la retina se mantiene en el tectum óptico.</p>
<p>Para
  explicar el crecimiento axónico preciso que implica la cartografía
  topográfica en el cerebro en desarrollo se ha propuesto <strong>la
    hipótesis del gradiente topográfico</strong> (véase Debski y Cline,
  2002; Grove y Fukuchi-Shimogori, 2003; McLaughlin, Hindges y O’Leary,
  2003). Conforme a esta hipótesis, los axones que se desarrollan a partir
  de una superficie topográfica (p.ej., la retina) a otra (p.ej., el
  tectum óptico) son guiados a objetivos específicos que están dispuestos
  sobre la superficie terminal del mismo modo que lo están los axones de
  los cuerpos celulares sobre la superficie original. La parte clave de
  esta hipótesis es que los axones en crecimiento son guiados a sus
  destinos por dos gradientes señal en intersección (p.ej., un gradiente
  anterior-posterior y un gradiente medial-lateral). El mecanismo se
  ilustra en la Figura 9.7.</p>
<h4>Formación de sinapsis</h4>
<p>Una vez que los axones han alcanzado el objetivo deseado, han de
  establecer un modelo de sinapsis apropiado. Una neurona individual puede
  desarrollar un axón por sí misma, pero se requiere una actividad
  coordinada entre al menos dos neuronas para crear una sinapsis entre
  ellas (véase Yuste y Bonhoeffer, 2004). Esta es una de las razones por
  las que nuestro conocimiento de cómo los axones conectan con sus
  objetivos se ha rezagado en comparación con nuestro conocimiento de cómo
  los alcanzan (véase Benson, Colman y Huntley, 2001; Lee y Sheng, 2000).
  Aún así, se ha hecho algún apasionante gran descubrimiento.</p>
<p>Quizá, el descubrimiento reciente más apasionante sobre la
  sinaptogénesis (la formación de nuevas sinapsis) es que depende de la
  presencia de neurogliocitos (véase Barres y Smith, 2001; Fields, 2004;
  Slezak y Pfrieger, 2003). Células ganglionares retinianas que se
  mantuvieron en cultivo establecieron siete veces más sinapsis cuando
  había astrocitos. Además, las sinapsis establecidas en presencia de
  astrocitos se perdieron rápidamente cuando aquellas células se
  suprimieron. Otra investigación ha sugerido que las neuronas en
  desarrollo necesitan altos niveles de colesterol durante el período de
  formación de sinapsis y que este colesterol adicional es suministrado
  por los astrocitos (Mauch et al., 2001; Pfreiger, 2002)</p>
<h3>Muerte neuronal y
  nueva disposición sináptica</h3>
<h4>Muerte neuronal</h4>
<p>La muerte neuronal es una parte normal e importante del desarrollo
  nervioso. Tal desarrollo parece operar siguiendo el principio de
  supervivencia del más apto: se producen muchas más neuronas —alrededor
  de un cincuenta por ciento más— de las que se requieren y sólo
  sobreviven las más aptas. La muerte a gran escala no constituye una fase
  del desarrollo limitada en el tiempo; se produce en oleadas en diversas
  partes del encéfalo a lo largo del desarrollo.</p>
<p>Tres hallazgos sugieren que las neuronas en desarrollo mueren debido
  a su incapacidad de competir con éxito por sustancias químicas vitales
  que les suministran sus lugares de destino [u objetivos].</p>
<ol>
  <li>En primer lugar, la implantación de objetivos adicionales reduce la
    muerte neuronal. Por ejemplo, injertar un miembro adicional en un
    costado de un embrión de pollo reduce la muerte de neuronas motoras en
    ese lado.
  </li>
  <li>En segundo lugar, destruir algunas de las neuronas que crecen en un
    área antes del período de muerte celular aumenta la tasa de
    supervivencia de las neuronas restantes.
  </li>
  <li>En tercer lugar, aumentar la cantidad de axones que inervan
    inicialmente un objetivo disminuye la proporción de neuronas que
    sobreviven.
  </li>
</ol>
<p>Se han identificado varias sustancias químicas vitales que son
  suministradas a las neuronas en desarrollo por sus objetivos. La clase
  más destacada de estas sustancias químicas es la de las neurotrofinas.
  El factor de crecimiento nervioso (FCN) fue la primera neurotrofina que
  se aisló (véase Levi-Montalcini, 1952, 1975), pero desde entonces se han
  identificado otras tres en mamíferos. Las neurotrofinas realizan una
  serie de funciones. Por ejemplo, promueven el desarrollo y la
  supervivencia de las neuronas, funcionan como moléculas de orientación
  del axón y estimulan la sinaptogénesis (véase Huang y Reichardt, 2001;
  Vicario-Abejón et al., 2002).</p>
<p>La ausencia de las neurotrofinas adecuadas puede desencadenar un
  programa genético interno de las neuronas que haga que éstas se suiciden
  activamente. La muerte celular pasiva se denomina
  <strong>necrosis</strong> ; la muerte celular activa se denomina
  <strong>apoptosis</strong>.</p>
<ul>
  <li>La apoptosis es menos peligrosa que la necrosis. Las células
    necróticas se fragmentan y vierten su contenido al líquido extracelular;
    la consecuencia es una inflamación potencialmente perjudicial. Por el
    contrario, en la muerte celular <strong>apoptótica</strong> , el ADN y
    otras estructuras internas se parten y son empaquetadas dentro de
    membranas antes de que la célula se fragmente. Estas membranas contienen
    moléculas que atraen fagocitos y otras que previenen la inflamación (Li
    et al., 2003; Savill, Gregory y Haslett, 2003; Wang et al., 2003).
  </li>
  <li>Durante la fase de muerte neuronal, la apoptosis elimina las
    neuronas excedentes —por ejemplo, neuronas que no obtienen suficientes
    neurotrofinas— de un modo seguro, pulcro y ordenado. Pero la apoptosis
    también tiene un lado oscuro. Si se inhiben los programas genéticos de
    muerte celular apoptótica, la consecuencia puede ser el cáncer; si los
    programas se activan de forma inadecuada, la consecuencia puede ser una
    enfermedad neurodegenerativa.
  </li>
</ul>
<h4>Nueva disposición sináptica</h4>
<p>Durante
  el período de muerte celular, las neuronas que han establecido
  conexiones incorrectas son particularmente propensas a morir. Cuando
  mueren, el espacio que han dejado vacante en las membranas
  postsinápticas es ocupado por los terminales axónicos que brotan de las
  neuronas supervivientes. Así pues, la muerte celular da lugar a una
  reorganización masiva de las conexiones sinápticas. Esta fase de
  reorganización sináptica tiende a agrupar el output de cada neurona en
  una pequeña cantidad de células postsinápticas, aumentando así la
  selectividad de la transmisión (véase la Figura 9.8).</p>
<h2>Desarrollo
  cerebral postnatal en bebés humanos</h2>
<p>La mayor parte de nuestro conocimiento sobre el desarrollo neural
  procede del estudio de especies no humanas. Este hecho resalta el valor
  de la aproximación comparativa y la perspectiva evolutiva. Hay, sin
  embargo, un aspecto en el que el desarrollo del cerebro humano es único:
  el cerebro humano se desarrolla bastante más lentamente que el de otras
  especies y no alcanza su plena madurez hasta el final de la adolescencia
  (Spear, 2000). Este apartado se ocupa de la parte del desarrollo del
  cerebro humano que ocurre después del nacimiento. Se centra en el
  desarrollo de la corteza prefrontal (véase la Figura 1.7). La corteza
  prefrontal es la última parte del cerebro que alcanza la madurez, y se
  piensa que media muchas capacidades cognitivas superiores.</p>
<h3>Crecimiento postnatal
  del encéfalo humano</h3>
<p>El encéfalo humano crece considerablemente después del nacimiento: su
  volumen se cuadriplica entre el nacimiento y la vida adulta (véase
  Johnson, 2001). Este aumento de tamaño no se debe, sin embargo, al
  desarrollo de neuronas adicionales. A excepción de unas cuantas
  estructuras (p.ej., el bulbo olfativo y el hipocampo) en las que
  continúan produciéndose muchas neuronas nuevas durante los años adultos,
  todas las neuronas que compondrán el encéfalo humano adulto se han
  desarrollado y migrado a su lugar apropiado en el séptimo mes del
  desarrollo prenatal. Parece ser que el crecimiento postnatal del
  encéfalo humano proviene de otros tres tipos de crecimiento:</p>
<ul>
  <li>sinaptogénesis,</li>
  <li>mielinización de muchos axones y</li>
  <li>aumento de la ramificación de las dendritas.</li>
</ul>
<p>Se ha dado un particular interés por la formación postnatal de
  sinapsis debido a que se asume que la cantidad de conexiones entre
  neuronas en una región determinada del encéfalo es un índice de la
  capacidad analítica de esa región. Parece haber un incremento en el
  ritmo de formación de sinapsis en toda la corteza humana poco después
  del nacimiento, pero hay diferencias entre las regiones corticales en el
  curso de este desarrollo (Huttenlocher, 1994).</p>
<p>La mielinización aumenta la velocidad de conducción axónica, y la
  mielinización de diversas áreas del encéfalo humano durante el
  desarrollo es aproximadamente paralela a su desarrollo funcional.</p>
<ol>
  <li>La mielinización de las <strong>áreas sensitivas</strong> tiene
    lugar en los primeros meses inmediatamente después del nacimiento,
    y
  </li>
  <li>la mielinización de las <strong>áreas motoras</strong> le sigue
    pronto; mientras que
  </li>
  <li>la mielinización de la <strong>corteza prefrontal</strong> continúa
    hasta la adolescencia.
  </li>
</ol>
<p>El desarrollo postnatal del cerebro humano no es una vía de sentido
  único; se dan cambios regresivos además de crecimiento (Huttenlocher,
  1994). Por ejemplo, una vez que se alcanzado la máxima densidad
  sináptica, hay períodos de <strong>pérdida sináptica</strong>. Al igual
  que los períodos de sinaptogénesis, los períodos de pérdida sináptica
  ocurren en momentos diferentes en diferentes partes del encéfalo,</p>
<p>Por ejemplo, la densidad sináptica en la corteza visual primaria
  desciende hasta los niveles propios del adulto aproximadamente a los
  tres años de edad <strong>,</strong> mientras que su disminución a los
  niveles adultos en la corteza prefrontal no acaba hasta la adolescencia.
  Se ha sugerido que el exceso de producción de sinapsis puede subyacer a
  la mayor plasticidad que tiene el encéfalo joven.</p>
<h3>Desarrollo de la corteza
  prefrontal</h3>
<p>Como se acaba de aprender, la corteza prefrontal presenta el período
  de desarrollo más prolongado de cualquier región cerebral. Se piensa que
  su desarrollo es en gran parte responsable del curso del desarrollo
  cognitivo humano, que ocurre aproximadamente en el mismo período.
  Considerando el tamaño, la complejidad y la heterogeneidad de la corteza
  prefrontal, no es de sorprender que no haya una única teoría ampliamente
  aceptada que explique su función. No obstante, se han relacionado
  sistemáticamente tres tipos de funciones cognitivas con esta área en
  estudios de adultos con lesión prefrontal.</p>
<p>Al parecer, la corteza prefrontal interviene en:</p>
<ol>
  <li>la memoria de trabajo, esto es, mantener accesible información
    relevante durante cortos períodos de tiempo mientras se completa la
    tarea,
  </li>
  <li>la planificación y ejecución de secuencias de acciones y</li>
  <li>la inhibición de respuestas que son inadecuadas en el contexto
    actual pero no en otros (véase Hauser, 1999).
  </li>
</ol>
<h2>Efectos
  de la experiencia en el desarrollo inicial, mantenimiento y
  reorganización de los circuitos neurales</h2>
<p>Los programas genéticos del desarrollo nervioso no actúan en el
  vacío. El desarrollo nervioso se despliega a partir de interacciones
  entre las neuronas y su ambiente. En el primer apartado de este capítulo
  se ha visto cómo los factores de su ambiente más inmediato (por ejemplo,
  las neurotrofinas y las MACs) pueden influir en la migración,
  agrupamiento y crecimiento de las neuronas. Este apartado se centra en
  la forma en que las experiencias del organismo en desarrollo influyen en
  el desarrollo, mantenimiento y reorganización de los circuitos neurales.
  El principio fundamental que rige los efectos de las primeras
  experiencias sobre los circuitos neurales nerviosos es sencillo: las
  neuronas y las sinapsis que no son activadas por la experiencia por lo
  general no sobreviven (véase Hockfield y Kalb, 1993; Kalil, 1989). Es
  decir, se usa o se pierde.</p>
<p>Como se acaba de aprender, los seres humanos somos excepcionalmente
  lentos en nuestro desarrollo neural. Una ventaja de esta lentitud puede
  ser que ofrece muchas oportunidades para tener experiencias a los
  delicadamente sintonizados sistemas en desarrollo (Johnson, 2001).</p>
<h3>Estudios
  iniciales de la experiencia y desarrollo neural</h3>
<p>Muchas de las primeras demostraciones de las repercusiones de las
  primeras experiencias sobre el desarrollo neural proceden de dos líneas
  de investigación: el estudio de los efectos de la privación visual
  temprana y el estudio de la exposición temprana a ambientes ricos en
  estímulos.</p>
<p>Por ejemplo, se ha encontrado que las ratas criadas desde el
  nacimiento en oscuridad tienen menos sinapsis y menos espinas
  dendríticas en la corteza visual primaria, así como una visión de
  profundidad y de patrones visuales deficiente cuando llegan a ser
  adultas. Por el contrario, las ratas que se han criado en jaulas de
  grupo con muchos estímulos (complejas) en vez de criarse solas en jaulas
  estériles [con pocos estímulos] tienen cortezas más gruesas, con más
  espinas dendríticas y más sinapsis por neurona.</p>
<h3>Carácter
  competitivo de la experiencia y el desarrollo neural</h3>
<p>La experiencia fomenta el desarrollo de circuitos neurales activos y
  el mantenimiento o la reorganización de los existentes, pero en esto
  parece haber un aspecto competitivo. Este aspecto competitivo queda
  ilustrado claramente por los perjudiciales efectos de la privación
  monocular temprana.</p>
<p>Privar de estímulos visuales a un ojo durante unos cuantos días en
  una etapa temprana de la vida tiene un efecto adverso duradero sobre la
  visión del ojo privado, pero esto no sucede si también se ciega el otro
  ojo. Cuando solamente se ciega un ojo, se reduce la capacidad de ese ojo
  para activar la corteza visual, mientras que la capacidad del otro ojo
  aumenta. Estos dos efectos ocurren porque la privación monocular
  temprana cambia el patrón del input sináptico a la capa IV de la corteza
  visual primaria.</p>
<p>El carácter competitivo de los efectos de la actividad neural sobre
  la reorganización sináptica se ha demostrado asimismo en experimentos
  realizados con neuronas motoras y células musculares. En los neonatos
  (recién nacidos), cada célula muscular está inervada normalmente por
  varias neuronas motoras y luego, en el transcurso del desarrollo, se
  eliminan todas menos una. Lo y Poo (1991) estudiaron una preparación in
  vitro en la que una célula muscular en desarrollo estaba inervada por
  dos neuronas motoras en desarrollo. La aplicación de descargas de
  estimulación eléctrica a una de estas neuronas provocó una rápida
  degradación de los contactos sinápticos de la otra. Al parecer, las
  neuronas motoras compiten entre sí por los contactos sináptícos con las
  células musculares y las sinapsis activas adquieren prioridad.</p>
<h3>Efectos
  de la experiencia sobre los mapas corticales sensitivos
  topográficos</h3>
<p>En segundo lugar, Knudsen y Brainard (1991) criaron lechuzas con
  prismas en sus ojos que distorsionaban la visión. Esto llevó a un cambio
  correspondiente en el mapa auditivo espacial del tectum. Por ejemplo,
  una lechuza que fue criada llevando prismas que giraban el mundo visual
  23º hacia la derecha tenía un mapa auditivo que estaba también girado
  23º hacia la derecha, de modo que los objetos se oían donde se debían
  ver (véase Gutfreund, Zheng y Knudsen, 2002; Millar y Knudsen,
  1999).</p>
<p>En cuarto lugar, varios estudios han demostrado que la formación
  musical temprana influye en la organización de la corteza auditiva
  humana (véase Münte, Altenmüller y Jänke, 2002). En particular, los
  estudios de RMf han demostrado que la formación musical temprana tiende
  a expandir el área de corteza auditiva que responde a los tonos
  musicales complejos, y los estudios comportamentales han puesto de
  manifiesto que la formación musical temprana lleva al desarrollo del
  oído absoluto (la capacidad de identificar el tono de cualquier
  frecuencia de vibración sonora).</p>
<h3>Mecanismos
  por los que la experiencia puede influir en el desarrollo neural</h3>
<p>El problema no es la falta de posibles mecanismos, sino más bien que
  son demasiados (véase Gottlieb, 2000). A continuación se indican tres
  posibilidades.</p>
<ol>
  <li>En primer lugar, se ha demostrado que la actividad neural regula la
    expresión de genes que dirigen la síntesis de moléculas de adherencia
    celular (MACs). Así, al influir en la actividad neural, la experiencia
    podría producir cambios en la adherencia celular.
  </li>
  <li>En segundo lugar, se ha comprobado que la actividad neural influye
    en la liberación de neurotrofinas (Thoenen, 1995). Por lo tanto, al
    influir sobre la actividad neural, la experiencia podría fomentar y
    dirigir el crecimiento de neuronas e influir en su supervivencia.
  </li>
  <li>En tercer lugar, algunos circuitos neurales están espontáneamente
    activos en una etapa temprana del curso del desarrollo cerebral, y para
    que progresen normalmente ciertos aspectos del desarrollo cerebral se
    requiere la actividad de estos circuitos (Huberman et al., 2003). De
    este modo, influyendo en la actividad de circuitos neurales
    espontáneamente activos, la experiencia podría influir en el curso del
    desarrollo del cerebro.
  </li>
</ol>
<h2>Plasticidad neural en
  adultos</h2>
<p>Hasta la última década se pensaba que la neuroplasticidad se
  restringía al período de desarrollo del cerebro. Los cerebros maduros se
  consideraban estancados, incapaces de una reorganización sustancial.
  Ahora es evidente que los cerebros maduros también tienen plasticidad.
  Ha quedado claro que el cerebro maduro no es un órgano estático, sino
  que está cambiando y adaptándose continuamente. Descubrir la naturaleza
  de estos cambios es en la actualidad una de las máximas prioridades de
  la investigación neurocientífica (véase Kolb, Gibb y Robinson,
  2003).</p>
<p>y de que la cantidad de nuevas neuronas que se añaden al hipocampo
  adulto es sustancial, se calcula que unas 2.000 por hora (West,
  Slomianka y Gunderson, 1991).</p>
<p>¿De donde proceden las neuronas creadas por la neurogénesis adulta?
  Las células madre [hemocitoblastos] adultas se producen en lugares
  determinados de la capa ependimaria que rodea los ventrículos y en la
  capa de tejido neural adyacente (Momma, Johansson y Frisén, 2000;
  Morshead y van der Kooy, 2001); desde aquí migran a los bulbos
  olfativos. Por lo contrario, parece ser que las nuevas células
  hipocampales se producen cerca de su emplazamiento final.</p>
<p>Resultó que las ratas adultas que habitaban en ambientes
  «enriquecidos» (ambientes cambiantes, con juguetes, ruedas giratorias y
  otras ratas) producían un 60% más de nuevas neuronas hipocampales que
  las ratas adultas que habitaban en ambientes no enriquecidos (Kempermann
  y Gage, 1999).</p>
<p>No obstante, antes de que el lector empiece a «enriquecer» su casa,
  ha de ser consciente de que el efecto positivo observado en la
  neurogénesis en el hipocampo de la rata adulta no es una consecuencia
  directa de los ambientes enriquecidos. El efecto depende en gran medida,
  si no en su totalidad, del aumento de ejercicio físico que suele darse
  en tales ambientes (Farmer et al., 2004; Van Praag et al., 1999). Este
  descubrimiento tiene una implicación sugerente: en vista del hecho de
  que el hipocampo está implicado en ciertos tipos de memoria (véase Duffy
  et al., 2001; Rhodes et al., 2002), tal vez pueda utilizarse el
  ejercicio como un tratamiento para aquellos que padecen problemas de
  memoria (Cottman y Berchtold, 2002).</p>
<h3>Efectos
  de la experiencia sobre la reorganización de la corteza en adultos</h3>
<p>Sorprendentemente, la experiencia en la vida adulta puede llevar a
  una reorganización de los mapas corticales <strong>sensitivos y
    motores</strong> (véase, p.ej., Jones, 2000; Sanes y Donoghue, 2000).
  Por ejemplo, Mühlnickel y colaboradores (1998) hallaron que el acúfeno
  (zumbido de oídos) produce una reorganización notable en la corteza
  auditiva primaria; por su parte Elbert y colaboradores (1995)
  demostraron que los músicos adultos que interpretan instrumentos de
  cuerda que se tocan con los dedos de la mano izquierda (p.ej., el
  violín) tienen aumentada el área de representación de la mano en la
  corteza somatosensitiva derecha. Los datos sugieren que es la práctica
  de la habilidad, más que la fortaleza o la tenacidad de la práctica, lo
  que lleva a la reorganización de la corteza motora (Remple et al.,
  2001).</p>
<h1>Daño cerebral y plasticidad
  neural</h1>
<h2>Causas del daño cerebral</h2>
<p>Este apartado aporta una introducción a seis causas del daño
  cerebral: tumores cerebrales, trastornos cerebrovasculares, traumatismos
  craneoencefálicos cerrados, infecciones cerebrales, neurotoxinas y
  factores genéticos. Finaliza con un análisis de la muerte celular
  programada, la cual media muchas formas de daño cerebral.</p>
<h3>Tumores cerebrales</h3>
<p>Un tumor, o neoplasia, (literalmente «nueva proliferación») consiste
  en una masa de células que proliferan independientemente del resto del
  organismo (véase Wechsler-Reya y Scott, 2001). En otras palabras, es un
  cáncer. Alrededor del 20 por ciento de los tumores que se han encontrado
  en el encéfalo humano son meningiomas (véase la Figura 10.1) —tumores
  que se desarrollan entre las meninges, las tres membranas que recubren
  el sistema nervioso central—. Todos los meningiomas son tumores
  encapsulados —tumores que se desarrollan dentro de su propia membrana—.
  En consecuencia, son particularmente fáciles de detectar mediante una
  exploración con TAC, sólo pueden influir en la función cerebral por la
  presión que ejercen sobre el tejido circundante y casi siempre son
  tumores benignos —tumores que se pueden extirpar quirúrgicamente con
  poco riesgo de que vuelvan a desarrollarse en el organismo (véase
  Grimson et al., 1999).</p>
<p>Desafortunadamente, cuando se trata de tumores cerebrales, el que
  estén envueltos por membranas es la excepción, más que la regla. Aparte
  de los meningiomas, la mayoría de los tumores encefálicos son
  infiltrantes. Los <strong>tumores infiltrantes</strong> son aquellos que
  crecen de un modo difuso a través del tejido que los rodea. En
  consecuencia, suelen ser tumores malignos: es difícil extirparlos o
  eliminarlos por completo, y cualquier tejido canceroso que permanezca
  después de la cirugía sigue desarrollándose.</p>
<h3>Isquemia cerebral</h3>
<p>La
  isquemia cerebral es una alteración del riego sanguíneo a una región del
  encéfalo. Las tres causas principales de la isquemia cerebral son</p>
<ul>
  <li>En la trombosis, se forma un tapón, denominado trombo, que bloquea
    el riesgo sanguíneo en el punto donde se ha formado. Un trombo puede
    estar compuesto por un coágulo de sangre, grasa, aceite, una burbuja de
    aire, células tumorales, o cualquier combinación de éstas.
  </li>
  <li>La embolia es similar, salvo por el hecho de que el tapón, llamado
    émbolo en este caso, es transportado por la sangre desde un vaso más
    grande, donde se ha formado, hasta un vaso más pequeño, donde se aloja;
    básicamente, un émbolo es un trombo que ha viajado
  </li>
  <li>En la arterioesclerosis, las paredes de los vasos sanguíneos se
    endurecen y los conductos se estrechan, por lo general como resultado de
    depósitos grasos; este estrechamiento puede llevar finalmente a la
    oclusión completa de los vasos sanguíneos (Libby, 2002)
  </li>
</ul>
<p>Gran parte del daño que produce la isquemia cerebral tarda uno o dos
  días en desarrollarse por completo y, paradójicamente, algunos de los
  propios neurotransmisores del cerebro desempeñan un papel clave en el su
  desarrollo (Wahlgren y Ahmed, 2004). Gran parte del daño cerebral que se
  asocia con el accidente cerebrovascular se debe a la excesiva liberación
  de neurotransmisores aminoácidos excitadores, en concreto de glutamato,
  el neurotransmisor excitador que predomina en el encéfalo.</p>
<h3>Traumatismo
  craneoencefálico cerrado</h3>
<p>Resulta curioso que la misma dureza del cráneo, que protege al
  encéfalo de lesiones perforantes, sea el principal factor que ocasione
  contusiones. Las contusiones producidas por traumatismos
  craneoencefálicos cerrados ocurren cuando el encéfalo se golpea
  violentamente dentro del cráneo. Como se muestra en la Figura 10.6, la
  sangre que producen estas lesiones puede acumularse en el espacio
  subdural —espacio entre las membranas duramadre y aracnoides— y deformar
  gravemente en el tejido nervioso que lo rodea. Puede que al lector le
  sorprenda enterarse de que las contusiones se dan con frecuencia en el
  lado opuesto del encéfalo dañado por el golpe. La razón de estas
  <strong>llamadas lesiones por contragolpe</strong> es que el impacto
  hace que el encéfalo se golpee dentro del cráneo contra el otro lado de
  la cabeza.</p>
<p>Cuando hay una alteración de la consciencia después de un golpe en la
  cabeza y no hay evidencia de que haya una contusión u otros daños
  estructurales, el diagnóstico es el de <strong>conmoción
    cerebral</strong>. Por lo general se asume que estas conmociones
  conllevan una alteración temporal del funcionamiento cerebral normal,
  sin una lesión a largo plazo. Sin embargo, el síndrome «punch-drunk»
  sugiere algo distinto.</p>
<p>El <strong>síndrome punch-drunk</strong> consiste en la demencia
  (deterioro intelectual general) y las cicatrizaciones cerebrales que se
  observan en boxeadores y otras personas que sufren repetidamente una
  conmoción cerebral. Si no se produjera una lesión por una única
  conmoción, los efectos de muchas conmociones no se sumarían para
  producir una lesión grave (McCrory y Berkovic, 1998).</p>
<p>Uno de los aspectos más peligrosos de las conmociones es la poca
  importancia que el sujeto les concede. Referirse a ellas de un modo tan
  frívolo como «haber visto las estrellas» transmiten poco acerca de sus
  peligros.</p>
<h3>Neurotoxinas</h3>
<p>El sistema nervioso puede resultar dañado por la exposición a
  cualquiera de una serie de sustancias químicas tóxicas, que pueden
  penetrar en la circulación general procedentes del tubo digestivo, de
  los pulmones o a través de la piel. Por ejemplo, los metales pesados
  tales como el mercurio y el plomo pueden acumularse en el encéfalo y
  dañarlo de forma permanente, produciendo una psicosis tóxica (demencia
  crónica producida por una neurotoxina).</p>
<h3>Factores genéticos</h3>
<p>Los trastornos neuropsicológicos hereditarios rara vez se asocian con
  genes dominantes ya que los genes dominantes que alteran la función
  neuropsicológica tienden a ser eliminados de la reserva genética —cada
  individuo que porta uno tiene una mayor desventaja para sobrevivir y
  reproducirse—. Por lo contrario, quienes heredan un gen recesivo anormal
  no manifiestan el trastorno, y el gen se transmite a las generaciones
  siguientes.</p>
<p>Hay, sin embargo, dos situaciones posibles en las que los trastornos
  neurológicos pueden asociarse con genes dominantes.</p>
<ol>
  <li>Una es el caso en que un gen dominante anómalo se manifiesta
    solamente en circunstancias ambientales poco comunes.
  </li>
  <li>La otra es el caso en que un gen dominante anómalo no se expresa
    hasta que el sujeto ha pasado con creces la pubertad
  </li>
</ol>
<p>La probabilidad de parir un bebé con síndrome de Down aumenta a
  medida que aumenta la edad de la madre (Carothers et al., 2001).</p>
<h3>Muerte celular programada</h3>
<p>La muerte celular programada también interviene en el daño cerebral.
  En realidad, parece que cada una de las seis causas de daño cerebral que
  ya se han analizado en este capítulo (tumores, trastornos
  cerebrovasculares, lesiones por traumatismo craneoencefálico cerrado,
  infecciones, toxinas y factores genéticos) produce sus efectos, en
  parte, activando programas de autodestrucción (Allsop y Fazakerley,
  2000; Dirnagl, Simon y Hallenbeck, 2003; Nijhawan, Jonarpour y Wang,
  2000).</p>
<p>En un principio se asumió que la muerte de neuronas tras daño
  cerebral era en su totalidad necrótica —la necrosis es la muerte celular
  pasiva resultante de una lesión—. Ahora parece ser que si las células no
  están dañadas demasiado gravemente intentarán conseguir recursos
  suficientes para suicidarse. No obstante, la muerte celular no es una
  situación exclusivamente de uno u otro tipo: algunas células lesionadas
  y moribundas manifiestan signos tanto de necrosis como de muerte celular
  programada (véase Elibol et al., 2001).</p>
<p>Es fácil entender por qué han evolucionado los mecanismos de muerte
  celular programada: ésta es claramente más adaptativa que la necrosis.
  En la necrosis, las células dañadas se hinchan y se rompen comenzando
  por los axones y las dendritas y terminando en el soma celular. Esta
  fragmentación lleva a la inflamación, que puede dañar a otras células
  vecinas. La muerte celular necrótica es rápida, por lo general se
  completa en unas cuantas horas. En contraposición, la muerte celular
  programada es lenta, suele requerir un día o dos. La muerte celular
  programada de una neurona procede gradualmente, comenzando por el
  encogimiento del cuerpo celular. Luego, cuando partes de la neurona
  mueren, los desechos resultantes se empaquetan en vesículas. En
  consecuencia, no hay inflamación y el daño de las células vecinas se
  mantiene en un mínimo.</p>
<h2>Síndromes neuropsicológicos</h2>
<h3>Epilepsia</h3>
<p>El síntoma principal de la epilepsia es la crisis epiléptica, pero no
  se asume que todas las personas que sufren crisis epilépticas tengan
  epilepsia. No es infrecuente que una persona por lo demás sana sufra una
  crisis durante una enfermedad temporal o después de haber estado
  expuesto a un agente convulsivo. La etiqueta de epilepsia se aplica sólo
  a los pacientes cuyas crisis parecen estar generadas por su propia
  disfunción cerebral crónica. Alrededor de un uno por ciento de la
  población recibe un diagnóstico de epilepsia en algún momento de su
  vida.</p>
<p>Son muchas las causas de la epilepsia. De hecho, todas las causas de
  daño cerebral que se han descrito en este capítulo —incluyendo virus,
  neurotoxinas, tumores y golpes en la cabeza— pueden provocar epilepsia,
  y se han relacionado con ella unos 70 genes defectuosos diferentes
  (Noebels, 2003). Muchos casos de epilepsia parecen estar asociados con
  fallos en las sinapsis inhibidoras que hacen que una gran cantidad de
  neuronas disparen en salvas sincronizadas (Köhling, 2002).</p>
<p>El <strong>diagnóstico</strong> de epilepsia se basa en gran medida
  en la electroencefalografía (EEG). El valor de la electroencefalografía
  registrada sobre el cuero cabelludo [EEG de superficie] en casos en los
  que se sospecha epilepsia deriva del hecho de que las crisis epilépticas
  se asocian con salvas de puntas EEG de alta amplitud, las cuales a
  menudo se revelan en el EEG de superficie durante una crisis (véase la
  Figura 10.8), así como del hecho de que, en los períodos libres de
  crisis, el EEG de superficie de las personas con epilepsia a menudo está
  salpicado de puntas aisladas (Cohen et al., 2002).</p>
<p>Algunos pacientes con epilepsia sufren cambios psicológicos
  característicos justo antes de una convulsión. Estos cambios, llamados
  <strong>aura epiléptica</strong> , pueden adoptar muchas formas
  diferentes —por ejemplo, un olor desagradable, un pensamiento concreto,
  una sensación vaga de familiaridad, una alucinación o una opresión en el
  pecho—. Las auras epilépticas son importantes debido a dos razones.
  Primera, la naturaleza de las auras aporta pistas importantes respecto a
  la localización del foco epiléptico. Segunda, ya que las auras
  epilépticas que experimenta un determinado paciente en una crisis y otra
  suelen parecerse, avisan al paciente de una convulsión inminente.</p>
<h4>Crisis parciales</h4>
<p>Una crisis parcial es una crisis que no afecta a todo el encéfalo.
  Las neuronas epilépticas de un foco comienzan a disparar todas juntas en
  salvas, y es este disparo sincrónico de las neuronas lo que genera el
  patrón de puntas epilépticas en el EEG.</p>
<p>Hay dos categorías principales de crisis parciales: simples y
  complejas.</p>
<ul>
  <li>Las <strong>crisis parciales simples</strong> son crisis parciales
    cuyos síntomas son fundamentalmente sensitivos, motores o de ambos
    tipos; a veces se les llama crisis jacksonianas, en alusión al famoso
    neurólogo del siglo XIX, Hughlings Jackson. A medida que las descargas
    epilépticas se propagan por las áreas sensitivas o motoras del cerebro,
    los síntomas se propagan sistemáticamente por el cuerpo.
  </li>
  <li>En contraposición, las <strong>crisis parciales complejas</strong> a
    menudo se restringen a los lóbulos temporales, y de quienes las sufren
    se dice que padecen epilepsia del lóbulo temporal. Durante una crisis
    parcial compleja, el paciente realiza conductas sencillas, compulsivas y
    repetitivas, que se designan habitualmente automatismos (p.ej.,
    abrocharse y desabrocharse un botón) y conductas más complejas que
    parecen casi normales. Aunque parece que los pacientes están conscientes
    durante las crisis complejas parciales, habitualmente recuerdan muy poco
    o no recuerdan nada de ellas. Aproximadamente la mitad de todos los
    casos de epilepsia son de tipo parcial complejo —los lóbulos temporales
    tienen una especial predisposición a desarrollar descargas
    epilépticas—.
  </li>
</ul>
<p>La diversidad que presentan las crisis parciales complejas se refleja
  en los cuatro casos siguientes.</p>
<figure class="tablap normal">
  <table>
    <thead>
    <tr>
      <th colspan=2>La sutileza de las crisis parciales complejas: cuatro casos</th>
    </tr>
    </thead>
    <tbody>
    <tr>
      <td>
        Un veterano de guerra que padecía muchos automatismos leyó en el periódico que un hombre había abrazado a una
        mujer en un parque, la había seguido hasta los aseos de mujeres, y luego había subido a un autobús. Por la
        descripción que se daba, se dio cuenta de que él era ese hombre.
      </td>
      <td>
        Una mañana, un médico salió de casa para atender una llamada de urgencia del hospital y volvió varias horas
        después, un tanto confundido, con la sensación de haber tenido un mal sueño. En el hospital había llevado a cabo
        una [intervención quirúrgica] difícil... con su competencia habitual, pero luego había hecho y dicho cosas que
        se consideran imprudentes.
      </td>
    </tr>
    <tr>
      <td>
        Un hombre joven, profesor de música, mientras asistía a un concierto, se dirigió por el pasillo hasta el
        estrado, dio la vuelta alrededor del piano, dio saltos sobre el suelo, saltó a la pata coja, dio brincos, saltó
        de nuevo al pasillo, y recuperó el juicio a mitad de camino hacia su casa. A menudo se encontraba de pronto en
        un tranvía [autobús] lejos de su destino.
      </td>
      <td>
        Durante una crisis, un hombre se dirigió a su jefe y le dijo: «Necesito ganar más dinero o me voy». Más tarde,
        para su sorpresa, se encontró con que le habían aumentado el sueldo.
      </td>
    </tr>
    </tbody>
  </table>
</figure>
<h4>Crisis generalizadas</h4>
<p>Las crisis generalizadas afectan a todo el encéfalo. Algunas
  comienzan como descargas focales que gradualmente se extienden por todo
  el encéfalo. En otros casos, las descargas parecen iniciarse casi
  simultáneamente en todas las partes del encéfalo</p>
<p>Al igual que las crisis parciales, las crisis generalizadas se
  producen de muchas formas.</p>
<ol>
  <li>Una de ellas es la <strong>convulsión tonicoclónica
    generalizada</strong> (literalmente, «gran dolencia»). Los síntomas
    primordiales de una convulsión tonicoclónica generalizada son pérdida de
    consciencia, pérdida de equilibrio, y una violenta convulsión
    tónico-clónica —convulsión que implica tanto al tono [rigidez] como al
    clono [temblores]—.
  </li>
  <li>La segunda categoría principal de crisis generalizada es la
    <strong>ausencia típica</strong> (literalmente, «pequeña dolencia»)
    (véase Crunelli y Leresche, 2002). Las ausencias típicas no se asocian
    con convulsiones: su síntoma comportamental más destacado es la ausencia
    de pequeño mal —alteración de la consciencia que se asocia con un cese
    de la conducta que se está desarrollando, una mirada vacía y, en
    ocasiones, agitación de los párpados—.
  </li>
</ol>
<h4>Modelo de
  activación propagada de la epilepsia</h4>
<p>En 1969, Goddard, McIntyre y Leech aplicaron una leve estimulación
  eléctrica al día a ratas mediante electrodos implantados en la amígdala.
  No hubo respuesta comportamental a unas cuantas primeras estimulaciones,
  pero pronto cada estimulación comenzó a provocar una respuesta
  convulsiva. Las primeras convulsiones fueron moderadas, implicando sólo
  un ligero temblor de la cara. Sin embargo, con cada estimulación
  posterior las convulsiones provocadas se hicieron más generalizadas
  hasta que cada convulsión afectó a todo el cuerpo.</p>
<p>El desarrollo progresivo y la intensificación de las convulsiones
  inducidas por una serie de estimulaciones cerebrales periódicas llegaron
  a conocerse como fenómeno de activación propagada [«kindling»].</p>
<p>La activación propagada presenta muchas características interesantes
  (véase Racine y Burnham, 1984; Wada, 1990b), si bien hay dos que merece
  la pena destacar. La primera es que los cambios neurales que subyacen a
  la activación propagada son permanentes. Un sujeto que ha sido sometido
  a ella y al que luego se ha dejado de estimular durante varios meses
  sigue respondiendo a cada estimulación de baja intensidad con una
  convulsión generalizada (Goddard, McIntyre y Leech, 1969; Wada y Sato,
  1974). La segunda es que la activación propagada se origina por la
  estimulación distribuida, en oposición a la masiva. Si los intervalos
  entre estimulaciones sucesivas son menores de una o dos horas,
  habitualmente se precisan más estimulaciones para activar en exceso a un
  sujeto y, en condiciones normales, no se da ningún grado de activación
  propagada si los intervalos son menores de 20 minutos (Racine et al.,
  1973).</p>
<h2>Respuestas
  de plasticidad neural al daño del sistema nervioso: degeneración,
  regeneración, reorganización y recuperación</h2>
<p>El daño del sistema nervioso puede desencadenar cuatro respuestas de
  neuroplasticidad: degeneración, regeneración,</p>
<p>reorganización y recuperación de la función.</p>
<h3>Degeneración neuronal</h3>
<p>Un método muy utilizado para el estudio controlado de las respuestas
  de las neuronas al daño es seccionar sus axones. A esto le siguen dos
  tipos de degeneración (deterioro) neuronal: degeneración anterógrada y
  degeneración retrógrada (véase Coleman y Perry, 2002; Raff, Whitmore y
  Finn, 2002). La degeneración anterógrada consiste en la degeneración del
  segmento distal —la parte del axón seccionado que queda entre el corte y
  los terminales sinápticos—. La degeneración retrógrada consiste en la
  degeneración del segmento proximal —la parte del axón seccionado que
  queda entre el corte y el cuerpo celular.</p>
<h3>Regeneración neuronal</h3>
<p>La
  regeneración neuronal —nuevo crecimiento de las neuronas dañadas— no se
  da con tanto éxito en los mamíferos y otros vertebrados superiores como
  en la mayoría de los invertebrados y los vertebrados inferiores. La
  capacidad de crecimiento axónico certero, capacidad que poseen los
  vertebrados superiores durante su desarrollo original, se pierde una vez
  que se alcanza la madurez. La regeneración prácticamente no existe en el
  SNC de los mamíferos adultos y en el SNP, en el mejor de los casos, es
  una cuestión de lotería.</p>
<p>En el SNP de los mamíferos, el nuevo crecimiento a partir del muñón
  proximal de un nervio lesionado suele comenzar dos o tres días después
  de haberse dañado. Lo que sucede luego depende del tipo de lesión (véase
  Tonge y Golding, 1993). Hay tres posibilidades.</p>
<ol>
  <li>Primera, si la vaina de mielina original de la célula de Schwann
    permanece intacta, los axones periféricos que se están regenerando
    crecen a su través hasta su lugar de destino original, a un ritmo de
    unos cuantos milímetros al día.
  </li>
  <li>Segunda, si se secciona el nervio periférico y los extremos cortados
    quedan separados unos pocos milímetros, los extremos del axón que se
    está regenerando suelen crecer dentro de vainas equivocadas y son
    guiados por ellas hacia destinos equivocados. Ésta es la razón por la
    que a menudo resulta difícil recuperar el uso coordinado de una
    extremidad afectada por una lesión nerviosa, incluso si se ha producido
    una regeneración substancial.
  </li>
  <li>Y tercera, si los extremos cortados del nervio periférico seccionado
    de un mamífero quedan muy separados o si se daña una extensa sección del
    nervio, puede que no se produzca ninguna regeneración significativa: los
    extremos del axón que se está regenerando crecen de forma enmarañada en
    torno al muñón proximal, y la neurona termina muriendo.
  </li>
</ol>
<p>Es evidente que sucede algo en el ambiente del SNP que promueve la
  regeneración, y algo en el ambiente del SNC que no lo hace (Goldberg y
  Barres, 2000). Las células de Schwann son la clave del problema.</p>
<ul>
  <li>Las <strong>células de Schwann</strong> , que recubren de mielina
    los axones del SNP, favorecen la regeneración en el SNP de los mamíferos
    produciendo tanto factores neurotróficos como moléculas de adhesión
    celular (MAC). Los factores neurotróficos liberados por las células de
    Schwann estimulan el crecimiento de nuevos axones, y las moléculas de
    adhesión celular de las membranas celulares de las células de Schwann
    aportan las vías a lo largo de las cuales se desarrollan los axones en
    proceso de regeneración en el SNP.
  </li>
  <li>Por lo contrario, la <strong>oligodendroglia</strong> , que
    proporciona mielina a los axones del SNC, no estimula ni guía la
    regeneración; de hecho, libera factores que impiden activamente la
    regeneración (Filbin, 2003; Fournier y Strittmatter, 2001).
  </li>
</ul>
<p>Cuando
  un axón degenera, de los axones ilesos adyacentes crecen ramificaciones
  que establecen sinapsis en los lugares que ha dejado vacíos el axón que
  ha degenerado; esto se denomina crecimiento de brotes colaterales.
  <strong>Los brotes colaterales</strong> pueden crecer de las ramas
  terminales del axón o de los nódulos de Ranvier de las neuronas
  adyacentes. El crecimiento de brotes colaterales se ilustra en la Figura
  10.17.</p>
<h3>Reorganización neuronal</h3>
<p>Desde hace mucho tiempo se ha supuesto que los principales cambios en
  el sistema nervioso de los mamíferos se confinan al período de las
  primeras fases de desarrollo: se pensaba que los cambios en el sistema
  nervioso de los mamíferos adultos se limitaban a los sutiles cambios
  funcionales que median el aprendizaje y la memoria. Sin embargo, como se
  expuso en el Capítulo 9, recientemente se ha descubierto que el cerebro
  del mamífero adulto conserva la capacidad de reorganizarse en respuesta
  a la experiencia. También conserva la capacidad de reorganizarse en
  respuesta a las lesiones.</p>
<p>Se han propuesto dos tipos de mecanismos para explicar la
  reorganización de los circuitos neuronales:</p>
<ul>
  <li>un
    fortalecimiento de las conexiones existentes, posiblemente mediante la
    liberación de la inhibición y
  </li>
  <li>el establecimiento de nuevas conexiones mediante el crecimiento de
    brotes colaterales (véase O’Leary, Ruff y Dyck, 1994).
  </li>
</ul>
<p>A favor del primer mecanismo están dos observaciones: la
  reorganización se produce a menudo demasiado rápidamente para que pueda
  explicarse mediante crecimiento neuronal, y la reorganización rápida
  nunca conlleva cambios de más de 2 milímetros de superficie cortical. A
  favor del segundo mecanismo está la observación de que la magnitud de la
  reorganización a largo plazo puede ser demasiado grande</p>
<p>Durante años parecía ser que la reorganización neural era la única
  explicación de la recuperación del daño del SNC. No obstante, el
  descubrimiento de la neurogénesis en adultos dio lugar a otra
  posibilidad: tal vez la prolif eración neuronal intervenga en dicha
  recuperación, en particular cuando el daño afecta al hipocampo. Hace
  poco se ha demostrado (véase Kokaia y Lindvall, 2003) que la isquemia
  cerebral, la cual daña preferentemente al hipocampo, aumenta la
  neurogénesis en adultos; que muchas de estas nuevas células llegan a
  formar parte del hipocampo; y que estas nuevas células establecen
  sinapsis y se convierten en neuronas maduras —véase la Figura
  10.21)—.</p>
<h3>Recuperación de
  la función tras daño cerebral</h3>
<p>Se trató el hipocampo de las ratas del grupo experimental con virus
  creados por ingeniería genética para que liberasen una proteína
  inhibidora de la muerte celular programada. Sorprendentemente, la
  proteína inhibidora de la muerte celular programada previno tanto la
  pérdida de neuronas hipocampales como la disminución del rendimiento en
  el laberinto de agua de Morris.</p>
<p>En modelos animales y en cultivos celulares se ha encontrado que los
  <strong>estrógenos</strong> limitan o retrasan la muerte neuronal, y hay
  también algunos datos en pacientes humanos que lo apoyan. Tales efectos
  neuroprotectores de los estrógenos pueden explicar por qué varios
  trastornos cerebrales (p.ej., la enfermedad de Parkinson) tienen mayor
  prevalencia en los hombres que en las mujeres. En general, las moléculas
  que limitan la degeneración neural también favorecen la
  regeneración.</p>
<p>Aunque la regeneración no se da normalmente en el SNC de los
  mamíferos, varios estudios han señalado que puede inducirse. Los tres
  estudios siguientes son particularmente prometedores ya que han
  demostrado que dicha regeneración puede asociarse con una recuperación
  funcional.</p>
<p>Cheng, Cao y Olson (1996) seccionaron la médula espinal de ratas,
  haciéndolas así parapléjicas (con parálisis en la parte posterior del
  cuerpo). Luego los investigadores transplantaron secciones de nervio
  periférico mielinizado de un lado a otro del corte. Como resultado, las
  neuronas de la médula espinal se regeneraron a través de las vainas de
  mielina de las células de Schwann implantadas, y la regeneración
  permitió que las ratas recobraran el uso de sus patas traseras.</p>
<h3>Activación
  de la recuperación del daño del SNC mediante ejercicios de
  rehabilitación</h3>
<p>Su procedimiento, llamado terapia inducida por restricción (Taub,
  Uswatte y Elbert, 2002), consistió en mantener sujetado el brazo útil
  durante dos semanas mientras se sometía al brazo afectado a
  entrenamiento intensivo. La ejecución con el brazo afectado mejoró
  marcadamente a lo largo de las dos semanas y se produjo un aumento del
  área de la corteza motora que controla dicho brazo.</p>
<p>El <strong>Dr.Ramachandran</strong> aplicó un poco de ingenio
  biopsicológico al problema. ¿Podría aliviar el dolor de F. enseñándole a
  mover su brazo fantasma? Sabiendo lo importante que es la
  retroalimentación en el movimiento (véase el Capítulo 8), el
  Dr.Ramachandran construyó un aparato de retroalimentación especial para
  F. Este consistía en una caja dividida en dos por un espejo vertical. Se
  le pidió a F. que metiera su mano derecha ilesa dentro de la caja a
  través de un agujero en la parte frontal y lo mirara a través de un
  agujero en la parte superior. Cuando miraba su mano, podía ver ésta y su
  imagen en el espejo. Se le pidió que colocara su miembro fantasma dentro
  de la caja tratando de posicionarlo, lo mejor que pudiera, de modo que
  se correspondiera con la imagen del espejo de su mano ilesa. Luego, se
  le pidió que hiciera movimientos simétricos, sincronizados y
  bilaterales, de sus brazos —su brazo derecho real y su brazo izquierdo
  fantasma— mientras veía su brazo ileso y su imagen en el espejo.</p>
<h1>Aprendizaje, memoria y
  amnesia</h1>
<p>Aprendizaje y memoria son dos modos de pensar en lo mismo. Ambos
  términos se refieren a la capacidad del cerebro de cambiar su
  funcionamiento en respuesta a la experiencia: El de
  <strong>aprendizaje</strong> hace referencia a cómo la experiencia
  cambia el cerebro, y el de <strong>memoria</strong> a cómo estos cambios
  se almacenan y posteriormente se reactivan.</p>
<p>A los recuerdos conscientes se les denomina <strong>memoria
  explícita</strong> , mientras que a los recuerdos que se manifiestan
  mediante una mejora en el rendimiento en una prueba sin que el sujeto
  tenga consciencia de ello, se les llama <strong>memoria
    implícita</strong>.</p>
<p>La <strong>memoria semántica</strong> consiste en recuerdos
  explícitos de hechos o información de carácter general, mientras que la
  <strong>memoria episódica</strong> está formada por recuerdos explícitos
  de acontecimientos o experiencias concretas de la vida de cada uno.</p>
<p>Los
  golpes en la cabeza que no penetran el cráneo, pero que son lo
  suficientemente graves como para producir conmoción cerebral (alteración
  temporal de la conciencia producida por una herida en la cabeza sin
  penetración) son la causa más frecuente de amnesia (véase Levin, 1989).
  La amnesia que sigue a un golpe en la cabeza sin que penetre el cráneo
  se denomina <strong>amnesia postraumática</strong> (APT).</p>
<p>El <strong>coma</strong> (estado patológico de inconsciencia) que
  sigue a un fuerte golpe en la cabeza suele durar unos segundos o
  minutos, pero en casos graves puede durar semanas. Luego, cuando el
  paciente recobra la consciencia, se da un período de confusión. Quienes
  han sufrido una conmoción cerebral por lo general no son examinados por
  un neuropsicólogo hasta después del período de confusión ⎯si es que se
  les examina⎯. La evaluación a menudo pone de manifiesto que el paciente
  tiene una amnesia retrógrada permanente de los acontecimientos que han
  precedido inmediatamente a la contusión y una amnesia anterógrada
  permanente de muchos de los acontecimientos que han ocurrido durante el
  período posterior de confusión.</p>
<p>Nadel y Moscovitch propusieron que el hipocampo y otras estructuras
  implicadas en el almacenamiento de recuerdos almacenan recuerdos
  mientras existen ⎯no sólo durante el período inmediatamente después del
  aprendizaje⎯. Cuando ocurre una experiencia consciente, se codifica
  rápida y pobremente de forma distribuida por todo el hipocampo y otras
  estructuras relacionadas. Según Nadel y Moscovitch, los recuerdos
  retenidos van siendo progresivamente más resistentes a ser alterados por
  daño hipocámpico debido a que cada vez que tiene lugar una experiencia
  similar o se rememora el recuerdo original, se establece un nuevo
  <strong>engrama</strong> (un cambio en el encéfalo que sirve para
  almacenar recuerdos) y se vincula al engrama original, lo que hace que
  resulte más fácil recuperar el recuerdo y más difícil alterar el engrama
  original.</p>
<h2>Hipocampo y
  memoria de localización espacial</h2>
<p>El descubrimiento de que la corteza entorrinal tiene una función más
  importante que el hipocampo en el reconocimiento de objetos no significa
  que el hipocampo no juegue un papel significativo en la memoria. Por
  descontado que el hipocampo juega un papel clave en la memoria de
  localización espacial.</p>
<p>Coherente con la observación de que las lesiones del hipocampo
  alteran la memoria espacial está el hecho de que muchas neuronas del
  hipocampo son <strong>células de lugar</strong> (Best, White y Minai,
  2001; Brun et al., 2002; Moser y Paulsen 2001) —neuronas que sólo
  responden cuando un sujeto está en un lugar específico (es decir, en los
  campos de lugar de la neurona)—. Por ejemplo, cuando se sitúa por
  primera vez a una rata en un entorno de prueba desconocido, ninguna de
  sus neuronas del hipocampo tiene un campo de lugar en ese entorno;
  posteriormente, a medida que la rata se familiariza con el entorno,
  muchas neuronas piramidales del hipocampo adquieren un campo de lugar
  —esto es, cada una de ellas dispara sólo cuando la rata está en una zona
  concreta del entorno de prueba—. Cada célula de lugar tiene un campo de
  lugar en una parte diferente del entorno.</p>
<p>De particular interés son las investigaciones realizadas con aves que
  almacenan comida. Estas aves han de tener una memoria espacial notable,
  ya que, para sobrevivir, tienen que recordar la localización de cientos
  de escondrijos de comida dispersos por su territorio. En un estudio,
  Sherry y Vacarino (1989) encontraron que las especies que almacenan
  comida suelen tener un hipocampo mayor que las especies de la misma
  familia que no almacenan comida. En efecto, Clayton (2001) halló que la
  actividad de esconder y de recuperar es necesaria para desencadenar el
  crecimiento del hipocampo y mantener su tamaño en los polluelos de
  montaña.</p>
<p>Por último, Brown y Aggleton (2001) han propuesto una teoría
  específica sobre el papel del hipocampo en el reconocimiento de objetos
  y su relación con la de la corteza entorrinal. Están de acuerdo con los
  datos de que la corteza entorrinal, no el hipocampo, interviene en la
  mayor parte de las tareas de reconocimiento de objetos. No obstante,
  sugieren que el hipocampo juega un papel que en el reconocimiento de
  disposiciones espaciales de objetos, como una escena visual, por ejemplo
  (véase Wan, Aggleton y Brown, 1999).</p>
<h2>¿Dónde se almacenan los
  recuerdos?</h2>
<p>Los
  datos sugieren que cada recuerdo se almacena de modo difuso en todas las
  estructuras del encéfalo que han participado en su experiencia original
  (véase Fries, Fernández y Jensen 2003; Nyberg et al., 2000; Wheeler,
  Petersen y Buckner, 2000).</p>
<h3>Corteza temporal inferior</h3>
<p>Naya y sus colegas concluyeron que este patrón de actividad invertido
  reflejaba la recuperación de los recuerdos visuales de la corteza
  temporal inferior.</p>
<h3>Amígdala</h3>
<p>Parece ser que la amígdala desempeña un papel en la memoria del</p>
<p>significado emocional de las experiencias.</p>
<h3>Corteza prefrontal</h3>
<p>Los pacientes con daño de la corteza prefrontal no padecen una
  amnesia muy pronunciada; a menudo no manifiestan síntoma alguno en las
  pruebas habituales de memoria (véase Müller, Machado y Knight, 2002;
  Petrides, 1996). Pero presentan alteraciones de la memoria en cuanto al
  orden temporal de los acontecimientos, aun cuando pueden recordar los
  acontecimientos en sí mismos, así como anomalías de la memoria de
  trabajo (la capacidad de mantener los recuerdos relevantes mientras se
  completa una tarea) ⎯véase Kimberg, D’Esposito y Farah (1998) y Smith
  (2000).</p>
<h3>Cerebelo y neoestriado</h3>
<p>Se piensa que en el <strong>cerebelo</strong> se almacena el recuerdo
  de las habilidades sensitivomotoras que se han aprendido. En particular,
  se ha investigado en profundidad su función en el condicionamiento
  pavloviano de la respuesta de parpadeo en conejos (véase Linden, 2003).
  En este paradigma experimental, se hace sonar un tono (estímulo
  condicionado) justo antes de administrar un soplo de aire al ojo
  (estimulo incondicionado). Tras varios ensayos, el tono llega a provocar
  un parpadeo.</p>
<p>Se cree que en el <strong>neoestriado</strong> se almacenan recuerdos
  de relaciones sistemáticas entre estímulos y respuestas —el tipo de
  recuerdos que se crean gradualmente a lo largo de muchos ensayos (véase
  White, 1997) —. A veces a esta forma de aprendizaje basada en el
  neoestriado se le denomina formación de hábitos (Packard y Knowlton,
  2002; Schultz, Tremblay y Hollermar, 2003).</p>
<h2>Potenciación a largo plazo</h2>
<p>En 1973, Bliss y Lomo demostraron que se da una facilitación de la
  transmisión sináptica después de que se haya aplicado a las neuronas
  presinápticas estimulación eléctrica de alta frecuencia. Este fenómeno
  se ha denominado potenciación a largo plazo (PLP).</p>
<p>La PLP se ha estudiado más exhaustivamente en las sinapsis en las que
  predominan los receptores NMDA (N-metil-D-aspartato). El receptor NMDA
  es un receptor del glutamato —el principal neurotransmisor excitador del
  cerebro—. El receptor NMDA tiene una propiedad especial. No da su máxima
  respuesta a menos que ocurran simultáneamente dos acontecimientos:</p>
<ul>
  <li>que el glutamato se una a él y</li>
  <li>que la neurona postsináptica esté ya parcialmente
    despolarizada.
  </li>
</ul>
<p>Este doble requisito procede del hecho de que los canales de calcio
  ligados a los receptores NMDA sólo permiten que penetre en la neurona
  una pequeña cantidad de iones de calcio, a no ser que la neurona esté ya
  despolarizada cuando el glutamato se une al receptor. Es la entrada de
  iones de calcio lo que desencadena los potenciales de acción y la
  cascada de sucesos fisiológicos en la neurona postsináptica que originan
  la PLP.</p>
<h3>Mantenimiento
  y expresión de la PLP: almacenamiento y recuerdo</h3>
<p>El mantenimiento y la expresión de la PLP implica cambios tanto en
  las neuronas presinápticas como en las postsinápticas. Este
  descubrimiento ha complicado la definición de los mecanismos de
  mantenimiento y expresión (véase Lisman, 2003). No obstante, se han
  producido cinco avances particularmente importantes.</p>
<ul>
  <li>Se ha hecho evidente que los cambios que tienen lugar inmediatamente
    y mantienen la experiencia de estimulación de alta frecuencia durante un
    cierto tiempo no son los mismos que los que mantienen la experiencia
    semanas más tarde. Específicamente, es probable que el mantenimiento a
    largo plazo, dada su permanencia, implique cambios estructurales, los
    cuales dependen de la síntesis de proteínas. La síntesis de proteínas no
    puede ser responsable del mantenimiento a corto plazo ya que no ocurre
    con la suficiente rapidez.
  </li>
  <li>En la actualidad está bien establecido que se producen cambios
    estructurales en las sinapsis NMDA en asociación con la PLP de larga
    duración. Hay un aumento de la cantidad y el tamaño de las sinapsis, de
    la cantidad y el tamaño de las espinas dendríticas y de la cantidad de
    los receptores NMDA postsinápticos (véase Harris, Fiala y Ostroff, 2003;
    Lüscher y Frerking, 2001; Yuste y Bonhoeffer, 2001).
  </li>
</ul>
<p>Además, se ha comprobado que se da PLP en muchas otras partes del
  SNC, donde suele estar mediada por diferentes mecanismos (p.ej.,
  Gaiarsa, Caillard y Ben-Ari, 2002; Ikeda et al., 2003). Y luego está la
  DLP (depresión a largo plazo), el otro lado de la moneda de la PLP. La
  DLP se da en respuesta a una prolongada estimulación de baja frecuencia
  de las neuronas presinápticas (Bliss y Schoepfer, 2004; Lui et al.,
  2004).</p>
<h2>Conclusión</h2>
<p>Tendemos a pensar en la memoria como una capacidad unitaria. Sin
  embargo, las personas con daño cerebral suelen manifestar graves
  alteraciones en un proceso de memoria pero no en otros. Puesto que este
  capítulo se ha centrado preferentemente en los efectos amnésicos del
  daño cerebral, el lector se puede haber quedado con la impresión de que
  las disociaciones entre varios tipos de memoria tienen poca relación
  directa con las personas con cerebros sanos, indemnes.</p>
<p>Todos experimentamos amnesia infantil, es decir: prácticamente no
  recordamos ninguno de los sucesos de nuestra infancia (Howe, 2003).
  Newcombe y sus colegas (2000) plantearon la siguiente cuestión: ¿Los
  niños normales que no logran recordar o reconocer explícitamente cosas
  de su temprana infancia manifiestan memoria implícita de dichas cosas?
  Los resultados de dos experimentos indican que la respuesta es «sí».</p>
<h1>Hambre, ingesta de
  alimentos y salud</h1>
<p>Como
  resultado de la digestión, la energía se suministra al organismo en tres
  formas (véase la Figura 12.1). Estas tres formas son:</p>
<ol>
  <li>lípidos (grasas)</li>
  <li>aminoácidos (el producto de la degradación de las proteínas) y</li>
  <li>glucosa (un azúcar simple, producto del metabolismo de hidratos de
    carbono complejos, es decir, almidones y azúcares complejos).
  </li>
</ol>
<p>El cuerpo utiliza energía continuamente, pero su consumo es
  intermitente. Por lo tanto tiene que almacenar energía para utilizarla
  en los intervalos entre las comidas.</p>
<p>La energía se almacena en tres formas:</p>
<ol>
  <li>grasas,</li>
  <li>glucógeno y</li>
  <li>proteínas.</li>
</ol>
<p>La mayor parte de las reservas energéticas del organismo se almacena
  como grasas; relativamente poca como glucógeno o proteínas (véase la
  Figura 12.2). Así pues, los cambios del peso corporal de los humanos
  adultos se deben en gran parte a cambios en la cantidad de grasa
  corporal.</p>
<p>Dado que el glucógeno, que principalmente se almacena en el hígado,
  se convierte rápido en glucosa —la principal fuente de energía que puede
  utilizar directamente el organismo—, se podría esperar que el glucógeno
  fuera el modo preferido del organismo para almacenar energía. Hay dos
  razones fundamentales por las que las grasas, antes que el glucógeno,
  son la forma principal de almacenamiento de energía. Una de ellas es que
  un gramo de grasa puede almacenar el doble de energía que un gramo de
  glucógeno; la otra es que el glucógeno, a diferencia de las grasas,
  atrae y retiene cantidades importantes de agua. En consecuencia, si el
  peso se sitúa dentro de lo normal y todas las calorías de las grasas se
  almacenasen en forma de glucógeno, el peso corporal probablemente
  sobrepasaría los 275 kilos.</p>
<p>En el <strong>metabolismo energético</strong> (los cambios químicos
  por los que la energía queda disponible para ser utilizada por un
  organismo) se dan tres fases:</p>
<ol>
  <li>La <strong>fase cefálica</strong> es la fase preparatoria. A menudo
    se inicia al ver u oler la comida, o sólo con pensar en ella; y acaba
    cuando la comida empieza a ser absorbida por el torrente
    circulatorio.
  </li>
  <li>La <strong>fase de absorción</strong> es el período durante el cual
    toda la energía no almacenada de la comida que ha absorbido el torrente
    circulatorio suple las necesidades energéticas inmediatas del
    organismo.
  </li>
  <li>La <strong>fase de ayuno</strong> es el período durante el cual toda
    la energía no almacenada de la comida previa ha sido utilizada y el
    organismo está obteniendo energía de sus reservas para cumplir con las
    necesidades energéticas inmediatas. Esta fase termina con el comienzo de
    una nueva fase cefálica. Durante los períodos de aumento rápido de peso,
    las personas pasan a menudo directamente de una fase de absorción a la
    fase cefálica siguiente sin atravesar una fase intermedia de ayuno.
  </li>
</ol>
<p>El flujo energético durante las tres fases del metabolismo de la
  energía está regulado por dos hormonas pancreáticas:</p>
<ul>
  <li>la insulina y</li>
  <li>el glucagón.</li>
</ul>
<p>Durante
  las fases cefálica y de absorción, el páncreas libera una gran cantidad
  de insulina al torrente circulatorio, pero muy poca cantidad de
  glucagón. La insulina desempeña tres funciones:</p>
<ol>
  <li>estimula la utilización de la glucosa como principal fuente de
    energía por parte del organismo;
  </li>
  <li>estimula la conversión de los carburantes de transmisión hemática en
    formas que pueden almacenarse: la glucosa en glucógeno y grasa, y los
    aminoácidos en proteínas, y
  </li>
  <li>estimula el almacenamiento de glucógeno en el hígado y los músculos,
    de las grasas en el tejido adiposo y de las proteínas en los
    músculos.
  </li>
</ol>
<p>En resumen, la función de la insulina durante la fase cefálica
  consiste en disminuir los niveles de carburantes de transmisión
  hemática, principalmente la glucosa, anticipándose a una afluencia
  inminente; y su función durante la fase de absorción es minimizar los
  niveles crecientes de carburantes de transmisión hemática, utilizándolos
  y almacenándolos.</p>
<p>A diferencia de la fase cefálica y la de absorción, la fase de ayuno
  se caracteriza por un nivel sanguíneo alto de glucagón y bajo de
  insulina. Sin que haya un nivel elevado de insulina, la glucosa tiene
  dificultades para entrar en la mayoría de las células del organismo; por
  lo tanto, la glucosa deja de ser el principal carburante del organismo.
  De hecho, esto reserva la glucosa del organismo para el encéfalo, ya que
  no se requiere insulina para que la glucosa penetre en la mayor parte de
  las células cerebrales. Los niveles bajos de insulina también favorecen
  la conversión del glucógeno y de las proteínas en glucosa. (La
  transformación de las proteínas en glucosa se denomina
  gluconeogénesis.).</p>
<p>Por otro lado, los altos niveles de glucagón propios de la fase de
  ayuno estimulan la liberación de ácidos grasos libres por parte del
  tejido adiposo y su utilización como carburante principal del organismo.
  Los niveles altos de glucagón estimulan asimismo la transformación de
  los ácidos grasos libres en cetonas, que son empleadas por los músculos
  como fuente de energía durante la fase de ayuno. Sin embargo, tras un
  período prolongado sin alimento, el cerebro también empieza a usar
  cetonas para así mantener los recursos de glucosa del organismo.</p>
<h2>Factores que determinan qué
  comemos</h2>
<p>Algunos sabores tienen un alto valor de incentivo positivo para
  prácticamente todos los miembros de una especie. Por ejemplo, la mayoría
  de los seres humanos tiene una inclinación especial por los sabores
  dulces, grasos y salados. Esta pauta típica de preferencias humanas de
  sabor es adaptativa ya que, por naturaleza,</p>
<ul>
  <li>los sabores dulces y grasos son característicos de alimentos ricos
    en energía que son ricos en vitaminas y minerales; y los sabores salados
    son característicos de alimentos ricos en sodio.
  </li>
  <li>Por lo contrario, los sabores amargos, por los cuales la mayoría de
    los seres humanos sienten aversión, se asocian a menudo con
    toxinas.
  </li>
  <li>A estas preferencias y aversiones de sabores típicas de especie se
    le añade que cada individuo tiene capacidad para aprender preferencias y
    aversiones de sabores específicas (véase Rozin y Shulki, 1990).
  </li>
</ul>
<h3>Preferencias y
  aversiones gustativas aprendidas</h3>
<p>Además, los seres humanos y otros animales aprenden a comer
  observando a sus congéneres. Por ejemplo, las ratas aprenden a preferir
  sabores que han experimentado en la leche materna y los que huelen en el
  aliento de otras ratas (véase Galef, 1995, 1996; Gales y Whishkin y
  Bielavska, 1997).</p>
<p>Cuando un animal tiene falta de sodio, desarrolla una preferencia
  inmediata y apremiante por el sabor de la sal (véase Rowland, 1990). Por
  lo contrario, un animal con carencia de alguna vitamina o mineral
  distinta del sodio ha de aprender a consumir alimentos que sean ricos en
  el nutriente que le falta, experimentando sus efectos positivos. Ésta es
  la razón por la que normalmente no se detecta en los alimentos el sabor
  de vitaminas y minerales, aparte del sodio.</p>
<p>Una de las razones es que, para maximizar los beneficios, los
  fabricantes producen alimentos con los sabores que preferimos, pero
  eliminándoles la mayoría de los nutrientes esenciales. (Incluso las
  ratas prefieren las galletas con pepitas de chocolate a la ración de
  comida para ratas nutricionalmente completa.) La segunda razón la
  ilustra el estudio clásico de Harris y colaboradores (1933). Cuando se
  les ofrecieron a ratas con carencia de tiamina dos dietas nuevas, una
  con tiamina y otra sin ella, la mayoría aprendió a comer la dieta
  completa y a evitar la deficiente. Sin embargo, cuando se les ofrecieron
  diez dietas nuevas, de las cuales únicamente una contenía la tan
  necesaria tiamina, pocas establecieron una preferencia por la dieta
  completa. La cantidad de sustancias diferentes consumidas cada día por
  la mayoría de las personas en las sociedades industrializadas es inmensa
  y ello hace que sea difícil, si no imposible, que sus organismos
  aprendan qué alimentos son beneficiosos y cuáles no.</p>
<h2>Factores que influyen
  en cuándo comemos</h2>
<p>El número de veces que los seres humanos comen al día está influido
  por normas culturales, horarios de trabajo, rutinas familiares,
  preferencias personales, riqueza y una gran variedad de otros factores.
  Sin embargo, a diferencia de las preferencias generales de los
  mamíferos, la mayoría de las personas, sobre todo las que viven en
  grandes núcleos familiares, tienden a comer un número reducido de veces,
  pero comidas muy abundantes al día y a intervalos regulares. Es
  interesante el hecho de que el momento de la comida de cada persona
  coincide con el momento en que es probable que esa persona sienta más
  hambre. De hecho, muchas personas experimentan crisis de malestar (dolor
  de cabeza, náuseas y dificultades de concentración) cuando se saltan una
  comida.</p>
<p>Según Woods, la clave para entender el hambre está en darse cuenta de
  que comer resulta estresante para el organismo. Antes de una comida, las
  reservas energéticas del organismo se encuentran en un equilibrio
  homeostático razonable; luego, a medida que se consume la comida, se
  produce una incorporación de carburante al torrente circulatorio que
  altera la homeostasis. El organismo hace lo que puede para mantener la
  homeostasis. A la primera señal de que una persona va a comer pronto
  —por ejemplo, cuando se aproxima la hora habitual de la comida—, el
  organismo entra en la fase cefálica y toma medidas para suavizar el
  impacto de la afluencia inminente, perturbadora de la homeostasis,
  liberando insulina en la sangre y reduciendo así el nivel de glucosa en
  sangre.</p>
<p>El mensaje de Woods es que las intensas y desagradables sensaciones
  de hambre que se pueden sentir a la hora de la comida no son gritos del
  organismo pidiendo comida, son las sensaciones de los preparativos del
  organismo para la esperada comida, perturbadora de la homeostasis. El
  hambre a la hora de comer se debe a la expectativa de alimento y no a
  una carencia de energía.</p>
<h2>Factores que influyen
  en cuánto comemos</h2>
<p>El estado de motivación que hace que dejemos de ingerir alimento
  cuando todavía queda comida es la <strong>saciedad</strong>. Los
  mecanismos de saciedad juegan un importante papel en determinar cuánto
  comemos.</p>
<h3>Influencias sociales y
  saciedad</h3>
<p>La sensación de saciedad depende de que se esté comiendo solo o en
  compañía. Redd y de Castro (1992) encontraron que sus sujetos consumían
  un 60% más cuando comían en compañía de otros. Las ratas de laboratorio
  también comen sustancialmente más cuando se las alimenta en grupo. En el
  caso de los seres humanos, se ha comprobado que los factores sociales
  también reducen el consumo. Muchas personas comen menos de lo que les
  gustaría con el fin de alcanzar el ideal de delgadez de su sociedad, y
  otras se abstienen de comer grandes cantidades delante de otros para no
  parecer glotones. Desgraciadamente, en nuestra cultura las mujeres están
  enormemente influenciadas por este tipo de presiones y, como se verá más
  adelante en este capítulo, algunas llegan a padecer graves trastornos de
  la alimentación.</p>
<h3>Saciedad sensitiva
  específica</h3>
<p>El efecto de las dietas de cafetería sobre la cantidad de comida
  ingerida resulta del hecho de que la saciedad es en gran medida
  específica para el sabor. A medida que se come algo en concreto, el
  valor de incentivo positivo de todos los alimentos en general disminuye
  ligeramente, pero el de esa comida en particular cae a plomo. En
  consecuencia, pronto se llega a estar saciado de ese alimento y se deja
  de comerlo. No obstante, si se ofrece otra comida, a menudo se empezará
  a comer de nuevo.</p>
<p>El fenómeno de la saciedad sensitiva específica presenta dos
  consecuencias adaptativas.</p>
<ol>
  <li>En primer lugar, estimula el consumo de una dieta variada. Si no
    existiera saciedad sensitiva específica, una persona tendería a comer
    únicamente su alimento preferido y nada más, y el resultado sería la
    malnutrición.
  </li>
  <li>En segundo lugar, la saciedad sensitiva específica estimula a los
    animales que disponen de una gran variedad de alimentos para comer
    mucho. Un animal que ha comido hasta la saciedad un alimento en concreto
    empezará a comer de nuevo si se encuentra con un alimento diferente
    (Raynor y Epstein, 2001). Esto anima a los animales a aprovechar
    plenamente las épocas de abundancia, que son tan poco frecuentes en la
    naturaleza.
  </li>
</ol>
<h3>Péptidos del hambre y la
  saciedad</h3>
<p>Al estudiar los efectos reductores del apetito de los péptidos, los
  investigadores han descartado la posibilidad de que estos efectos sean
  simplemente la consecuencia del malestar (véase Morin, 2004). De hecho,
  hay pruebas de que la CCK provoca malestar: cuando se administra CCK a
  ratas después de que hayan comido una sustancia desconocida se provoca
  una aversión condicionada al gusto respecto a dicha sustancia, y la CCK
  induce náuseas en sujetos humanos. Sin embargo, la CCK reduce el apetito
  y la ingesta de alimentos a dosis sustancialmente por debajo de las que
  se requieren para inducir aversión al gusto en ratas, y esto la califica
  como un legítimo péptido de saciedad (un péptido que disminuye el
  apetito).</p>
<p>Se han descubierto asimismo varios péptidos del hambre (péptidos que
  aumentan el apetito). Estos péptidos suelen sintetizarse en el encéfalo,
  particularmente en el hipotálamo. Los más estudiados de ellos son</p>
<ul>
  <li>el neuropéptido Y,</li>
  <li>la galanina,</li>
  <li>la orexina A y</li>
  <li>el ghrelin (véase p.ej, Inui, 2001; Rodgers et al., 2001; Williams
    et al., 2004).
  </li>
</ul>
<p>El descubrimiento de péptidos de hambre y saciedad ha ejercido dos
  efectos principales en la búsqueda de los mecanismos neurales del hambre
  y la saciedad.</p>
<ul>
  <li>En primer lugar, la mera cantidad de estos péptidos de hambre y
    saciedad indica que el sistema neural que controla la ingesta de
    alimentos probablemente responde a muchas señales diferentes (véase
    Berthoud, 2002; Schwartz y Azzara, 2004), no sólo a una o dos (p.ej.,
    no sólo a la glucosa y la grasa).
  </li>
  <li>En segundo lugar, el descubrimiento de que muchos de los péptidos de
    hambre y saciedad tienen receptores en el hipotálamo ha renovado el
    interés por el papel del hipotálamo en el control de la ingesta de
    alimentos (Mercer y Speakman, 2001). El apoyo más sólido de este papel
    deriva de la demostración de que las microinyecciones de péptidos
    intestinales determinados en ciertas zonas del hipotálamo tienen dos
    efectos fundamentales en la conducta de comer. Aun así, se acepta
    generalmente que los circuitos del hipotálamo son sólo una parte de un
    sistema mucho mayor.
  </li>
</ul>
<h3>Serotonina y saciedad</h3>
<p>En seres humanos, se ha demostrado que los agonistas de la serotonina
  (p.ej., la fenfluramina, dexfenfluramina, fluoxetina) reducen el
  hambre, la ingesta de alimentos y el peso corporal en una serie de
  situaciones (véase Blundell y Halford, 1998). Más adelante en este
  capítulo se aprenderá cómo se usa la serotonina en el tratamiento de la
  obesidad (véase De Vry y Schreiber, 2000).</p>
<p>En varios estudios de pacientes obesos se ha hallado que los
  agonistas de la serotonina reducen lo siguiente: el impulso de comer
  alimentos ricos en calorías, el consumo de grasas, la intensidad
  subjetiva del hambre, la cantidad de comida, el número de tentempiés
  entre comidas y los atracones de comida.</p>
<p>Dado este extremadamente positivo perfil de efectos y la gravedad del
  problema de la obesidad, los agonistas de la serotonina (fenfluramina y
  dexfenfluramina) se introdujeron rápidamente en la práctica clínica. Sin
  embargo, posteriormente se retiraron del mercado ya que se encontró que
  su consumo crónico se asociaba con cardiopatías en un pequeño, pero
  significativo, número de consumidores. Actualmente, la búsqueda se
  dirige a medicaciones de pérdida de peso serotoninérgicas que no tienen
  efectos secundarios peligrosos. Hay motivos para ser optimistas. La
  variedad de subtipos de receptores serotoninérgicos diferentes significa
  que puede ser posible elaborar agonistas serotoninérgicos que favorezcan
  selectivamente la pérdida de peso.</p>
<h3>Comida y salud</h3>
<p>Los efectos de la restricción de calorías son el segundo tipo de
  pruebas de que el consumo ad libitum no es saludable. En los
  experimentos de restricción de calorías, a un grupo de sujetos se le
  permite comer tanto como quieran, mientras que a otros grupos de sujetos
  su aporte calórico de la misma dieta se les reduce sustancialmente
  (entre un 25% y un 65% en diversos estudios). Los resultados de tales
  experimentos han sido sorprendentemente sistemáticos (véase Bucci, 1992;
  Masoro, 1988; Weindruch, 1996; Weindruch y Walford, 1988): experimento
  tras experimento, la reducción sustancial del aporte calórico en dietas
  equilibradas ha mejorado notablemente los índices de salud y de
  longevidad. Por ejemplo, en un experimento (Weindruch et al., 1986),
  grupos de ratones tenían reducido tras el destete el aporte calórico de
  su dieta comercial equilibrada ya fuera en un 25%, un 55% o un 65%.
  Todos los niveles de dieta restringida mejoraron sustancialmente la
  salud y aumentaron la longevidad, pero los beneficios fueron mayores en
  los ratones cuya ingesta se redujo al máximo. Los ratones que
  consumieron menos tuvieron los índices más bajos de cáncer, la mejor
  respuesta inmunitaria y la mayor expectativa de vida —ya que vivieron un
  67% más que los ratones que comieron todo lo que quisieron—.</p>
<p>La opinión actual es que algunos subproductos del consumo de energía
  se acumulan en las células y aceleran el envejecimiento, con todos los
  problemas de salud que ello conlleva (Lane, Ingram y Roth, 2002; Prolla
  y Mattson, 2001).</p>
<p>A medida que disminuye el nivel de grasa corporal de una persona, esa
  persona empieza a utilizar los recursos energéticos de manera más
  eficaz, lo que limita posteriores pérdidas de peso (véase Martin, White
  y Hulsey, 1991). A la inversa, la ganancia de peso está limitada por una
  disminución progresiva de la eficacia de utilización de la energía</p>
<p>El mecanismo según el cual el organismo ajusta la eficacia de la
  utilización de su energía en respuesta a sus niveles de grasa corporal
  se conoce como <strong>termogénesis inducida por la dieta</strong>. Los
  aumentos de los niveles de grasa corporal producen aumentos de la
  temperatura corporal, lo cual requiere energía adicional para mantener
  dicha temperatura —y los descensos del nivel de grasa corporal tienen el
  efecto contrario—.</p>
<h2>Obesidad</h2>
<p>El <strong>ejercicio físico</strong> tiene muchos efectos que
  benefician la salud; sin embargo, pese a la creencia general de que es
  el método más eficaz para perder peso, varios estudios han demostrado
  que el ejercicio suele contribuir poco a la pérdida de peso
  (véase,p.ej.,Sweeney et al., 1993). Una de las razones es que la
  actividad física normalmente es sólo responsable de una pequeña
  proporción del gasto energético total: alrededor de un ochenta por
  ciento de la energía que se gasta se emplea en mantener los procesos
  fisiológicos del organismo en reposo y en digerir la comida
  (Calles-Escandon y Horton, 1992). Otra razón es que, tras el ejercicio,
  muchas personas consumen más bebidas y comidas que contienen una
  cantidad de calorías mayor que las relativamente pocas que han perdido
  durante el ejercicio.</p>
<p>En 1994, Friedman y colaboradores identificaron y clonaron el gen que
  ha mutado en los ratones ob/ob (Zhang et al., 1994). Hallaron que este
  gen se expresa únicamente en los adipocitos [células grasas], y
  determinaron la hormona proteínica que codifica. A esta proteína se le
  llamó <strong>leptina</strong>.</p>
<p>Las investigaciones han demostrado que la leptina cumple tres
  criterios que requiere una señal del tejido adiposo de retroalimentación
  negativa (Ahima y Osei, 2004; Seeley y Schwartz, 1997):</p>
<ol>
  <li>se ha hallado que hay una relación positiva entre los niveles de
    leptina en sangre y los depósitos de grasa en seres humanos y otros
    animales (Schwartz et al., 1996a);
  </li>
  <li>se ha visto que las inyecciones de leptina a dosis demasiado bajas
    para ser aversivas reducen la ingesta de alimentos y la grasa corporal
    en los ratones ob/ob (Campfield et al., 1995) y
  </li>
  <li>se han encontrado receptores de leptina en el encéfalo (Schwartz et
    al., 1996b).
  </li>
</ol>
<p>¿cómo podría el nivel de insulina en el organismo, que asciende y
  luego desciende hasta el valor normal después de cada comida, aportar al
  encéfalo información sobre los niveles de grasa corporal, que cambian
  gradualmente? Resultó que la insulina no penetra fácilmente en la
  barrera hematoencefálica, y se ha encontrado que sus niveles en el
  encéfalo son relativamente estables.</p>
<p>Lo que es más importante, se ha encontrado que los niveles cerebrales
  de insulina se relacionan positivamente con los niveles de grasa
  corporal (Seeley et al., 1996); se han encontrado receptores en el
  cerebro para ella (Baura et al., 1993); y se ha encontrado que
  infusiones de insulina en el cerebro de animales de laboratorio, a dosis
  demasiado bajas para ser aversivas y demasiado bajas para afectar al
  nivel de glucemia, reducen la ingesta de alimentos y el peso corporal
  (Campfield et al., 1995; Chavez, Seeley y Woods, 1995). A diferencia de
  los individuos con carencia de leptina, los individuos con carencia de
  insulina no son obesos (véase Woods et al., 2000). Pese a su extrema
  hiperfagia, se mantienen delgados debido a que no pueden transformar los
  alimentos en grasa sin insulina. La mayoría del exceso de calorías que
  consumen permanece en la sangre y luego se excretan.</p>
<h2>Anorexia</h2>
<p>Los datos sugieren que las personas —ante todo las mujeres
  adolescentes— bajo la fuerte presión del énfasis cultural en la delgadez
  empiezan a hacer régimen, y aquellas que son excesivamente controladas,
  rígidas y obsesivas vencen la atracción de la comida y llegan a padecer
  el trastorno (véase Wilson, Heffernan y Black, 1996). No obstante, las
  nuevas concepciones sobre el hambre y la ingesta de alimentos que el
  lector ha visto en este capítulo apuntan otro factor en la etiología de
  la anorexia nerviosa.</p>
<p>Enigmas de la anorexia: ¿por qué el enorme aumento adaptativo del
  valor de incentivo positivo del hecho de comer que ocurre en las
  victimas de inanición no se da en las depauperadas personas con
  anorexia? El valor de incentivo positivo de la ingesta de alimentos
  normalmente aumenta hasta niveles tales en condiciones de inanición que
  es difícil imaginar cómo alguien que está pasando hambre —no importa lo
  controlado, rígido, obsesivo que sea y lo motivado que esté— puede
  abstenerse de comer delante de una sabrosa comida. Por qué no se activa
  este mecanismo de protección en las personas con anorexia grave es una
  pregunta apremiante acerca de la etiología de la anorexia nerviosa. La
  respuesta tendrá que explicar cómo alguien puede resistirse a la
  atracción de la comida lo suficiente como para alcanzar el nivel de
  inanición que caracteriza a la anorexia extrema.</p>
<p>¿Entonces, por qué las personas con anorexia grave no experimentan un
  fuerte incremento del valor de incentivo positivo del hecho de comer,
  similar al aumento que experimentan otros individuos depauperados? La
  respuesta puede ser: las comidas —comidas a las que se obliga a estos
  pacientes como resultado de la idea equivocada de nuestra sociedad de
  que las comidas son el modo saludable de comer—. Cada comida que consume
  una persona con anorexia puede producir una serie de aversiones
  condicionadas al gusto, las cuales reducen la motivación para comer.
  Esta hipótesis ha de estudiarse dadas sus implicaciones para el
  tratamiento: a los pacientes con anorexia — o a cualquiera que esté
  gravemente desnutrido— no se les debería animar, ni incluso permitir,
  tomar comidas. Se les debería alimentar —o infundir— pequeñas cantidades
  de alimento intermitentemente a lo largo del día.</p>
<p>Se ha descrito la hipótesis precedente para demostrar al lector el
  valor de las nuevas ideas que ha hallado en este capítulo: el principal
  examen de una nueva teoría es ver si conduce a hipótesis innovadoras.
  Hace unos cuantos meses, cuando estaba leyendo detenidamente un artículo
  sobre hambruna y desnutrición global, reparé en un comentario
  fascinante: una de las complicaciones clínicas resultantes de alimentar
  con comidas a las víctimas de hambrunas es la anorexia (Blackburn,
  2001).</p>
<p><em>La parte sobre los incentivos positivos y el aprendizaje era
  realmente buena. Creo que mi problema empezó cuando comer dejó de tener
  un valor de incentivo positivo para mí —en mi mente—. Hice una especie
  de asociación entre comer y estar gorda y todos los problemas que tenía
  con mi novio. Esto hizo que me fuera fácil hacer régimen, pero de cuando
  en cuando me sentía hambrienta y me daba atracones o mis padres me
  obligaban a comer una copiosa comida. Comía tanto que me sentía enferma.
  Así es que introducía mis dedos en la garganta y me provocaba el vómito.
  Esto me evitó ganar peso, pero creo que también enseñó a mi cuerpo a
  asociar mis alimentos favoritos con el malestar —un tipo de aversión
  condicionada al gusto—.</em></p>
<h1>Hormonas y sexo</h1>
<p>Las hormonas influyen sobre la conducta sexual de dos maneras:</p>
<ol>
  <li>influyendo en el desarrollo, desde la concepción hasta la madurez
    sexual, de las características anatómicas, fisiológicas y
    comportamentales que distinguen a un individuo como mujer o como varón
    y
  </li>
  <li>activando la conducta relacionada con la reproducción de los adultos
    maduros sexualmente. En este capítulo se exponen tanto los efectos de
    desarrollo como los de activación de las hormonas sexuales.
  </li>
</ol>
<h2>Hormonas</h2>
<p>La mayoría de las hormonas pueden clasificarse en una de estas tres
  categorías:</p>
<ol>
  <li>derivados de aminoácidos;</li>
  <li>péptidos y proteínas, y</li>
  <li>esteroides.</li>
</ol>
<p>Las hormonas derivadas de aminoácidos son hormonas que se sintetizan
  en unos cuantos pasos sencillos a partir de una molécula de aminoácido.
  Un ejemplo es la adrenalina, liberada por la médula suprarrenal y
  sintetizada a partir de la tirosina. Las hormonas peptídicas y las
  hormonas proteínicas son cadenas de aminoácidos: —las hormonas
  peptídicas son cadenas cortas y las hormonas proteínicas son cadenas
  largas—.</p>
<p>Las <strong>hormonas esteroides</strong> son hormonas que se
  sintetizan a partir del colesterol, un tipo de molécula grasa. Las
  hormonas esteroides desempeñan un papel esencial en el desarrollo sexual
  y la conducta. La mayor parte de las otras hormonas producen sus efectos
  uniéndose a receptores de la membrana celular. Las moléculas esteroides
  pueden influir en las células de esta manera; sin embargo, debido a que
  son pequeñas y solubles en grasas, pueden penetrar fácilmente en las
  membranas celulares y a menudo afectan a las células de otro modo. Una
  vez en el interior de la célula, las moléculas esteroides pueden unirse
  a receptores en el citoplasma o el núcleo y, al hacerlo, influyen
  directamente en la expresión genética —las hormonas derivadas de los
  aminoácidos y las hormonas peptídicas también pueden afectar a la
  expresión genética, pero lo hacen con menos frecuencia y mediante
  mecanismos menos directos ya que no pueden penetrar las membranas
  celulares—. En consecuencia, de todas las hormonas, las hormonas
  esteroides son las que suelen tener los efectos más diversos y duraderos
  sobre la función celular (Brown, 1994).</p>
<h2>Esteroides sexuales</h2>
<p>En muchos textos se afirma que los cromosomas X tienen forma de X y
  los cromosomas Y tienen forma de Y pero esto no es así. Una vez que un
  cromosoma se ha duplicado, las dos partes resultantes permanecen unidas
  por un punto, lo que produce una forma de X. Esto atañe a todos los
  cromosomas, incluyendo los cromosomas Y. Ya que los cromosomas Y son
  mucho más pequeños que los cromosomas X, las investigaciones iniciales
  no lograron distinguir el brazo pequeño.</p>
<p>Las gónadas sirven para algo más que generar esperma y óvulos;
  también producen y liberan hormonas. La mayoría de las personas se
  sorprenden al saber que los testículos y los ovarios liberan las mismas
  hormonas.</p>
<p>Las dos principales clases de hormonas gonadales son los
  <strong>andrógenos</strong> y los <strong>estrógenos</strong>.</p>
<ul>
  <li>La <strong>testosterona</strong> es el andrógeno más frecuente,
    y
  </li>
  <li>el <strong>estradiol</strong> el estrógeno más frecuente.</li>
</ul>
<p>El hecho de que los ovarios adultos tiendan a liberar más estrógenos
  que andrógenos y el que los testículos adultos liberen más andrógenos
  que estrógenos ha llevado a que sea bastante habitual, aunque puede
  inducir a error, referirse a los andrógenos como «las hormonas sexuales
  masculinas» y a los estrógenos como «las hormonas sexuales
  femeninas».</p>
<p>Esta costumbre debe evitarse porque, desde la perspectiva «los
  hombres son hombres y las mujeres son mujeres», lleva implícita la idea
  de que los andrógenos producen masculinidad y los estrógenos feminidad.
  No es así. Los ovarios y los testículos liberan asimismo una tercera
  clase de hormonas esteroides, llamadas <strong>progestágenos</strong>.
  El progestágeno más habitual es la progesterona, que en las hembras
  prepara el útero y las mamas para el embarazo. Su función en los varones
  no está clara.</p>
<h2>Hormonas de la hipófisis</h2>
<p>Con
  frecuencia se alude a la hipófisis como la glándula maestra, ya que la
  mayor parte de sus hormonas son hormonas trópicas. Las hormonas trópicas
  son hormonas cuya función principal es influir en la liberación de
  hormonas por parte de otras glándulas (trópico es un adjetivo que
  describe aquellos hechos que estimulan o cambian otros). Por ejemplo, la
  <strong>gonadotropina</strong> es una hormona trópica hipofisaria que
  viaja por el aparato circulatorio hasta las gónadas, donde estimula la
  liberación de hormonas gonadales.</p>
<p>Lo que estos estudios demostraron fue que la hipófisis anterior no es
  intrínsecamente femenina (cíclica) o masculina (estable); sus patrones
  de liberación hormonal están regulados por otras zonas del cuerpo. La
  glándula maestra parece tener su propio maestro. ¿Dónde está?</p>
<p>La búsqueda de la estructura neural concreta que controla la
  hipófisis anterior se dirigió entonces, como es natural, hacia el
  <strong>hipotálamo</strong> , la estructura de la que cuelga la
  hipófisis. Experimentos de estimulación y lesión del hipotálamo
  establecieron rápidamente que el hipotálamo regula la hipófisis
  anterior, pero cómo cumple esta función siguió siendo un misterio. La
  hipófisis anterior, a diferencia de la posterior, no recibe un input
  neural de parte alguna del hipotálamo ni de cualquier otra estructura
  neural.</p>
<p>Existen dos mecanismos distintos por los que el hipotálamo controla
  la hipófisis: uno para la hipófisis posterior y otro para la hipófisis
  anterior. Las dos hormonas principales de la hipófisis posterior, la
  <strong>vasopresina</strong> y la <strong>oxitocina</strong> , son
  hormonas peptídicas que se sintetizan en los cuerpos celulares de las
  neuronas del núcleo paraventricular y del núcleo supraóptico del
  hipotálamo. Luego se transportan a lo largo de los axones de estas
  neuronas hasta sus terminales en la hipófisis posterior, donde se
  almacenan hasta que la llegada de un potencial de acción hace que se
  viertan al torrente circulatorio.</p>
<p>A las hormonas hipotalámicas que se pensaba que estimulan la
  liberación de una hormona de la hipófisis anterior se les llamó factores
  <strong>liberadores</strong> y a las que se pensaba que inhibían la
  liberación de una hormona de la hipófisis anterior, factores
  <strong>inhibidores</strong>.</p>
<p>Los esfuerzos por aislar los supuestos (hipotéticos) factores
  hipotalámicos liberadores e inhibidores llevaron a un avance fundamental
  en los años sesenta. Guillemin y colaboradores aislaron la
  <strong>tiroliberina</strong> [TRH] a partir del hipotálamo de oveja, y
  Schally y colaboradores aislaron la misma hormona a partir del
  hipotálamo de cerdo. La tiroliberina desencadena la liberación de
  tirotropina por la hipófisis anterior, lo que a su vez estimula que la
  glándula tiroidea libere sus hormonas. Es difícil apreciar el esfuerzo
  que invirtió en aislar por primera vez la tiroliberina. Los factores
  liberadores e inhibidores se encuentran en cantidades tan pequeñas que
  se requirió incontable tejido hipotalámico para extraer sólo una
  cantidad mínima.</p>
<h2>Regulación neural</h2>
<p>Todas las glándulas endocrinas, salvo la hipófisis anterior, están
  reguladas directamente por señales procedentes del sistema nervioso. Las
  glándulas endocrinas que se localizan en el cerebro (esto es, la
  hipófisis y la pineal) están reguladas por neuronas cerebrales; las que
  se localizan fuera del SNC están inervadas por el sistema
  neurovegetativo —por lo general, tanto por la rama simpática como por la
  parasimpática, que suelen tener efectos opuestos en la liberación de
  hormonas. Los efectos de la experiencia sobre la liberación hormonal
  habitualmente están mediados por señales procedentes del sistema
  nervioso. Es muy importante recordar que la liberación de hormonas está
  regulada por la experiencia. Esto significa que las explicaciones
  hormonales en ningún caso descartan las explicaciones que se refieren a
  la experiencia; de hecho, pueden ser diferentes partes del mismo
  mecanismo.</p>
<p>Las señales que proceden de las hormonas mismas también influyen en
  la liberación hormonal. Ya se ha aprendido, por ejemplo, que las
  hormonas trópicas de la hipófisis anterior influyen en la liberación de
  hormonas por parte de sus respectivos órganos de actuación. No obstante,
  la regulación de la función endocrina por la hipófisis anterior no es
  una vía de una sola dirección. Las hormonas que están circulando suelen
  aportar retroalimentación a las mismas estructuras que influyen en su
  liberación: la hipófisis, el hipotálamo y otras zonas del cerebro. La
  función de la mayor parte de la retroalimentación hormonal es mantener
  estables los niveles sanguíneos de hormonas.</p>
<p>En la
  regulación de los niveles hormonales pueden intervenir otras sustancias
  químicas que están circulando, aparte de las hormonas. Los niveles de
  glucosa, calcio y sodio en sangre influyen en la liberación de
  determinadas hormonas. Por ejemplo, en el Capítulo 12 se ha aprendido
  que el aumento de glucemia aumenta la liberación de insulina por parte
  del páncreas, y la insulina, a su vez, reduce los niveles de
  glucosa.</p>
<h2>Hormonas y desarrollo sexual</h2>
<p>Parece que la aromatización de la testosterona perinatal a estradiol
  es importante tanto para la desfeminización como para la masculinización
  de la conducta de cópula de los roedores (Goy y McEwen, 1980; Shapiro,
  Levine y Adler, 1980).</p>
<p>La pubertad se asocia con un aumento de la liberación de hormonas de
  la hipófisis anterior (véase Grumbach, 2002).</p>
<ul>
  <li>El aumento de liberación de <strong>somatotropina</strong> [u
    hormona del crecimiento, GH] —la única hormona de la hipófisis anterior
    que no tiene como objetivo de actuación principal una glándula
    endocrina— actúa directamente sobre el hueso y el tejido muscular,
    produciendo así el estirón de la pubertad.
  </li>
  <li>Los aumentos de liberación de <strong>gonadotropina</strong> y
    <strong>corticotropina</strong> ACTH hacen que las gónadas y la corteza
    suprarrenal aumenten su liberación de hormonas gonadales y
    suprarrenales, lo que a su vez inicia la maduración de los genitales y
    el desarrollo de los caracteres sexuales secundarios.
  </li>
</ul>
<p>Pero
  incluso durante la pubertad, su momento de mayor importancia, el
  concepto de «los hombres son hombres y las mujeres son mujeres» se
  encuentra con obstáculos. La <strong>androstenediona</strong> , un
  andrógeno liberado principalmente por la corteza suprarrenal, es
  normalmente responsable del crecimiento del vello púbico y del vello
  axilar (vello debajo del brazo) en las mujeres. Es difícil tomar en
  serio la costumbre de referirse a los andrógenos como «hormonas
  masculinas» cuando una de ellas es responsable del modelo de crecimiento
  del vello púbico femenino. El modelo masculino es piramidal y el
  femenino, el de una pirámide invertida (véase la Figura 13.9).</p>
<p>¿Recuerda el lector qué edad tenía cuando alcanzó la pubertad? En la
  mayoría de los países norteamericanos y europeos, la pubertad comienza
  aproximadamente a los 10.5 años en las chicas y a los 11,5 años en los
  chicos. Estoy seguro de que el lector se hubiera sentido desgraciado si
  no hubiera llegado a la pubertad hasta los 15 ó 16 años, pero esta era
  la norma en Norteamérica y Europa hace justo un siglo y medio.
  Posiblemente, esta aceleración de la pubertad se debe a mejoras en las
  condiciones de alimentación, médicas y socioeconómicas.</p>
<h2>Casos excepcionales</h2>
<p>A. sufre el síndrome de <strong>insensibilidad a los
  andrógenos</strong> ; todos sus síntomas proceden de una mutación del
  gen receptor de andrógenos que hizo que sus receptores de andrógenos
  fueran defectuosos (véase Fink et al., 1999; Goldstein, 2000. Durante el
  desarrollo, los testículos de A. liberaron una cantidad de andrógenos
  normal para un varón, pero su organismo no pudo responder a ellos y, por
  lo tanto, su desarrollo prosiguió como si no se hubieran liberado
  andrógenos. Sus genitales externos, su cerebro y su conducta
  evolucionaron siguiendo directrices femeninas, sin que los efectos de
  los andrógenos anulasen el programa femenino, y sus testículos no
  pudieron descender de la cavidad corporal ya que no había escroto a
  donde bajar. Además, A. no desarrolló conductos reproductores internos
  femeninos normales porque, al igual que otros varones genéticos, sus
  testículos liberaban la sustancia inhibidora de Müller; razón por la
  cual su vagina era corta y su útero estaba poco desarrollado. En la
  pubertad, los testículos de A. liberaron la cantidad de estrógenos
  suficiente para feminizar su cuerpo en ausencia de los efectos
  contrarios de los andrógenos; sin embargo, la androstenediona
  suprarrenal no pudo estimular el crecimiento del vello púbico y el
  axilar.</p>
<p>El caso de John sugiere que la práctica clínica de cambiar
  quirúrgicamente el sexo de una persona en el nacimiento debe
  suspenderse. Un tratamiento tan irrevocable debería esperar a la
  pubertad y a que haya surgido la identidad sexual y la atracción sexual
  que siente el paciente. Entonces es cuando puede elegirse un tratamiento
  compatible con ello.</p>
<h2>Efectos de las
  hormonas gonadales en los adultos</h2>
<h3>Conducta
  relacionada con la reproducción masculina y testosterona</h3>
<p>Del estudio de Bremer pueden obtenerse dos generalizaciones
  importantes.</p>
<ol>
  <li>La primera es que la orquiectomía lleva a una reducción del interés
    y la conducta sexual; la segunda es que la tasa y grado de esta pérdida
    es variable. Durante la duración del estudio, aproximadamente la mitad
    de los hombres se volvieron completamente asexuales unas cuantas semanas
    después de la operación; otros perdieron rápidamente la capacidad para
    conseguir una erección, pero siguieron sintiendo cierto grado de interés
    y placer sexual; y unos pocos continuaron copulando satisfactoriamente,
    aunque con algo menos de entusiasmo.
  </li>
  <li>Asimismo se dieron cambios corporales: reducción del vello en el
    tronco, extremidades y rostro; acumulación de grasa en las caderas y el
    pecho; mayor suavidad de la piel y disminución de la fuerza física.
  </li>
</ol>
<p>De los 102 condenados por delitos sexuales del estudio de Bremer,
  sólo 3 fueron condenados de nuevo por el mismo motivo. Por consiguiente,
  Bremer recomendó la castración como tratamiento eficaz en última
  instancia para los varones violadores.</p>
<p>Parece ser que los hombres sanos tienen mucha más testosterona de la
  necesaria para activar los circuitos neurales que producen su conducta
  sexual, y que tener más del mínimo no es una ventaja a este respecto
  (Sherwin, 1988). Un experimento clásico realizado por Grunt y Young
  (1952) ilustra claramente este punto.</p>
<h3>Conducta
  relacionada con la reproducción femenina y hormonas gonadales</h3>
<p>Las mujeres son diferentes de las ratas hembra y los cobayas en lo
  que respecta al control hormonal de su conducta sexual. Ni la motivación
  sexual ni la conducta sexual de las mujeres están inextricablemente
  ligadas a sus ciclos menstruales (véase Sanders y Bancroft, 1982). Por
  otra parte, la ovariectomía tiene un sorprendentemente bajo efecto
  directo tanto sobre la motivación sexual como sobre la conducta sexual
  (véase p.ej., Martin, Roberts y Clayton, 1980). Aparte de la
  esterilidad, la principal consecuencia de la ovariectomía es un descenso
  de la lubricación vaginal. Paradójicamente, hay datos que sostienen que
  el impulso sexual en las mujeres está bajo el control de andrógenos, no
  de estrógenos (véase Sherwin, 1988). Al parecer, las glándulas
  suprarrenales humanas liberan la cantidad de andrógenos suficiente para
  mantener la motivación sexual en las mujeres, incluso después de que se
  les hayan extirpado los ovarios. El apoyo a la teoría de que los
  andrógenos controlan la sexualidad femenina en seres humanos ha surgido
  de tres fuentes:</p>
<ul>
  <li>Estudios de correlación en mujeres sanas: Distintas medidas de
    motivación sexual se relacionan con los niveles de testosterona, pero no
    con los de estradiol (véase Bancroft et al., 1983: Morris et al.,
    1987).
  </li>
  <li>Estudios clínicos de mujeres tras ovariectomía y suprarrenalectomía:
    Las inyecciones de restitución de testosterona, pero no las de
    estradiol, reavivan su deseo sexual (véase Sherwin, 1985; Sherwin.
    Gelfand y Brender, 1985).
  </li>
</ul>
<p>Aunque el <strong>estradiol</strong> es más conocido por sus efectos
  de organización y de activación en lo referente al sexo, esta hormona
  también puede reducir el daño cerebral que se asocia con el accidente
  cerebrovascular y diversos trastornos neurodegenerativos.</p>
<ul>
  <li>Por ejemplo, Yang y sus colegas (2003) demostraron que cuando se
    administra estradiol justo antes, durante o después de que se produzca
    hipoxia cerebral (reducción del aporte de oxígeno al cerebro), se reduce
    sustancialmente el daño cerebral (véase el Capítulo 10).
  </li>
  <li>Se ha demostrado que el estradiol tiene varios efectos neurotróficos
    que podrían explicar sus propiedades neuroprotectoras (véase el capítulo
    10). Por ejemplo, se ha comprobado que el estradiol reduce la
    inflamación, estimula la regeneración axónica y favorece la
    sinaptogénesis (véase Stein y Hoffman, 2003; Zhang et al., 2004);
  </li>
  <li>Brandi Ormerod y Liisa Galea dirigieron una interesante línea de
    experimentos sobre otro efecto neurotrófico más del estradiol: aumentar
    la neurogénesis adulta (véase el Capítulo 10). Comprobaron que una
    inyección de estradiol inicialmente aumentaba la cantidad de nuevas
    neuronas que se originaban en la circunvolución dentada de ambos
    hipocampos en ratas adultas hembra y luego, unas 48 horas más tarde,
    suprimía la neurogénesis durante un tiempo (Ormerod, Falconer y Galea,
    2003; Ormerod, Lee y Galea, 2001).
  </li>
  <li>También hallaron que el estradiol, así como aumentaba la
    neurogénesis adulta, aumentaba la tasa de supervivencia de las nuevas
    neuronas (Ormerod y Galea, 2001).
  </li>
</ul>
<p>El descubrimiento de las propiedades neuroprotectoras del estradiol
  está originando mucha emoción entre los neurocientíficos. Estas
  propiedades pueden explicar la mayor longevidad de las mujeres, la más
  baja incidencia de varios trastornos neuropsicológicos frecuentes, tales
  como el Parkinson, entre las mujeres, y la disminución de ciertas
  funciones cognitivas que experimentan las mujeres posmenopáusicas (véase
  Bisagno, Bowman y Luine, 2003; Gandy, 2003). Además, los compuestos
  similares al estradiol pueden resultar ser eficaces como agentes
  preventivos y terapéuticos (véase Gooren y Toorians, 2003; Sherwin,
  2003).</p>
<h2>Mecanismos neurales
  de la conducta sexual</h2>
<p>La región preóptica medial del hipotálamo (que incluye al núcleo
  sexualmente dimorfo) es un área de éste que desempeña un papel clave en
  la conducta sexual masculina. La destrucción de toda el área anula la
  conducta sexual en los machos de todas las especies de mamíferos que se
  han estudiado (véase Hull et al., 1999). Por el contrario, las lesiones
  de la región preóptica medial no suprimen las conductas sexuales
  femeninas de las hembras, pero eliminan las conductas sexuales
  masculinas (p.ej., de monta) que se observan a menudo en las hembras
  (Singer, 1968). Así pues, parece ser que las lesiones preópticas
  mediales bilaterales suprimen la conducta de cópula en ambos sexos. En
  la otra cara de la moneda, la estimulación eléctrica de la región
  preóptica medial provoca la conducta de cópula en la rata macho
  (Malsbury, 1971; Rodríguez Manzo et al., 2000), y los implantes de
  testosterona en la región preóptica medial pueden restaurarse la
  conducta de cópula en las ratas macho castradas (Davidson, 1980).</p>
<p>Parece ser que la región preóptica medial controla la conducta sexual
  masculina a través de un fascículo que proyecta a un área del
  mesencéfalo llamada campo tegmental lateral. La destrucción de este
  fascículo altera la conducta sexual de las ratas macho (Brackett y
  Edwards, 1984). Por otra parte, la actividad de neuronas individuales
  del campo tegmental lateral de ratas macho a menudo se relaciona con
  aspectos de la cópula (Shimura y Shimokochi, 1990). Por ejemplo, algunas
  neuronas del campo tegmental lateral tienen una alta frecuencia de
  disparo sólo durante la penetración.</p>
<p>Parece ser que la influencia del NVM en la conducta sexual de las
  ratas hembra está regulada por un fascículo que desciende hasta la
  sustancia gris periacueductal (SGP) del tegmento mesencefálico. La
  destrucción de este tracto suprime la conducta sexual femenina
  (Hennessey et al., 1990), al igual que lo hacen las lesiones de la
  sustancia gris periacueductal misma (Sakuma y Pfaff, 1979).</p>
<h2>Orientación sexual,
  hormonas y encéfalo</h2>
<p>La investigación ha demostrado que las diferencias de orientación
  sexual tienen una base genética. Por ejemplo, Bailey y Pillard (1991)
  estudiaron a un grupo de varones homosexuales que tenían hermanos
  gemelos, encontrando que el 52% de los hermanos gemelos monocigóticos y
  el 22% de los dicigóticos eran homosexuales. En un estudio equiparable
  de mujeres gemelas, realizado por el mismo grupo de investigadores
  (Bailey et al., 1993), las tasas de concordancia para la homosexualidad
  fueron del 48% en el caso de los gemelos monocigóticos y del 16% en el
  de los dicigóticos.</p>
<p>Muchas personas dan por hecho, erróneamente, que los homosexuales
  tienen un nivel de hormonas sexuales más bajo de lo normal. No los
  tienen: los heterosexuales y los homosexuales no se diferencian en
  cuanto a sus niveles de hormonas circulantes. Por otra parte, la
  orquiectomía reduce la conducta sexual de los varones tanto
  heterosexuales como homosexuales, pero no la reorienta, y las
  inyecciones de restitución simplemente reactivan las preferencias que ya
  existían antes de la cirugía. Mucha gente también asume que la
  preferencia sexual es algo que se elige. No lo es: las personas
  descubren sus preferencias sexuales, no las escogen. Parece ser que las
  preferencias sexuales se desarrollan muy temprano y el primer indicio de
  adonde se dirige la atracción sexual de un niño habitualmente no cambia
  cuando madura. ¿Podría ser la exposición perinatal a hormonas el
  acontecimiento temprano que modela la orientación sexual?</p>
<p>McClintock y Herdt (1996) han sugerido que la aparición de la
  atracción sexual puede ser estimulada por los esteroides de la corteza
  suprarrenal. A diferencia de la maduración gonadal, la maduración
  suprarrenal tiene lugar aproximadamente a los 10 años.</p>
<h1>Sueño, ensueños y ritmos
  circadianos</h1>
<p>Posteriormente, el electroencefalograma (EEG), el electroculograma
  (EOG) y el electromiograma (EMG) submentoniano se convirtieron en las
  tres medidas psicofisiológicas básicas que habitualmente se utilizan
  para definir las fases del sueño (Rechtschaffen y Kales, 1968).</p>
<h2>Las cuatro fases del sueño</h2>
<p>En el EEG se distinguen cuatro fases de sueño: fase 1, fase 2, fase 3
  y fase 4. En la Figura 14.2, se muestran ejemplos de cada una.</p>
<p>Tras
  cerrar los ojos y disponerse la persona a dormir, las <strong>ondas
    alfa</strong> —salvas crecientes y menguantes de ondas EEG de 8 a 12 Hz—
  empiezan a inundar el EEG de bajo voltaje y alta frecuencia propio de la
  vigilia activa. Luego, cuando la persona se duerme, hay una repentina
  transición a un período de fase 1 EEG de sueño. La fase 1 del EEG de
  sueño consiste en una actividad EEG de fondo de bajo voltaje y alta
  frecuencia similar a la de la vigilia activa, aunque más lenta.</p>
<p>A medida que la persona pasa progresivamente de la fase 1, a las
  fases 2, 3 y 4 se da un aumento gradual del voltaje EEG y una
  disminución de su frecuencia. La fase 2 del EEG de sueño tiene una
  amplitud ligeramente mayor y una frecuencia más baja que el EEG de fase
  1. Además, está salpicada por dos ondas características: los complejos K
  y los husos del sueño [o «spindles»]. Cada complejo K es una única onda
  grande negativa (deflexión ascendente), seguida de inmediato por una
  gran onda positiva (deflexión descendente). Cada huso del sueño es una
  salva creciente y decreciente de ondas de 12 a 14 Hz, que dura entre 1 y
  2 segundos.</p>
<p>La fase 3 del EEG de sueño se define por la presencia ocasional de
  <strong>ondas delta</strong> —las más grandes y lentas de las ondas EEG
  cuya frecuencia oscila entre 1 y 2 Hz—, mientras que la fase 4 EEG del
  sueño se caracteriza por el predominio de las ondas delta.</p>
<p>Una vez que los sujetos alcanzan la fase 4 del EEG de sueño,
  permanecen en ella un cierto tiempo para luego retroceder, atravesando
  las distintas fases del sueño hasta fase 1. Sin embargo, cuando vuelven
  a la fase 1, las cosas no son como eran la primera vez. El primer
  período de fase 1 durante el sueño de una noche (EEG de fase 1 inicial)
  no está marcado por ningún cambio electromiográfico o electroculográfico
  llamativo, mientras que los períodos siguientes de la fase 1 del EEG del
  sueño (EEG de fase 1 emergente) se acompañan de movimientos oculares y
  de pérdida del tono en los músculos axiales [o principales] del cuerpo.
  Tras el primer ciclo EEG del sueño —de la fase 1 inicial a la fase 4, y
  vuelta a la fase 1 emergente—, el resto de la noche se pasa yendo hacia
  delante y hacia atrás de una fase a otra.</p>
<p>La Figura 14.3, ilustra los ciclos EEG del sueño nocturno típico, así
  como la estrecha relación entre la fase 1 emergente, los REMs y la
  pérdida de tono en los músculos axiales. Repárese en que cada ciclo
  suele durar unos noventa minutos y que, a medida que avanza el sueño
  nocturno, se pasa cada vez más tiempo en fase 1 emergente y menos en las
  otras fases, especialmente en fase 4. Obsérvese también que hay breves
  momentos durante la noche en los que el sujeto está despierto; estos
  períodos de vigilia no se suelen recordar por la mañana.</p>
<p>Hagamos aquí una pausa para explicar algunos términos relacionados
  con las fases del sueño. El sueño que se asocia con el EEG de fase 1
  emergente se suele denominar sueño REM, debido a los movimientos
  oculares rápidos [«rapid eye movements»] de los que se acompaña;
  mientras que todas las demás fases del sueño se denominan, en conjunto,
  sueño NREM (sueño no REM). Las fases 3 y 4, de modo global, se conocen
  como sueño de ondas lentas ( <strong>SOL</strong> ) [o sueño delta],
  debido a las ondas delta que lo caracterizan.</p>
<h2>Sueños REM y ensueños</h2>
<p>Un sólido apoyo a la teoría de que el sueño REM es el correlato
  fisiológico de los ensueños provino de la observación de que el 80% de
  los despertares de sueño REM, frente al 7% de despertares de sueño NREM,
  llevaba al relato de un ensueño. Los sueños que se recordaban al
  despertar en sueño NREM consistían en experiencias individuales («me
  estaba cayendo»), a diferencia de las historias que se asociaban con los
  ensueños ocurridos en REM. El fenómeno de los ensueños, que ha sido
  motivo de libre especulación durante siglos, había resultado finalmente
  accesible a la investigación científica. La siguiente anécdota, relatada
  por Dement (1978), transmite algo de la emoción que sintieron quienes
  participaron en el descubrimiento.</p>
<ul>
  <li>Mucha gente cree que los estímulos externos pueden incorporarse a
    sus ensueños. Dement y Wolpert (1958) rociaron con agua a sujetos
    dormidos cuando llevaban unos cuantos minutos en sueño REM y unos
    segundos después se les despertó a cada uno de ellos. En 14 de los 33
    casos, el elemento agua se había incorporado al relato de su ensueño. El
    siguiente relato es el de un sujeto que había soñado que actuaba en una
    obra de teatro.
  </li>
  <li>Algunas personas creen que los ensueños sólo duran un instante, pero
    las investigaciones sugieren que éstos tienen lugar en «tiempo real». En
    un estudio (Dement y Kleitman, 1957), se despertó a los sujetos 5 ó 15
    minutos después del comienzo de un episodio REM y se les pidió que
    juzgaran, basándose en la duración de los sucesos ocurridos en sus
    ensueños, si habían estado soñando durante 5 ó durante 15 minutos.
    Acertaron en 92 de 111 casos.
  </li>
</ul>
<h2>Análisis comparativo del
  sueño</h2>
<p>La investigación comparada del sueño ha llevado a varias conclusiones
  importantes. Consideremos cuatro de ellas.</p>
<ol>
  <li>Primera, el hecho de que todos los mamíferos y aves duerman sugiere
    que el sueño desempeña una función fisiológica importante, y que no
    solamente sirve para proteger a los animales de los peligros y conservar
    la energía. Las pruebas son más sólidas en especies que tienen un mayor
    riesgo de ser atacadas cuando duermen (p.ej., los antílopes), así como
    en especies que han desarrollado mecanismos complejos que les capacitan
    para dormir. Por ejemplo, en algunos mamíferos marinos, tales como los
    delfines, sólo duerme la mitad de su encéfalo en un momento dado, de
    modo que la otra mitad pueda controlar salir a la superficie para tomar
    aire (véase Rattemborg, Amlanev y Lima, 2000). Va en contra de la lógica
    de la selección natural para algunos animales con riesgo de ser atacados
    mientras duermen y para otros que han desarrollado mecanismos complejos
    el permitirles dormir, a menos que el sueño en sí mismo cumpla una
    función crítica (Rechtschaffen, 1998).
  </li>
  <li>Segunda, el hecho de que todos los mamíferos y las aves duerman
    sugiere que la función del sueño no es una función humana de tipo
    superior, especial. Por ejemplo, las propuestas de que el sueño
    contribuye a que los seres humanos reprogramemos nuestros complejos
    cerebros, o que permite cierto tipo de liberación emocional con el fin
    de que mantengamos nuestra salud mental, parecen haber sido descartadas
    debido a los resultados comparativos.
  </li>
  <li>Tercera, las grandes diferencias entre especies respecto al tiempo
    de sueño, sugieren que, aunque se precise el sueño para la
    supervivencia, no se necesita forzosamente en grandes cantidades (véase
    de nuevo la Tabla 14.1). A los caballos y otros muchos animales les
    basta dormir de dos a tres horas diarias.
  </li>
  <li>Cuarta, numerosos estudios han tratado de identificar algunas
    características que identifiquen diversas especies como largos o cortos
    durmientes. ¿Por qué los gatos suelen dormir unas catorce horas al día y
    los caballos sólo alrededor de dos? Bajo la influencia de las teorías de
    recuperación, los investigadores han centrado su esfuerzo en los
    factores relacionados con la energía. Sin embargo, no hay una clara
    relación entre el tiempo de sueño de distintas especies y su nivel de
    actividad, su tamaño corporal o su temperatura corporal. El hecho de que
    el oso perezoso gigante duerma 20 horas diarias es un argumento de peso
    contra la teoría de que el sueño es una reacción compensatoria al gasto
    de energía. Por el contrario, las teorías circadianas predicen de manera
    correcta que el tiempo diario de sueño de cada especie se relaciona con
    la vulnerabilidad de dicha especie mientras duerme y con la cantidad de
    tiempo que tiene que dedicar cada día a alimentarse y ocuparse de sus
    otras necesidades de supervivencia. Por ejemplo, las cebras deben pastar
    casi continuamente para comer lo suficiente y son extremadamente
    vulnerables a los ataques de los depredadores mientras duermen. Sin
    embargo, los leones africanos duermen a menudo de manera casi continua a
    lo largo de dos o tres días tras haberse atiborrado con una presa.
  </li>
</ol>
<h2>Ciclos circadianos de sueño</h2>
<p>El mundo en que vivimos oscila entre periodos de luz y oscuridad de
  24 horas, y la mayoría de las especies que viven en la superficie de la
  tierra se han adaptado a este cambio regular de su entorno,
  desarrollando así una variedad de los llamados ritmos circadianos (véase
  Foster y Kreitzman, 2004). (Circadiano significa «que dura
  aproximadamente un día».) Por ejemplo, la mayoría de las especies
  presentan un ciclo circadiano regular de vigilia-sueño. Los humanos
  aprovechan la luz del día para atender sus necesidades biológicas y
  duermen la mayor parte de la noche. Los animales nocturnos, como las
  ratas, duermen la mayor parte del día y permanecen despiertos durante la
  noche. Aunque el ciclo de sueño-vigilia es el más obvio de los ritmos
  circadianos, es prácticamente imposible encontrar en animales un proceso
  fisiológico, bioquímico o conductual que no muestre en alguna medida una
  ritmicidad circadiana. Todos los días, en nuestros cuerpos se efectúan
  una serie de cambios para que nos adaptemos a las exigencias de los dos
  entornos en que vivimos: el de la luz y el de la oscuridad.</p>
<p>Nuestros ciclos circadianos se mantienen en su programa de 24 horas
  mediante claves que proporciona el ambiente. La clave más importante
  para la regulación de los ritmos circadianos en mamíferos es el ciclo
  diario de luz y oscuridad: las claves ambientales que pueden arrastrar
  (controlar el momento en que ocurren) los ritmos circadianos se llaman
  sincronizadores [«Zeitgebers»], una palabra alemana que significa
  «marcadores de tiempo». En el ambiente controlado de un laboratorio, es
  posible alargar o acortar los ritmos circadianos modificando el ciclo de
  luz oscuridad. Por ejemplo, cuando se someten a períodos alternantes de
  10 horas de luz y 10 horas de oscuridad, los ciclos circadianos de los
  sujetos empiezan a adaptarse a días de 20 horas. En un mundo sin ciclos
  de luz y oscuridad de 24 horas, hay otros sincronizadores que pueden
  gobernar los ciclos circadianos. Por ejemplo, los ciclos circadianos de
  sueño-vigilia de hámsteres que viven bajo luz o bajo oscuridad continua,
  pueden estar sujetos a turnos cotidianos regulares de interacción
  social, acumulación de alimentos, comida o ejercicio físico (véase
  Mistlberger, 1994; Mistlberger et al., 1996, 1994; Sinclair y
  Mistlberger, 1997). Los hámsteres presentan ciclos circadianos
  especialmente evidentes y se utilizan como animales de experimentación
  para el estudio de los ritmos circadianos.</p>
<p>El estudio del sueño en ausencia de sincronizadores proporciona un
  método eficaz para estudiar el control del patrón temporal del sueño.
  ¿Qué ocurre con el ciclo vigilia-sueño y otros ciclos circadianos en un
  ambiente carente de sincronizadores? Sorprendentemente, bajo condiciones
  en las que no existe en absoluto ninguna clave temporal, los humanos y
  otros animales mantienen la totalidad de sus ritmos circadianos. Los
  ritmos circadianos de entornos estables se denominan ritmos de curso
  libre y su duración se llama período de curso libre. Los
  <strong>períodos de curso libre</strong> varían de longitud de un sujeto
  a otro, tienen una duración relativamente constante en cada sujeto y
  suelen durar más de 24 horas —alrededor de 25 en la mayoría de los seres
  humanos (véase Lavie, 2001)—.</p>
<h2>Efectos de la privación de
  sueño</h2>
<p>Las teorías circadianas y de recuperación hacen predicciones
  específicas sobre los efectos de la privación de sueño. Dado que las
  teorías de recuperación se basan en la premisa de que el sueño es una
  respuesta a la acumulación de algún efecto debilitador de la vigilia,
  predicen:</p>
<ol>
  <li>que los períodos largos de vigilia producirán alteraciones
    fisiológicas y conductuales;
  </li>
  <li>que estas alteraciones empeorarán a medida que continúe la privación
    de sueño y
  </li>
  <li>que, una vez finalizado un período de privación de sueño, se
    recupera gran parte del sueño perdido. ¿Se han confirmado estas
    predicciones?
  </li>
</ol>
<p>La Sra. Maureen Weston sustituyó más tarde a Randy Gardner en el
  Libro de los records mundiales. Durante una maratón de mecedoras en
  1977, la Sra. Weston se mantuvo balanceándose durante 449 horas (18
  días, 17 horas) —una impresionante muestra de «meciéndose en torno al
  reloj»—.</p>
<p>Se han observado alteraciones en algunos estudios, pero no en otros,
  incluso tras periodos de privación prolongados (p.ej., Bonnet y Arand,
  1996; Dinges et al., 1997; Gillberg et al., 1996; Harrison y Horne,
  1997). Por ejemplo, Martin (1986) concluyó que los cambios fisiológicos
  adversos que siguen a la privación de sueño aún han de ser probados
  convincentemente; Van Helder y Radomski (1989) hallaron que períodos de
  privación de sueño de más de 72 horas no influían en la fuerza física o
  el rendimiento motor, salvo por una disminución del tiempo en alcanzar
  el estado de agotamiento; y se ha comprobado que pruebas activas de
  capacidad cognitiva compleja (tales como pruebas de inteligencia —CI—)
  son en gran medida inmunes a la alteraciones provocadas por la privación
  de sueño (Binks, Waters y Hurry, 1999; Percival, Horne y Tilley,1983).
  Ha de señalarse, sin embargo, que aunque el rendimiento en pruebas de
  inteligencia se ve poco influido por la privación de sueño, Horne (1983)
  encontró que 32 horas de esta privación alteran notablemente el
  rendimiento en diversas pruebas diseñadas expresamente para medir la
  creatividad.</p>
<h2>Privación del sueño REM</h2>
<p>Una
  teoría reciente acerca del sueño REM se basa en la premisa de que este
  tipo de sueño no cumple una función esencial: ésta es la teoría del
  sueño REM por defecto (Horne, 2000). Conforme a esta teoría, es difícil
  permanecer continuamente en sueño NREM, de modo que el cerebro cambia
  periódicamente de un estado a otro. Si hay una necesidad física que
  satisfacer inmediatamente (p.ej., comer o beber), el cerebro pasa a
  vigilia; si no hay necesidades inmediatas cambia por defecto al estado
  de sueño REM. Según dicha teoría, el sueño REM y la vigilia son estados
  similares, pero el sueño REM es más adaptativo cuando no hay necesidades
  físicas inmediatas. Un apoyo indirecto de esta teoría procede de las
  muchas semejanzas entre el sueño REM y la vigilia. Por ejemplo, el
  lector ya conoce los elevados niveles de actividad neuronal, la rápida
  frecuencia cardiaca y la alta tensión arterial que caracterizan al sueño
  REM; y se ha demostrado que los sujetos se despiertan fácil y
  rápidamente del sueño REM (véase Horne, 2000).</p>
<p>Un estudio de Nycamp y colaboradores (1998) proporciona más apoyo
  directo a la teoría del sueño REM por defecto. Estos investigadores
  despertaron a sujetos cada vez que entraban en fase de sueño REM pero,
  en vez de permitirles dormirse de nuevo inmediatamente, sustituyeron un
  periodo de 15 minutos de vigilia por cada uno de los periodos REM
  perdidos. En estas condiciones, los sujetos, a diferencia de los sujetos
  del grupo de referencia, no se sintieron cansados al día siguiente, pese
  a que sólo habían dormido cinco horas, y no tuvieron rebote de sueño
  REM. En otras palabras, no parecía haber necesidad de sueño REM si se
  sustituía con periodos de vigilia. Esto es consistente con el hallazgo
  de que cuando los antidepresivos reducen el sueño REM, aumenta el número
  de despertares nocturnos (véase Horne, 2000).</p>
<p>Despertar repetidamente a los sujetos durante sueño REM produce un
  escaso aumento, si es que alguno, de la somnolencia que sienten al día
  siguiente; mientras que despertar repetidamente a los sujetos durante el
  sueño de ondas lentas tiene consecuencias notables (Nykamp et al.,
  1998).</p>
<p>Moruzzi y Magoun, propusieron que un nivel bajo de actividad en la
  formación reticular produce sueño y que un nivel elevado produce
  vigilia. En efecto, esta teoría está tan ampliamente aceptada que a la
  formación reticular se le llama sistema reticular activador, aun cuando
  mantener la vigilia sea solamente una de las funciones de los muchos
  núcleos que incluye.</p>
<p>Esto sugiere que los estados de sueño REM, sueño de ondas lentas y
  vigilia no están controlados cada uno de ellos por un único mecanismo.
  Parece ser que cada estado resulta de la interacción de varios
  mecanismos que pueden, bajo determinadas condiciones, operar
  independientemente uno del otro.</p>
<p>Una vez que los investigadores establecieron que los genes
  circadianos en el interior de las neuronas del NSQ transcribían sus
  productos proteínicos en un ciclo circadiano, empezaron a examinar los
  mismos genes en otras células del organismo y se quedaron asombrados de
  lo que encontraron: existen mecanismos de sincronización circadianos
  similares a los del NSQ en la mayor parte de las células del organismo
  (véase Green y Menaker, 2003; Hastings; Reddy y Maywood, 2003; Yamaguchi
  et al., 2003). Pese a que la mayoría de las células contienen un reloj
  genético circadiano, estos relojes celulares normalmente están
  arrastrados por señales neurales y hormonales que proceden del NSQ.</p>
<h2>Trastornos del sueño</h2>
<h3>Insomnio</h3>
<p>Sorprendentemente, uno de los tratamientos más eficaces del insomnio
  es la terapia de restricción de sueño. En primer lugar, se reduce
  sustancialmente la cantidad de tiempo que el insomne permanece en cama.
  Luego, después de un periodo de restricción de sueño, se incrementa
  progresivamente en pequeñas cantidades el tiempo en cama con tal de que
  la latencia del sueño permanezca en el valor normal. Incluso los
  pacientes con insomnio más grave se benefician de esta terapia (Morin,
  Kowatch y O’Shanick, 1990; Spielman, Saskin y Thorpy, 1987).</p>
<h3>Hipersomnia</h3>
<p>Además de los dos síntomas cardinales de la narcolepsia (accesos de
  sueño diurno y cataplejía), los pacientes con narcolepsia a menudo
  experimentan otros dos síntomas: parálisis del sueño y alucinaciones
  hipnagógicas. La parálisis del sueño es la imposibilidad de moverse
  (parálisis) al quedarse dormido o al despertarse. Las alucinaciones
  hipnagógicas son experiencias similares a los ensueños durante la
  vigilia. Muchas personas han experimentado ocasionalmente parálisis del
  sueño y alucinaciones hipnagógicas.</p>
<p>Cuando la narcolepsia aparece en un gemelo idéntico, la probabilidad
  de que el otro gemelo padezca narcolepsia es solamente de un 25%. Este
  hecho sugiere que factores ambientales por lo general juegan un papel
  fundamental en el daño cerebral que se asocia a la narcolepsia. Quizás
  la exposición a una neurotoxina inicie una reacción autoinmunitaria
  contra el sistema de orexina.</p>
<p>Algunos pacientes experimentan sueño REM sin atonía muscular axial.
  Se ha sugerido que la función de la atonía del sueño REM es la de
  impedir que el sujeto represente sus ensueños. A favor de dicha teoría
  están los casos clínicos de personas que sufren este trastorno.</p>
<p>Se supone que el sueño REM sin atonía está provocado por una lesión
  del núcleo magnocelular o por una interrupción de su output. El núcleo
  magnocelular es una estructura de la formación reticular caudal, que
  controla la relajación muscular durante el sueño REM. En perros
  normales, está activo únicamente durante el sueño REM; en perros con
  narcolepsia está activo durante sus crisis narcolépticas. Las lesiones
  de la formación reticular caudal suelen inducir un trastorno similar
  relacionado con el sueño REM en gatos.</p>
<h2>Reducción
  prolongada de sueño mediante siestas</h2>
<p>La mayoría de los mamíferos y bebés humanos muestran ciclos de sueño
  polifásicos, es decir, duermen habitualmente más de una vez al día. En
  cambio, la mayoría de los seres humanos adultos muestran ciclos de sueño
  monofásicos; es decir, duermen una vez al día. Sin embargo, la mayoría
  de los humanos adultos muestran ciclos polifásicos de somnolencia, con
  períodos de somnolencia que tienen lugar a última hora de la tarde y de
  la mañana (Stampi, 1992a).</p>
<p>¿Necesitan los adultos humanos dormir en un período continuo cada
  día, o pueden dormir de manera eficaz con pequeñas siestas, como los
  bebés y otros mamíferos?, ¿cuál de los dos patrones de sueño es más
  eficaz? Las investigaciones han demostrado que las siestas tienen un
  poder de recuperación desproporcionado con respecto a su brevedad (véase
  p.ej. Gillberg et al., 1996; Horne y Reyner, 1996; Naitoh, 1992), lo
  que sugiere que el sueño polifásico podría ser particularmente
  eficaz.</p>
<p>El interés en el valor del sueño polifásico fue estimulado por la
  leyenda de que Leonardo da Vinci logró generar un torrente continuo de
  logros artísticos y de ingeniería durante su vida durmiendo quince
  minutos cada cuatro horas, con lo que limitaba su sueño a una hora y
  media al día. Por increíble que parezca, esto se ha replicado en varios
  experimentos (véase Stampi, 1992b). Aquí se presentan los principales
  hallazgos de estos experimentos, verdaderamente complicados.</p>
<ul>
  <li>En primer lugar, los sujetos requirieron mucho tiempo, unas dos
    semanas, para adaptarse a un horario de sueño polifásico.
  </li>
  <li>En segundo lugar, una vez adaptados al sueño polifásico, los sujetos
    estaban satisfechos y no mostraron alteraciones en las pruebas de
    rendimiento que se les aplicaron.
  </li>
  <li>En tercer lugar, el programa de sueño de cuatro horas de Leonardo
    funciona bastante bien, pero en situaciones de trabajo no estructuradas
    (p.ej., como en las regatas alrededor del mundo), los sujetos a menudo
    cambian la duración del ciclo sin sufrir consecuencias adversas.
  </li>
  <li>En cuarto lugar, la mayoría de los sujetos muestra una fuerte
    preferencia por duraciones de sueño determinadas (p.ej., de 25 minutos)
    y se abstienen de dormir demasiado poco, lo que les deja con sensación
    de no haber descansado, o de dormir demasiado, lo que les deja aturdidos
    durante varios minutos cuando se despiertan —un efecto llamado inercia
    del sueño—.
  </li>
  <li>En quinto lugar, al principio el sueño consiste en su mayoría en
    sueño de ondas lentas, pero finalmente los sujetos vuelven a su habitual
    proporción relativa de sueño REM y sueño de ondas lentas. No obstante,
    el sueño REM y el de ondas lentas rara vez ocurren durante la misma
    siesta.
  </li>
</ul>
<h2>Reducción prolongada de
  sueño</h2>
<p>Actualmente una serie de estudios a gran escala, realizados en Estados
  Unidos y Japón nos cuentan una historia diferente (véase p.ej. Ayas et
  al.; Kripke et al.; Patel et al., 2003; Tamakoshi y Ohno, 2004). A
  diferencia de los estudios antiguos, estos nuevos estudios no incluyen
  sujetos que eran una posible fuente de sesgo; por ejemplo, sujetos que
  dormían poco porque estaban enfermos, deprimidos o estresados. Los
  resultados de estos nuevos estudios son notablemente uniformes (Kripke,
  2004). Por ejemplo, la Figura 14.15 presenta datos de Tamakoshi y Ohno
  (2004), quienes siguieron a 104.010 sujetos durante 10 años. Se verá
  inmediatamente que dormir ocho horas cada noche no es el ideal de salud
  que habíamos supuesto. Los escasos fallecimientos ocurridos en sujetos
  que dormían entre cinco y siete horas por noche son, con mucho, menos
  que los producidos en los que dormían ocho horas.</p>
<h1>Drogadicción
  y circuitos cerebrales de recompensa</h1>
<p>Este apartado se centra en los principios básicos de acción de las
  drogas, haciendo hincapié en los psicofármacos —drogas que, al actuar
  sobre el sistema nervioso, influyen en la experiencia subjetiva y el
  comportamiento.</p>
<h2>Cinco drogas de consumo
  frecuente</h2>
<p>Alrededor del setenta por ciento de las personas que prueban un
  <strong>cigarrillo</strong> se vuelven adictos —una cifra muy
  desfavorable si se compara con el 10% respecto al alcohol y el 30%
  respecto a la heroína—. Además, sólo aproximadamente el 20% de los
  intentos de dejar de fumar se mantiene durante dos años o más
  (Schelling, 1992).</p>
<p>Dado que las moléculas de <strong>alcohol</strong> son pequeñas y
  solubles en la grasa y el agua, invaden todas las partes del organismo.
  El alcohol se clasifica como sedante porque a dosis moderadas o altas
  disminuye el disparo neural; sin embargo, a dosis bajas puede estimular
  el disparo neural y facilita la interacción social. La adicción al
  alcohol tiene un fuerte componente genético (Mc Gue, 1999); se calcula
  que puede heredarse genéticamente en un 55%.</p>
<p>El poder adictivo de la <strong>mariguana</strong> es bajo. La
  mayoría de las personas que consumen mariguana lo hacen sólo
  ocasionalmente y muchos de los que la consumen de jóvenes dejan de
  hacerlo a los 30 ó 40 años. La tolerancia a la mariguana se desarrolla
  durante períodos de uso continuado; no obstante, los síntomas de
  abstinencia obvios (p.ej., náuseas, diarrea, transpiración, resfriados,
  temblores, alteraciones del sueño) son poco frecuentes, excepto en
  situaciones artificiales de laboratorio en las que se administran dosis
  orales masivas. El consumo ocasional de pequeñas cantidades de
  mariguana, pauta de consumo preferida por la mayoría de los
  consumidores, tiene pocos, si es que alguno, efectos adversos
  permanentes (Jacques et al., 2004) Incluso el consumo crónico a largo
  plazo tiene efectos que son mucho menos graves que los de sus parientes
  legales: la nicotina y el alcohol.</p>
<p>Los <strong>estimulantes</strong> son drogas cuyo efecto primario es
  producir un aumento general de la actividad neural y comportamental.
  Aunque los estimulantes tienen un perfil de efectos similar, se
  diferencian en gran medida en cuanto a su potencia. La Coca-Cola es un
  preparado comercial moderadamente estimulante que consumen muchas
  personas en todo el mundo. En la actualidad, su acción estimulante puede
  atribuirse a la cafeína, pero cuando se introdujo en el mercado «la
  pausa refrescante» contenía una verdadera sacudida en forma de pequeñas
  cantidades de cocaína. La <strong>cocaína</strong> y sus derivados son
  los estimulantes que más se consumen, y por esto son el tema de esta
  exposición.</p>
<p>La mayoría de la gente se sorprende al enterarse de que hasta
  principios del siglo veinte el <strong>opio</strong> podía comprarse
  legalmente y se consumía en grandes cantidades en muchas partes del
  mundo, incluyendo Europa y Norteamérica. El opio se encontraba en
  pasteles, dulces y vinos, así como en una serie de productos medicinales
  que podían comprarse sin receta. Las pociones de opio, como el láudano
  (una mezcla muy conocida de opio y alcohol), el cordial de Godfrey o el
  carminativo de Dalby, se hicieron muy populares. (La palabra carminativo
  debiera ganar un premio por hacer que esto suene tan bien: un
  carminativo es un medicamento que expele los gases del tubo digestivo,
  reduciendo así los retortijones de estómago y la flatulencia.
  Flatulencia es la opción obvia para el segundo premio.) Había incluso
  pociones de opio sin receta para bebés. Era frecuente que en muchos
  hogares hubiera pociones como el Jarabe calmante de la Sra. Winslow o el
  acertadamente denominado Tranquilidad del bebé de la calle. Aunque en
  aquella época no podía comprarse morfina pura sin receta, los médicos la
  recetaban con tanta frecuencia y para tantas dolencias que la adicción a
  la morfina era algo habitual entre quienes podían permitirse un
  médico.</p>
<p>Aunque los <strong>opiáceos</strong> son muy adictivos, los peligros
  directos para la salud del consumo crónico son asombrosamente leves. Los
  principales riesgos son: estreñimiento, contracción de las pupilas,
  irregularidad de la menstruación y disminución de la libido (impulso
  sexual). Muchos adictos a los opiáceos han tomado heroína pura o morfina
  durante años sin sufrir efectos secundarios graves. De hecho, la
  adicción a los opiáceos está más extendida entre médicos, enfermeras y
  dentistas que entre otros profesionales (véase p.ej., Brewster,
  1986).</p>
<p>Los síntomas de abstinencia de opiáceos no son triviales, pero su
  gravedad se ha exagerado mucho. La abstinencia de opiáceos es casi tan
  grave como un caso malo de gripe —muy distinto de las convulsiones, el
  delirium y el riesgo de muerte que se asocia con la abstinencia de
  alcohol.</p>
<p>El esfuerzo de investigación actual más importante sobre el
  tratamiento de la adicción a la heroína es el experimento suizo. En
  1994, el gobierno suizo instauró —a pesar de una considerable oposición
  por parte de la sociedad— una serie de consultorios en los que, como
  parte del paquete total de tratamiento, se les administraba a los
  residentes adictos a la heroína inyecciones de heroína bajo petición
  (los médicos vigilaban la inocuidad de las dosis). El gobierno suizo
  creó asimismo un importante programa de investigación para evaluar la
  labor de estos consultorios (véase Geschwend et al., 2002). Se ha
  publicado la primera oleada de informes de investigación y los
  resultados han sido uniformemente positivos: los adictos ya no están en
  las calles y en los parques; los delitos relacionados con la droga han
  disminuido sustancialmente; el bienestar físico y social de los adictos
  ha mejorado; ha habido un descenso de la cantidad de nuevos adictos a la
  heroína (véase Brehmer e Iten, 2001; De Preux, DuboisArber y Zobel,
  2004; Guttinger et al., 2003; Rehn et al., 2001).</p>
<h2>Soluciones</h2>
<p>Los expertos recomiendan soluciones al problema de la droga que son
  diferentes de las que prefiere la población norteamericana. Los expertos
  dicen: 1) que no existe forma de detener el suministro —cada redada
  antidroga importante aumenta el precio de la droga en la calle y
  promueve que más proveedores ilícitos se incorporen al mercado—; 2) que
  no tiene sentido perseguir y castigar a los enfermos y los débiles, y 3)
  que es una hipocresía tomar medidas severas contra algunas drogas,
  mientras que se permite anunciar manifiestamente otras que son más
  peligrosas. En contraposición al punto de vista de los expertos, las
  encuestas recientes indican que la población estadounidense, habiendo
  fracasado en el problema de la droga y sin saber cómo solucionarlo,
  quiere que se dedique incluso más dinero a las medidas que han resultado
  ser tan ineficaces.</p>
<h2>Teoría biopsicológica de
  la adicción</h2>
<p>Una teoría del incentivo positivo de la adicción se basa en la idea
  de que el valor de incentivo positivo de las drogas adictivas aumenta
  (es decir, el sujeto se sensibiliza) con el consumo de droga. Robinson y
  Berridge (2003) han sugerido que en las personas predispuestas a la
  adicción, el consumo de drogas sensibiliza su valor de incentivo
  positivo, haciendo así que el consumidor esté muy motivado por consumir
  drogas y buscar estímulos que se asocien con ellas. Merece la pena
  resaltar un punto clave de la teoría de sensibilización al incentivo de
  Robinson y Berridge: defienden que la base de la adicción no es el
  placer (satisfacción) del consumo de la droga en sí mismo, sino el
  placer anticipado (necesidad) del consumo de la droga (es decir, el
  valor de incentivo positivo de la droga). Inicialmente, el valor de
  incentivo positivo de una droga está estrechamente relacionado con sus
  efectos placenteros, pero a menudo se adquiere tolerancia a los efectos
  placenteros; mientras que la necesidad que tiene el adicto de la droga
  se sensibiliza [aumenta]. Así pues, en los adictos crónicos, el valor de
  incentivo positivo de la droga con frecuencia no guarda proporción con
  el placer que en realidad se obtiene de ella: muchos adictos son
  desgraciados, sus vidas están arruinadas, y sienten que los efectos de
  la droga ya no son tan intensos; sin embargo, ansían la droga más que
  nunca.</p>
<p>Se han identificado tres causas de recaída.</p>
<ol>
  <li>La primera es el estrés. La mayoría de los terapeutas y de los
    pacientes señalan el estrés como el mayor factor que influye en la
    recaída. Un dramático ejemplo de la repercusión del estrés en el consumo
    de drogas es el marcado aumento del consumo de cigarillos y alcohol que
    se dio en los ciudadanos de Nueva York tras los ataques del 11 de
    septiembre de 2001.
  </li>
  <li>La segunda causa de recaída es el priming (una sola exposición a la
    droga que se consumía anteriormente). Muchos adictos que se han
    abstenido de consumir la droga durante muchas semanas, y por lo tanto
    creen que han controlado su adicción, prueban sólo una vez la droga que
    consumían antes e inmediatamente se hunden de nuevo en una verdadera
    adicción.
  </li>
  <li>La tercera causa de recaída es entrar en contacto con claves
    ambientales (p.ej., personas, momentos, lugares u objetos) que
    previamente se han asociado con el consumo de la droga (véase Di Ciano y
    Everitt, 2003; Kruzich, Congleton y See, 2001). Se ha comprobado que
    dichas claves ambientales precipitan la recaída. El hecho de que muchos
    soldados estadounidenses que se hicieron adictos a la heroína mientras
    luchaban en la guerra de Vietnam se liberaran fácilmente de su adicción
    cuando volvieron a su hogar se ha atribuido a que dejaron el ambiente
    con el que habían asociado la droga.
  </li>
</ol>
<h2>Sistema dopaminérgico mesotelencefálico y autoestimulación cerebral</h2>
<p>El sistema dopaminérgico mesotelencefálico tiene una función
  importante en la autoestimulación cerebral. El sistema dopaminérgico
  mesotelencefálico es un sistema de neuronas dopaminérgicas que se
  proyecta desde el mesencéfalo hasta diversas regiones del telencéfalo.
  Como se indica en la Figura 15.8, las neuronas que forman el sistema
  dopaminérgico mesotelencefálico tienen sus cuerpos celulares en dos
  núcleos del mesencéfalo —la sustancia negra y el área tegmental
  ventral—. Sus axones se proyectan a una serie de puntos del telencéfalo,
  entre ellas regiones específicas de la neocorteza prefrontal, la corteza
  límbica, el bulbo olfativo, la amígdala, el septum, el cuerpo estriado
  dorsal y, en particular, el núcleo accumbens (un núcleo del cuerpo
  estriado ventral) —véase Zahm, 2000—.</p>
<p>La búsqueda de los mecanismos neurales de la drogadicción se ha
  centrado en la vía mesocorticolímbica. Este interés deriva de tres
  influencias:</p>
<ol>
  <li>del creciente reconocimiento de que los efectos placenteros de las
    drogas, más que el alivio de los efectos de abstinencia, son los
    principales factores que influyen en la adicción;
  </li>
  <li>del hallazgo de que la vía mesocorticolímbica juega un papel
    fundamental en la autoestimulación cerebral; y
  </li>
  <li>del descubrimiento de que la vía mesocorticolímbica está implicada
    en los efectos de las recompensas naturales (p.ej., comida y sexo). Se
    da por descontado que los mecanismos cerebrales no evolucionaron con el
    fin de intervenir en la adicción; por lo tanto, la clave para entender
    los mecanismos neurales de la adicción reside en entender los mecanismos
    de motivación naturales y cómo son escogidos y deformados por las drogas
    adictivas (Nesse y Berridge, 1997).
  </li>
</ol>
<p>En el <strong>paradigma de preferencia de lugar condicionada</strong>
  , las ratas reciben repetidamente una droga en un compartimento (el
  compartimento de droga) de una caja de dos compartimentos. Luego,
  durante la fase de prueba, se coloca a la rata en la caja que no
  contiene droga y se computa la proporción de tiempo que pasa en el
  compartimento con droga en comparación con el que pasa en el
  compartimento de control, del mismo tamaño pero con características
  especiales. Por lo general, las ratas prefieren el compartimento con
  droga al compartimento de control cuando el primero se ha asociado con
  los efectos de drogas a los que se vuelven adictos los seres humanos. La
  principal ventaja del paradigma de preferencia de lugar condicionada es
  que se examina a los sujetos sin que hayan tomado droga, lo que
  significa que no se confunde la medida del valor de incentivo de una
  droga con otros efectos que podría tener la droga sobre la conducta.</p>
<h2>El núcleo accumbens y la
  drogadicción</h2>
<p>Una vez acumulados datos que relacionaban la dopamina con los
  reforzadores naturales y la recompensa que producen las drogas, las
  investigaciones empezaron a explorar puntos concretos de la vía
  dopaminérgica mesocorticolímbica realizando experimentos con animales de
  laboratorio. Sus hallazgos pronto dirigieron la atención al núcleo
  accumbens. Los acontecimientos que suceden en el núcleo accumbens y en
  el input dopaminérgico que recibe desde el área tegmental ventral fueron
  los más claramente relacionados con la experiencia de recompensa y
  placer.</p>
<h2>Apoyo
  de la implicación de la dopamina en la adicción: pruebas de neuroimagen
  de cerebros humanos</h2>
<p>Con el desarrollo de las técnicas de neuroimagen para estimar los
  niveles de dopamina en el cerebro humano, comenzó a surgir una cantidad
  considerable de pruebas de que la dopamina participa en la recompensa
  humana en general y en la adicción humana en particular (véase Vo l kow
  et al., 2004). Uno de los más sólidos estudios iniciales de neuroimagen
  relacionando la dopamina con la adicción fue el publicado por Volkow y
  colaboradores (1997). Administraron diversas dosis de cocaína marcada
  radioactivamente a adictos y les pidieron que evaluaran la intensidad
  del «subidón» resultante. Asimismo utilizaron tomografía por emisión de
  positrones (TEP) para determinar el grado en que la cocaína marcada se
  unía a los transportadores de dopamina. Los transportadores de dopamina
  son moléculas localizadas en la membrana presináptica que atraen a las
  moléculas de dopamina al espacio sináptico y las devuelven al interior
  de la neurona —la cocaína ejerce sus efectos agonistas sobre la dopamina
  uniéndose a estos transportadores, bloqueando su recaptación e
  incrementado por lo tanto los niveles extracelulares de dopamina—. La
  intensidad de los «subidones» que experimentaron los adictos se
  relacionó con el grado en que la cocaína se unió a los transportadores
  de dopamina —no se sintieron en su máxima intensidad a menos que la
  droga se uniera con el 50% de los transportadores de dopamina—.</p>
<p>En general, los estudios de neuroimagen han demostrado que la función
  de la dopamina está marcadamente disminuida en los adictos humanos. Sin
  embargo, cuando se expone a los adictos a su droga, el núcleo accumbens
  y algunas otras partes de la vía dopaminérgica mesocorticolímbica suelen
  hacerse hiperactivas.</p>
<h2>Dopamina,
  núcleo accumbens y adicción: enfoque actual</h2>
<p>Hay pocas dudas acerca de que la dopamina y el núcleo accumbens
  intervengan en la recompensa y la adicción (véase Kelley, 2000): las
  pruebas de ello son muy contundentes. No obstante, los investigadores
  actualmente saben poco acerca de cómo participan. Analicemos las
  siguientes substanciales preguntas sobre la implicación de la dopamina y
  el núcleo accumbens en la recompensa y la adicción.</p>
<p>¿La liberación de dopamina en el núcleo accumbens ocurre
  selectivamente ante la recompensa o ante su expectativa? Joseph, Datla y
  Young (2003) revisaron todos los estudios de diálisis cerebral de
  liberación de dopamina en el núcleo accumbens. Concluyeron que
  prácticamente en todos los estudios que habían intentado demostrar este
  efecto se había demostrado que la recompensa o la expectativa de
  recompensa aumentaba la liberación de dopamina. Más problemático es el
  hecho de que se haya encontrado que una serie de estímulos (incluyendo
  algunos estímulos aversivos) también desencadenan la liberación de
  dopamina en el núcleo accumbens.</p>
<p>¿El núcleo accumbens es la única estructura cerebral que interviene
  en la recompensa? No (Wise, 2004). Aunque la mayoría de la investigación
  sobre las bases neurales de la recompensa se ha centrado en el núcleo
  accumbens, se ha comprobado en animales de laboratorio que varias de las
  estructuras del sistema dopaminérgico telencefálico (p.ej., la corteza
  prefrontal, el cuerpo es triado dorsal y la amígdala) son sensibles a la
  autoestimulación eléctrica y a la autoadministración de sustancias
  químicas. Por otra parte, los estudios de neuroimagen a menudo han
  puesto de manifiesto baja densidad celular e hipoactividad en la corteza
  cingulada anterior de los adictos (véase Peoples, 2002). Podría decirse
  que la prueba más sólida de que el núcleo accumbens no es la única
  estructura neural implicada en la recompensa y la adicción es el
  lamentable fracaso de las lesiones de esta estructura en bloquear la
  recaída de los adictos a los opiáceos (Gao et al., 2003).</p>
<p>¿La dopamina es el único neurotransmisor que interviene en la
  recompensa y la adicción? Datos recientes han señalado que el glutamato
  es otro candidato (Salivas, 2004) —resultan especialmente interesantes
  las proyecciones de neuronas glutamatérgicas desde la corteza prefrontal
  de vuelta al núcleo accumbens—. Una prueba definitiva de que la dopamina
  no es el único neurotransmisor que participa en la recompensa procede de
  ratones knockout que carecen de dopamina: no pierden su capacidad de
  identificar las disoluciones dulces o de que éstas les resulten
  reforzantes (Cannon y Bseikri, 2004).</p>
<p>De modo que ¿cuál es la idea que hay que retener acerca de las
  teorías actuales de la recompensa y la adicción? Hay tres puntos
  importantes:</p>
<ol>
  <li>Una gran cantidad de pruebas implican a la dopamina y el núcleo
    accumbens en la recompensa y la adicción, por lo tanto hay pocas dudas
    de que estén implicados de alguna manera.
  </li>
  <li>Por otra parte, una cantidad considerable de datos indican que
    demostrar la implicación de la dopamina sólo es un primer paso simplista
    para conocer los mecanismos neurales de la recompensa y la
    adicción.
  </li>
  <li>El descubrimiento de que existen muchas conexiones entre los
    mecanismos de la recompensa y los de la adicción ha prestado apoyo al
    enfoque del incentivo positivo de la adicción.
  </li>
</ol>
<p>Freud continuó alabando la cocaína hasta que el verano de 1887, pero
  poco después dejó de golpe de utilizar cocaína —tanto en su consumo
  personal como en su profesión—. Pese al hecho de que había utilizado
  cocaína durante 3 años, pareció no tener problemas en dejarla. Unos
  siete años después, en 1894, cuando Freud tenía 38 años, su médico y
  amigo íntimo le prescribió dejar de fumar, ya que le estaba provocando
  una arritmia cardíaca. Freud era un fumador empedernido; fumaba unos
  veinte puros al día.</p>
<h1>Lateralización,
  lenguaje y cerebro escindido</h1>
<p>Una de las razones por las que el informe de Dax tuvo poca
  repercusión fue que la mayoría de sus contemporáneos pensaba que el
  cerebro actúa como un todo y que no pueden atribuirse funciones
  específicas a partes concretas del mismo. Este punto de vista comenzó a
  cambiar veinticinco años después, cuando Paul Broca informó de su
  autopsia de dos pacientes con afasia. La afasia es una alteración de la
  capacidad de producir o comprender el lenguaje, debido a una lesión
  cerebral.</p>
<p>Sin embargo, varios estudios de neuroimagen han sugerido que las
  mujeres, más que los hombres, utilizan ambos hemisferios para realizar
  tareas de tipo lingüístico (véase p.ej., Jaeger et al., 1998; Kansaku,
  Yamaura y Kitazawa, 2000).</p>
<h2>Cerebro escindido</h2>
<p>Cuando se cambió el parche de ojo, el rendimiento de los gatos
  experimentales cayó inmediatamente hasta los valores iniciales (es
  decir, a un 50% de respuestas correctas); y luego los gatos aprendieron
  de nuevo la tarea sin beneficiarse en absoluto del aprendizaje anterior,
  como si nunca antes la hubieran realizado. En conclusión, Myers y Sperry
  sostuvieron que el cerebro de los gatos tenía capacidad de actuar como
  dos cerebros independientes y que la función del cuerpo calloso es
  transmitir información entre ellos. Las inquietantes conclusiones de
  Myers y Sperry sobre la dualidad esencial del cerebro y la función de
  transferencia de información que tiene el cuerpo calloso se han
  confirmado en varias especies, con varios procedimientos de prueba.</p>
<p>Los resultados de estas pruebas en pacientes con cerebro escindido
  han confirmado los hallazgos en animales de laboratorio en un aspecto
  importante, pero no en otro. Al igual que los animales de laboratorio
  con cerebro escindido, los pacientes humanos con cerebro escindido
  parecen tener dos cerebros independientes, cada uno de ellos con su
  propia corriente de consciencia, capacidades, recuerdos y emociones
  (véase p.ej., Gazzaniga, 1967; Gazzaniga y Sperry, 1967; Sperry, 1964).
  Pero a diferencia de los hemisferios de los animales de laboratorio con
  cerebro escindido, los hemisferios de los pacientes con cerebro
  escindido están muy lejos de tener la misma capacidad para realizar
  determinadas tareas. Lo más notable es que el hemisferio izquierdo de la
  mayoría de los pacientes con cerebro escindido es capaz de hablar,
  mientras que el hemisferio derecho no lo es.</p>
<p>Algunos estudiantes se sienten desconcertados ante los resultados de
  estas pruebas debido a su tendencia, profundamente arraigada, a pensar
  en el cerebro humano como un solo órgano unitario. Si el lector se
  siente desconcertado, imagínese al paciente con el cerebro escindido
  como dos sujetos distintos: el Sr.o la Sra. Hemisferio Derecho, que
  entiende algunas instrucciones sencillas pero no puede hablar, que
  recibe información sensitiva del campo visual izquierdo y la mano
  izquierda, y que controla las respuestas motoras de precisión de la mano
  izquierda; y el Sr.o Sra. Hemisferio Izquierdo, con habilidades
  verbales, que recibe información sensitiva del campo visual derecho y la
  mano derecha, y controla las respuestas motoras de precisión de la mano
  derecha. En la vida cotidiana, la conducta de los sujetos con cerebro
  escindido es bastante normal ya que sus dos cerebros van por la vida
  juntos y en gran medida reciben la misma información; no obstante, en el
  laboratorio neuropsicológico pueden surgir discrepancias significativas
  entre lo que aprenden los dos hemisferios.</p>
<p>Cuando se presentan objetos de prueba al hemisferio derecho, ya sea
  visualmente (en el campo visual izquierdo) o táctilmente (en la mano
  izquierda), la pauta de respuestas es diferente por completo. Es
  probable que un paciente con cerebro escindido al que se pide que diga
  el nombre de un objeto que se ha presentado brevemente en el campo
  visual izquierdo afirme que en la pantalla no ha aparecido nada.
  (Recuérdese que el que está hablando es el hemisferio izquierdo y el que
  ha visto el estímulo es el hemisferio derecho.) Por lo general, un
  paciente a quien se le pide que diga el nombre de un objeto que se ha
  colocado en su mano izquierda es consciente de que tiene algo ahí,
  posiblemente debido a la tosca información táctil que transmiten las
  fibras somatosensitivas homolaterales, pero es incapaz de decir de qué
  se trata (véase Fabri et al, 2001). Sorprendentemente, durante todo el
  tiempo que el paciente afirma (es decir, todo el tiempo que el
  hemisferio izquierdo afirma) que no puede identificar un objeto de
  prueba que se le ha presentado en el campo visual izquierdo o en la mano
  izquierda, la mano izquierda (es decir, el hemisferio derecho) puede
  escoger el objeto correcto. Imagínese lo confundido que puede quedarse
  el paciente cuando, ensayo tras ensayo, la mano izquierda puede palpar
  un objeto y después escoger uno exactamente igual de entre un conjunto
  de elementos de prueba bajo la repisa, mientras que el hemisferio
  izquierdo afirma con vehemencia que no sabe qué es el objeto de
  prueba.</p>
<p>Muy pronto nos dimos cuenta de la estrategia que seguía el paciente.
  Si se presentaba brevemente una luz roja y el paciente adivinaba al azar
  que era roja, seguía dando esa respuesta. Si la luz que se presentaba
  era roja y el paciente decía al azar que era verde, fruncía el ceño,
  movía la cabeza y luego decía: «¡oh no!, quería decir roja». Lo que
  estaba pasando era que el hemisferio derecho veía la luz roja y oía al
  hemisferio izquierdo decir al azar «verde». Sabiendo que la respuesta
  era errónea, el hemisferio derecho fruncía el ceño y negaba con la
  cabeza, lo cual a su vez indicaba al hemisferio izquierdo que la
  respuesta no era correcta y que ¡sería mejor corregirlo!</p>
<p>Si los dos hemisferios de un paciente con cerebro escindido son
  totalmente independientes, podrían aprender dos cosas diferentes al
  mismo tiempo. ¿Podrían? Claro que podrían. Por ejemplo, en una prueba se
  presentaron simultáneamente dos estímulos visuales en la pantalla de
  prueba —supongamos que un lápiz en el campo visual izquierdo y una
  naranja en el derecho—. Se le pidió al sujeto con cerebro escindido que
  buscara simultáneamente dentro de dos bolsas —en cada una con una mano—
  y escogiera con cada mano el objeto que se veía en la pantalla. Después
  de tomar los objetos, pero antes de sacarlos, se le pidió que le dijera
  al experimentador qué era lo que tenía en cada una de sus manos; el
  sujeto (es decir, el hemisferio izquierdo) respondió: «dos naranjas».
  Con gran desconcierto para el hemisferio verbal izquierdo, cuando sacó
  las manos de las bolsas tenía una naranja en la mano derecha y un lápiz
  en la izquierda. Los dos hemisferios del sujeto con cerebro escindido
  habían aprendido dos cosas diferentes exactamente al mismo tiempo.</p>
<p>En algunos ensayos, el hemisferio derecho se enfrentaba con este
  problema de la única forma que podía: la mano izquierda saltaba,
  agarraba a la derecha y la retiraba de la naranja dirigiéndola hacia el
  lápiz. Esta respuesta se denomina <strong>fenómeno de la mano que
    ayuda</strong>.</p>
<p>En la mayoría de los pacientes con cerebro escindido el hemisferio
  derecho no parece tener mucha voluntad por sí mismo; el hemisferio
  izquierdo parece controlar la mayoría de las actividades cotidianas. No
  obstante, en otros pacientes, el hemisferio derecho asume un papel más
  activo en el control de la conducta. En estos últimos casos, puede haber
  un grave conflicto entre el hemisferio izquierdo y el derecho.</p>
<h2>Diferencias
  entre el hemisferio izquierdo y el derecho</h2>
<p>Antes de exponer al lector algunas de las diferencias que existen
  entre el hemisferio izquierdo y el derecho, es necesario aclarar un
  equívoco frecuente: respecto a muchas funciones, no existen diferencias
  entre los hemisferios; y cuando hay diferencias funcionales suelen ser
  ligeros sesgos a favor de un hemisferio u otro —no diferencias absolutas
  (véase Brown y Kosslyn, 1993)— Sin tener en cuenta estos hechos, los
  medios de comunicación como siempre retratan las diferencias cerebrales
  entre izquierda y derecha como absolutas. En consecuencia, existe la
  creencia generalizada de que diversas capacidades residen exclusivamente
  en un hemisferio u otro. Por ejemplo, existe la creencia generalizada de
  que el hemisferio izquierdo tiene el control absoluto del lenguaje y que
  el hemisferio derecho lo tiene de la emoción y la creatividad. Lo más
  inquietante de esta falsa concepción es que los programas educativos a
  veces se basan en ella.</p>
<p>Las capacidades lingüísticas son un ejemplo particularmente bueno del
  hecho de que la lateralización de la función es estadística más que
  total. El lenguaje es la capacidad más lateralizada de todas las
  capacidades cognitivas. Pese a todo, incluso este caso tan extremo, la
  lateralización está lejos de ser total; en el hemisferio derecho se da
  una actividad lingüística sustancial. He aquí tres pruebas de esto:</p>
<ol>
  <li>Primera, en la prueba de escucha dicótica, los sujetos con dominancia
    izquierda respecto al lenguaje suelen identificar más dígitos con el
    oído derecho que con el izquierdo, pero esta ventaja del oído derecho es
    sólo una ligera ventaja: entre el 55% y el 45%.
  </li>
  <li>Segunda, en la mayoría de los pacientes con cerebro escindido el
    hemisferio izquierdo es dominante para el lenguaje, pero el hemisferio
    derecho puede entender muchas palabras habladas o escritas y frases
    sencillas (véase Baynes y Gazzaniga, 1997; Zaidel, 1987).
  </li>
  <li>Y tercera, aunque se da una considerable variabilidad entre los
    pacientes con cerebro escindido en cuanto a su rendimiento con el
    hemisferio derecho en pruebas de comprensión del lenguaje (Gazzaniga,
    1998), las capacidades lingüísticas de su hemisferio derecho suelen ser
    comparables a las de los niños de edad preescolar.
  </li>
</ol>
<p>El estudio de la lateralización de funciones ha descartado la arcaica
  noción de dominancia del hemisferio izquierdo. Se ha demostrado que el
  hemisferio derecho es superior al izquierdo desde el punto de vista
  funcional en varios aspectos. Los tres terrenos en los que más se ha
  probado la superioridad del hemisferio derecho son la capacidad
  espacial, la emoción y la capacidad musical. Asimismo, el hemisferio
  derecho es superior en algunas tareas de memoria. Antes de analizar
  estas cuatro superioridades del hemisferio derecho, conozcamos una
  superioridad insospechada del hemisferio izquierdo.</p>
<ul>
  <li>Superioridad del hemisferio izquierdo en el control del movimiento
    homolateral: El hecho de que sea más probable que las lesiones del
    hemisferio izquierdo se relacionen con problemas motores homolaterales
    que las lesiones del hemisferio derecho es coherente con esta
    observación.
  </li>
  <li>Superioridad del hemisferio derecho en capacidad espacial: Levy
    llegó a la conclusión de que el hemisferio derecho era superior al
    izquierdo en tareas espaciales. Esta conclusión se ha confirmado en
    varias ocasiones (véase, p.ej., Funnell, Corballis y Gazzaniga, 1999;
    Kaiser et al., 2000) y es coherente con el hallazgo de que los
    trastornos de percepción espacial (p.ej., la negligencia contralateral
    —véanse los Capítulos 7 y 8—) suelen estar relacionados con daño del
    hemisferio derecho.
  </li>
  <li>Superioridad del hemisferio derecho en la experiencia de la emoción:
    Según el antiguo concepto de dominancia del hemisferio izquierdo, el
    hemisferio derecho no interviene en la emoción. Se ha demostrado que
    este supuesto es falso. En efecto, el análisis de los efectos de
    lesiones cerebrales unilaterales indica que el hemisferio derecho es
    superior al izquierdo en la percepción tanto de expresiones faciales
    (Bowers et al., 1985) como del estado de ánimo (Tompkins y Mateer,
    1985).
  </li>
  <li>Superioridad del hemisferio derecho en la capacidad musical: El oído
    derecho (es decir, el hemisferio izquierdo) tuvo mejor rendimiento en la
    percepción de dígitos, mientras que el oído izquierdo (es decir, el
    hemisferio derecho) lo tuvo en la percepción de melodías. Esto es
    coherente con la observación de que es más probable que las lesiones de
    lóbulo temporal derecho alteren la discriminación musical que las
    lesiones de lóbulo temporal izquierdo.
  </li>
  <li>Diferencias hemisféricas en memoria: Los dos hemisferios parecen
    diferir algo asimismo en cuanto al tipo de información que recuerdan. En
    general, el hemisferio izquierdo juega un papel más significativo en
    memoria de material verbal, mientras que el hemisferio derecho lo hace
    en la de material no verbal (véase p.ej., Kelley et al., 2002)
  </li>
</ul>
<h2>¿Qué
  está lateralizado, amplios grupos de capacidades o procesos cognitivos
  específicos?</h2>
<p>Las primeras teorías de la lateralidad tendían a atribuir grupos
  complejos de capacidades mentales a un hemisferio u otro. El hemisferio
  izquierdo suele tener un mejor rendimiento en pruebas de lenguaje, de
  modo que se supone que es dominante en capacidades lingüísticas; el
  hemisferio derecho suele tener mejor rendimiento en ciertas pruebas
  espaciales, de modo que se supone que es dominante en capacidades
  espaciales; y así sucesivamente. Quizá este sea un primer paso
  razonable, pero actualmente la opinión que predomina en los
  investigadores es que esta aproximación es simplista, ilógica y no
  coincide con los datos.</p>
<p>El problema es que categorías tales como lenguaje, capacidad musical
  y capacidad espacial se componen cada una de ellas de docenas de
  actividades cognitivas individuales y no hay motivo para suponer que
  todas las actividades asociadas con un rótulo general (p.ej., capacidad
  espacial) estén necesariamente lateralizadas en el mismo hemisferio. Se
  ha confirmado lo inadecuado de categorías amplias de lateralización
  cerebral. ¿Cómo es posible sostener que todas las capacidades
  lingüísticas están lateralizadas en el hemisferio izquierdo cuando el
  hemisferio derecho ha demostrado ser superior en percibir la entonación
  del habla y la identidad del orador (Beerma y Chiarello, 1998)? De
  hecho, han surgido notables excepciones a todas las categorías amplias
  de lateralización cerebral (véase Vogel, Bowers y Vogel, 2003).</p>
<p>Basaron su investigación en la teoría cognitiva de Kosslyn (1994).
  Kosslyn encontró pruebas de que procesos independientes en el sistema
  visual juzgan tipos diferentes de relaciones espaciales entre objetos:
  existe un proceso para hacer juicios categóricos sobre relaciones
  espaciales (p.ej., izquierda/derecha, encima/debajo) y uno para hacer
  juicios precisos de las relaciones espaciales entre objetos en términos
  de su distancia y ángulo uno respecto a otro puesto que el proceso de
  hacer juicios espaciales categóricos es dominante en el hemisferio
  izquierdo y el proceso de hacer juicios espaciales coordinados
  (referentes a distancia y ángulos) lo es en el hemisferio derecho,
  Chabris y Kosslyn predijeron que el hemisferio izquierdo sería superior
  en juzgar si un objeto está encima o debajo de otro y que el hemisferio
  derecho sería mejor en juzgar si dos objetos están separados más o menos
  de determinados centímetros. Estaban en lo cierto.</p>
<h2>Asimetrías
  neuroanatómicas del cerebro</h2>
<p>Puesto
  que el plano temporal, la circunvolución de Heschl y el opérculo frontal
  intervienen en actividades lingüísticas, podría esperarse que todas
  estas zonas estuvieran más desarrolladas en el hemisferio izquierdo que
  en el derecho en la mayoría de las personas: pero no lo están. El plano
  temporal izquierdo tiende a ser mayor en el hemisferio izquierdo, pero
  sólo en el 65% de los cerebros humanos (Geschwind y Levitsky, 1968). Por
  lo contrario, la corteza de la circunvolución de Heschl por lo general
  es mayor en el hemisferio derecho, básicamente porque en el hemisferio
  derecho suele haber dos circunvoluciones de Heschl mientras que en el
  izquierdo solamente hay una. La lateralidad del opérculo frontal está
  menos clara. La zona del opérculo frontal visible en la superficie del
  cerebro tiende a ser mayor en el lado derecho; sin embargo, cuando se
  tiene en cuenta la corteza oculta en los surcos del opérculo frontal, el
  volumen de la corteza del opérculo frontal suele ser mayor en el
  izquierdo (Falzi, Perrone y Vignolo, 1982).</p>
<p>Conviene hacer una advertencia. Resulta tentador concluir que la
  tendencia a que el plano temporal esté más desarrollado en el hemisferio
  izquierdo predispone al hemisferio izquierdo a ser el dominante en el
  lenguaje. De hecho, el descubrimiento de que el plano temporal izquierdo
  es mayor que el derecho en cerebros fetales (Wada, Clarke y Hamm, 1975)
  es coherente con esta idea. No obstante, debido a que la mayoría de los
  estudios de asimetrías neuroanatómicas se realizan en autopsias, no
  existen pruebas de que las personas con asimetrías anatómicas bien
  definidas suelan tener más lateralizadas las funciones lingüísticas. De
  hecho, existe una discrepancia significativa entre la proporción de
  personas que, según los informes, tienen un plano temporal izquierdo más
  desarrollado (alrededor del sesenta y cinco por ciento) y la de aquellas
  cuyo hemisferio dominante para el lenguaje es el izquierdo (más del
  noventa por ciento).</p>
<p>Utilizaron resonancia magnética estructural (RM) para determinar la
  asimetría del plano temporal y relacionarla con el oído absoluto (la
  capacidad de identificar el tono de notas musicales aisladas). Se ha
  comprobado que el plano temporal está más lateralizado en el hemisferio
  izquierdo en músicos con oído absoluto que en personas que no se dedican
  a la música o en músicos sin oído absoluto (véase la Figura 16.8).</p>
<p>Sin
  embargo, recientemente los anatomistas han comenzado a estudiar las
  diferencias de estructura celular entre áreas correspondientes de los
  dos hemisferios que se ha visto que tienen una función diferente (véase
  Gazzaniga, 2000; Hutsler y Galuske, 2003). Uno de estos estudios fue
  realizado por Galuske y colaboradores (2000). Compararon la organización
  de microcircuitos en una parte del área de Wernicke con su organización
  en la misma parte del hemisferio derecho. Encontraron que las áreas de
  los dos hemisferios se organizan en columnas regularmente espaciadas de
  neuronas interconectadas y que las columnas estaban interconectadas por
  axones de calibre medio. Las columnas tienen el mismo diámetro en ambos
  hemisferios, pero en el hemisferio izquierdo están un 20% más separadas
  y están interconectadas por axones más largos. Es de suponer que el modo
  particular en el que se organizan las columnas en el área de Wernicke es
  una adaptación del procesamiento de las señales del lenguaje.</p>
<p>Las investigaciones sobre las asimetrías en el área de la mano de la
  corteza motora primaria humana han desembocado en un modelo similar de
  hallazgos (véase Hammond, 2002). El área de la mano en el hemisferio
  contralateral a la mano que tiende a utilizar más la persona suele ser
  mayor y tener más conexiones laterales.</p>
<h2>Teorías sobre la asimetría
  cerebral</h2>
<h3>Teoría motora</h3>
<p>Una segunda teoría de la asimetría cerebral es la teoría motora
  (véase Kimura, 1979). Según la teoría motora de la asimetría cerebral,
  el hemisferio izquierdo está especializado no en el control del habla en
  sí misma, sino en el control de movimientos de precisión, de los que el
  lenguaje es solamente una categoría. Esta teoría recibe apoyo de
  informes de que lesiones que producen afasia también producen otras
  alteraciones motoras. Por ejemplo, Kimura (1987) encontró una relación
  entre la alteración de capacidades lingüísticas debida a lesiones y la
  alteración de movimientos bucales voluntarios no relacionados con el
  habla; Kimura y Watson (1989) hallaron que las lesiones frontales
  izquierdas producían alteraciones en la capacidad de producir tanto los
  sonidos del habla individuales como los movimientos faciales
  individuales, mientras que las lesiones temporales y parietales
  izquierdas producían una disminución de la capacidad de producir
  secuencias de sonidos del habla y secuencias de movimientos faciales; y
  Wolff y colaboradores (1990) descubrieron que los sujetos con
  dificultades de lectura también tenían problemas para realizar una tarea
  de golpeteo con los dedos.</p>
<h3>Teoría lingüística</h3>
<p>Una tercera teoría de la asimetría cerebral es la teoría lingüística.
  La teoría lingüística de la asimetría cerebral postula que la función
  principal del hemisferio izquierdo es el lenguaje —a diferencia de la
  teoría analítico-sintética y la teoría motora, las cuales consideran el
  lenguaje como una especialización secundaria que reside en el hemisferio
  izquierdo dado su especialización primaria en el razonamiento analítico
  y en la actividad motora de precisión, respectivamente. La teoría
  lingüística de la asimetría cerebral se basa en gran parte en el estudio
  de personas sordas que utilizan el Lenguaje de Señas Americano [American
  Sign Language] (un lenguaje de señas con una estructura similar a la del
  lenguaje hablado) y que después han sufrido una lesión cerebral
  unilateral (véase Hickok, Bellugi y Klima, 2001).</p>
<h2>Evolución
  de la lateralización cerebral de la función</h2>
<p>Todos estos datos sugieren que la evolución de la lateralidad
  cerebral precedió a la evolución de los seres humanos. Es interesante
  señalar que el circuito motor que controla el canto en los canarios
  macho está más desarrollado en el lado izquierdo de su cerebro (véase
  Mooney, 1999). Ya que las aves no forman parte del linaje evolutivo de
  los seres humanos —las aves evolucionaron de los reptiles en una línea
  separada— este descubrimiento indica, ya sea que la lateralidad cerebral
  evolucionó antes de esa ramificación, o que las ventajas de la
  lateralidad cerebral llevaron a que evolucionara independientemente en
  más de una especie.</p>
<h2>Evaluación
  del modelo de Wernicke y Geschwind (desuso)</h2>
<p>Teniendo en cuenta que el modelo de Wernicke y Geschwind se
  desarrolló a partir del estudio de pacientes con lesiones corticales, es
  apropiado comenzar a evaluarlo comprobando su capacidad de predecir las
  alteraciones lingüísticas que producen la lesión de diferentes partes de
  la corteza.</p>
<p>El
  estudio de pacientes neuroquirúrgicos no ha confirmado en modo alguno
  las predicciones del modelo de Wernicke y Geschwind. Véanse los seis
  casos que se resumen en la Figura 16.12. Las operaciones en las que se
  destruye toda el área de Broca respetando la mayoría del tejido que la
  rodea por lo general no tiene un efecto duradero sobre el habla
  (Penfield y Roberts, 1959; Rasmussen y Milner. 1975; Zangwill, 1975). Se
  han observado algunos problemas del habla tras la extirpación del área
  de Broca, pero su evolución temporal sugirió que se debían a un edema
  (hinchazón) posoperatorio en el tejido neural adyacente, más que a la
  escisión (corte) en sí misma del área de Broca. Antes de que se usaran
  fármacos antinflamatorios eficaces, los pacientes con una escisión del
  área de Broca a menudo recuperaban el conocimiento con sus capacidades
  lingüísticas completamente intactas, y luego manifestaban graves
  problemas de lenguaje durante algunas horas posteriores que remitían en
  las semanas siguientes. De manera parecida, las lesiones quirúrgicas
  delimitadas del fascículo arqueado no producen problemas de habla
  permanentes y las lesiones quirúrgicas que se restringen a la corteza de
  la circunvolución angular no producen alexia ni agrafia permanentes
  (Rasmussen y Milner, 1975).</p>
<p>Menos comprobadas están las consecuencias de la extirpación
  quirúrgica del área de Wernicke; considerando las funestas predicciones
  de Wernicke, los cirujanos han vacilado a la hora de extirparla. No
  obstante, en algunos casos se ha extirpado una parte considerable del
  área de Wernicke sin que se produjeran alteraciones de lenguaje
  duraderas (p.ej., Ojemann. 1979; Penfield y Roberts, 1959). Los
  partidarios del modelo de Wernicke y Geschwind razonan que, a pesar de
  la precisión de la escisión quirúrgica, deberían descartarse los datos
  negativos obtenidos del estudio de los efectos de la cirugía cerebral.
  Argumentan que la patología cerebral que ha justificado la cirugía puede
  haber reorganizado el control del lenguaje por parte del cerebro.</p>
<p>Hécaen y Angelergues hallaron que las lesiones pequeñas del área de
  Broca rara vez producían un deterioro duradero del lenguaje y que las
  restringidas al área de Wernicke en ocasiones no producían este
  deterioro. Las lesiones de tamaño medio producían algunas alteraciones,
  pero, en contra de lo que predice el modelo de Wernicke y Geschwind,
  había la misma probabilidad de que se dieran problemas de articulación
  tras lesiones parietales o temporales de tamaño medio que tras lesiones
  comparables en los alrededores del área de Broca. Todos los demás
  síntomas que produjeron las lesiones de tamaño medio aparecían con mayor
  probabilidad tras lesiones temporales o parietales que tras lesiones
  frontales.</p>
<p>En los estudios iniciales con TAC realizados por Mazzocchi y Vignolo
  (1979) y por Naeser y colaboradores (1981), ninguno de los pacientes con
  afasia tenía una lesión cortical restringida a las áreas de Broca o de
  Wernicke, y todos presentaban extensas lesiones de la sustancia blanca
  subcortical.</p>
<p>Puesto que la estimulación eléctrica de la corteza produce un efecto
  mucho más localizado que una lesión cerebral, ha sido un método útil
  para poner a prueba las predicciones del modelo de Wernicke y Geschwind.
  Penfield y Roberts (1959) publicaron el primer estudio a gran escala de
  los efectos de la estimulación cortical sobre el habla. Encontraron que
  los puntos en los que la estimulación impedía o alteraba el habla en
  pacientes neuropsicológicos conscientes estaban dispersos por una
  extensa superficie de la corteza frontal, temporal y parietal, en lugar
  de estar restringidos a las áreas lingüísticas de Wernicke y Geschwind
  (véase la Figura 16.15). También hallaron que no se daba una tendencia a
  que se produjeran determinadas alteraciones del habla cuando se
  estimulaban determinadas zonas de la corteza: los puntos en los que la
  estimulación producía alteraciones de la pronunciación, confusión al
  contar, incapacidad de nombrar objetos o denominación errónea de objetos
  estaban más o menos entremezclados. La estimulación del hemisferio
  derecho casi nunca alteraba el habla. En una serie de estudios de
  estimulación cortical más recientes, Ojemann y sus colegas (véase
  Ojemann, 1983) evaluaron la denominación, lectura de frases sencillas,
  memoria verbal a corto plazo, capacidad de realizar movimientos de
  imitación con la cara y la boca y capacidad de reconocer fonemas
  —sonidos individuales del habla— durante la estimulación cortical.
  Hallaron que:</p>
<ol>
  <li>las áreas de la corteza en las que la estimulación podía alterar el
    lenguaje se extendían más allá de los límites de las áreas del lenguaje
    de Wernicke y Geschwind;
  </li>
  <li>todas las pruebas de lenguaje resultaban afectadas por la
    estimulación de puntos muy dispersos; y
  </li>
  <li>había diferencias importantes entre los sujetos en cuanto a la
    organización de las capacidades lingüísticas.
  </li>
</ol>
<p>De cualquier manera, las pruebas no han sustentado las predicciones
  específicas del modelo de Wernicke y Geschwind.</p>
<ol>
  <li>En primer lugar, el daño que se restringe a los límites de las áreas
    corticales de Wernicke y Geschwind no suele tener un efecto duradero en
    el uso del lenguaje.
  </li>
  <li>En segundo lugar, el daño cerebral que no incluye alguna de las
    áreas de Wernicke y Geschwind puede producir afasia.
  </li>
  <li>En tercer lugar, la afasia de Broca y la de Wernicke rara vez se dan
    en la forma pura que implica el modelo de Wernicke y Geschwind; la
    afasia prácticamente siempre implica síntomas tanto expresivos como
    receptivos (véase Benson, 1985).
  </li>
  <li>En cuarto lugar, parece haber diferencias significativas en cuanto a
    la localización de las áreas corticales del lenguaje en diferentes
    individuos.
  </li>
</ol>
<h2>Enfoque de la
  neurociencia cognitiva del lenguaje</h2>
<ol>
  <li>Premisa 1: Las conductas lingüísticas están mediadas por la
    actividad de aquellas áreas particulares del cerebro que intervienen en
    los procesos cognitivos específicos que requieren las conductas. El
    modelo de Wernicke y Geschwind postuló que determinadas áreas del
    cerebro implicadas en el lenguaje estaban cada una de ellas dedicadas a
    actividades específicas, pero complejas, tales como el habla, la
    comprensión o la lectura. Pero la investigación de la neurociencia
    cognitiva ha encontrado que cada una de estas actividades puede
    descomponerse en procesos cognitivos constituyentes, los cuales pueden
    organizarse en diferentes partes del cerebro (Neville y Bavelier, 1998).
    En consecuencia, estos procesos cognitivos constituyentes, y no la
    actividad general de Wernicke y Geschwind, parece ser el nivel apropiado
    al que se llevan a cabo los análisis. Los neurocientíficos cognitivos
    por lo general dividen los procesos cognitivos que participan en el
    lenguaje en tres categorías de actividad: análisis fonológico (análisis
    del sonido del lenguaje), análisis gramatical (análisis de la estructura
    del lenguaje) y análisis semántico (análisis del significado del
    lenguaje).
  </li>
  <li>Premisa 2: Las áreas del cerebro que intervienen en el lenguaje no
    se dedican únicamente a tal fin (Nobre y Plunkett, 1997). En el modelo
    de Wernicke y Geschwind, se suponía que amplias áreas de la corteza
    cerebral izquierda estaban dedicadas únicamente al lenguaje; mientras
    que el enfoque de la neurociencia cognitiva asume que muchos de los
    procesos cognitivos constituyentes implicados en el lenguaje también
    juegan un papel en otras conductas (véase Bischoff, Grethe et al.,
    2000). Por ejemplo, algunas de las áreas cerebrales que participan en la
    memoria a corto plazo y el reconocimiento visual de patrones están
    claramente implicadas asimismo en la lectura.
  </li>
  <li>Premisa 3: Puesto que muchas de las áreas cerebrales que ejecutan
    funciones lingüísticas específicas también forman parte de otros
    sistemas funcionales, es probable que estas áreas sean pequeñas, estén
    ampliamente distribuidas y estén especializadas (Neville y Bavelier,
    1998). En contraposición, se supone que las áreas del lenguaje del
    modelo de Wernicke y Geschwind son amplias, circunscritas y
    homogéneas.
  </li>
</ol>
<p>Además de estas premisas, la aproximación de la neurociencia
  cognitiva al lenguaje se distingue de la aproximación tradicional por su
  metodología. El modelo de Wernicke y Geschwind descansaba largamente en
  el análisis de pacientes con daño cerebral, mientras que los
  investigadores que siguen el enfoque de la neurociencia cognitiva tienen
  también a su disposición un creciente conjunto de técnicas —entre las
  más destacadas, las de neuroimagen— para estudiar la localización del
  lenguaje en sujetos sanos.</p>
<h3>Estudio
  de Bavelier con resonancia magnética funcional sobre la lectura</h3>
<p>En la
  Figura 16.16, se ilustran los aumentos de actividad relacionados con la
  lectura, promedios de todos los ensayos y todos los sujetos, del estudio
  de Bavelier y colaboradores —tal como por lo general se relatan—. El
  promedio da la falsa impresión de que durante la lectura estaban activas
  amplias extensiones de tejido, de modo homogéneo; si bien los retazos de
  actividad que se produjeron en cada ensayo sólo abarcaban entre el 5% y
  el 10% de las áreas ilustradas. Aun así, hay dos hechos claros: uno es
  que aunque se dio un grado significativo de actividad en el hemisferio
  derecho, hubo mucha más actividad en el hemisferio izquierdo; y otro,
  que la actividad se extendía mucho más allá de las áreas que según el
  modelo de Wernicke y Geschwind están implicadas en la lectura en
  silencio (p.ej., dicho modelo no predecía la actividad en el área de
  Broca y la corteza motora).</p>
<h3>Estudio
  de Damasio con tomografía por emisión de positrones sobre la
  denominación</h3>
<p>El hecho de denominar objetos activó el lóbulo temporal izquierdo más
  allá del área clásica del lenguaje de Wernicke. Sorprendentemente, el
  área precisa que fue activada por la denominación dependió de la
  categoría: las caras famosas, los animales y los instrumentos activaron
  cada uno de ellos un área ligeramente distinta. En general, las áreas
  para la denominación de caras famosas, animales e instrumentos se
  disponen desde la zona anterior a la posterior a lo largo de la parte
  media del lóbulo temporal izquierdo.</p>
<p>Durante actividades lingüísticas prácticamente siempre las técnicas
  de neuroimagen cerebral registran una actividad significativa en el
  hemisferio derecho, lo que sugiere que el hemisferio derecho juega un
  papel importante en el lenguaje; ahora bien, las lesiones del hemisferio
  derecho rara vez alteran este tipo de actividad, lo que sugiere que su
  papel no es esencial. Está claro que se necesita tener en cuenta ambos
  tipos de investigaciones para resolver este enigma (véase Price et
  al.1999).</p>
<h2>Enfoque de la
  neurociencia cognitiva y dislexia</h2>
<p>Paulesu y sus colegas (2000) empezaron por comparar la actividad TEP
  de los cerebros de adultos normales que hablaban o bien inglés o bien
  italiano. Estos investigadores postularon que, ya que las demandas
  cognitivas de la lectura en voz alta son diferentes para quienes hablan
  italiano y quienes hablan inglés, deberían usar diferentes partes de su
  cerebro al leer. Esto es exactamente lo que encontraron. Aunque las
  mismas áreas generales estaban activas durante la lectura en ambos
  grupos, los lectores de italiano presentaron más actividad en la zona
  superior del lóbulo temporal izquierdo; mientras que los lectores de
  inglés presentaron más actividad en la zona inferior del lóbulo temporal
  inferior y en los lóbulos frontales.</p>
<p>A continuación, Paulesu y sus colaboradores (2001) centraron la
  atención en la dislexia del desarrollo. Obtuvieron imágenes de TEP del
  cerebro de estudiantes universitarios normales y con dislexia ingleses,
  franceses e italianos mientras los sujetos leían palabras sueltas en su
  propia lengua. (Los estudiantes universitarios se utilizaron para
  descartar la falta de acceso a la educación como posible variable
  extraña). Pese al hecho de que los italianos con dislexia tenían
  problemas de lectura menos graves, los tres grupos de sujetos con
  dislexia manifestaron el mismo modelo de actividad TEP anómala cuando
  leían: menos actividad de lo normal asociada con la lectura en la región
  posterior del lóbulo temporal, cerca de su frontera con el lóbulo
  occipital. Así pues, aunque la dislexia puede manifestarse de un modo
  diferente en personas que hablan diferentes lenguas, la patología neural
  subyacente parece ser la misma.</p>
<p>¿En qué lugar del cerebro se ejecutan el procedimiento léxico y el
  fonético? Gran parte de las investigaciones que han tratado de responder
  a esta pregunta se han centrado en el estudio de la dislexia profunda.
  Lo más frecuente es que las personas con dislexia profunda tengan una
  extensa lesión de las áreas lingüísticas del hemisferio izquierdo, lo
  que sugiere que el procedimiento fonético alterado está muy distribuido
  por las áreas frontales y temporales del hemisferio izquierdo Pero ¿qué
  parte del cerebro mantiene el procedimiento léxico en las personas con
  dislexia profunda?</p>
<p>Ha habido dos teorías, cada una de ellas cuenta con cierto apoyo.</p>
<ol>
  <li>Una de las teorías es que las capacidades léxicas que perduran en
    quienes padecen dislexia profunda están mediadas por la actividad de las
    partes que perduran de las áreas lingüísticas del hemisferio izquierdo.
    La observación de tal actividad durante la lectura apoya esta teoría
    (Laine et al., 2000; Price et al., 1998).
  </li>
  <li>La otra teoría es que las capacidades léxicas que perduran en las
    personas con dislexia profunda están mediadas por la actividad del
    hemisferio derecho. Este punto de vista se apoya en el extraordinario
    caso clínico que se expone a continuación.
  </li>
</ol>
<p>En un intento de aliviar sus síntomas, se le practicó una
  hemisferectomía total; es decir, se le extirpó completamente el
  hemisferio izquierdo. Esta cirugía detuvo totalmente sus crisis.</p>
<p>La capacidad de lectura de N. I. es deficiente, pero presenta un
  perfil de capacidades preservadas sorprendentemente similar al de
  quienes padecen dislexia profunda o los pacientes con cerebro escindido
  que leen con su hemisferio derecho. Por ejemplo, reconoce las letras
  pero es totalmente incapaz de traducirlos a sonidos; puede leer palabras
  conocidas concretas; no puede pronunciar siquiera palabras sencillas sin
  sentido (p.ej., neg); y sus errores de lectura indican que está leyendo
  basándose en el significado y la configuración de las palabras más que
  traduciéndolas en sonidos (p.ej., cuando se le presenta las palabra
  fruta, responde: «jugo… esto es manzanas y peras y… fruta». En otras
  palabras, presenta un caso grave de dislexia profunda (Paterson,
  Vargha-Kadem y Polkey, 1989).</p>
<h1>Biopsicología
  de la emoción, el estrés y la salud</h1>
<p>Para solucionar este problema Lykken (1959) creó la técnica del
  conocimiento de la culpabilidad. Para utilizar esta técnica debe haber
  una información específica relacionada con el delito que solamente sepa
  la persona culpable. En lugar de tratar de sorprender al sospechoso
  mintiendo, el evaluador simplemente comprueba la reacción del sospechoso
  ante una lista de detalles reales e inventados del delito. Las personas
  inocentes, puesto que no saben nada del delito, reaccionan ante todos
  los detalles de la misma forma mientras que el culpable reacciona
  diferencialmente. En un estudio sobre la técnica del conocimiento de la
  culpabilidad (Lykken, 1959), los sujetos esperaban hasta que la ocupante
  de un despacho se fuera al servicio. Entonces, entraban en su despacho,
  robaban el bolso que tenía encima de la mesa, le quitaban el dinero y
  dejaban el bolso en un armario. La parte crítica del interrogatorio fue
  algo así: «¿Dónde cree que encontramos el bolso?… ¿en el servicio?… ¿en
  un armario?… ¿colgando de un perchero?…» A pesar de que la única medida
  de actividad del sistema neurovegetativo que se utilizó en este estudio
  fue la actividad electrodérmica, se identificó correctamente al 88% de
  los delincuentes simulados y, lo que es más importante, ninguna de las
  personas inocentes fue juzgada como culpable.</p>
<h2>Expresiones faciales
  primarias</h2>
<p>Ekman y Friesen llegaron a la conclusión de que la expresión facial
  de las seis emociones que figuran a continuación son primarias:
  sorpresa, enfado, tristeza, asco, miedo y felicidad. Asimismo, llegaron
  a la conclusión de que todas las demás expresiones faciales de otras
  emociones genuinas se componen de mezclas predecibles de las seis
  primarias. En la Figura 17.5, el propio Ekman ilustra las seis
  expresiones faciales primarias y su combinación para formar una
  expresión no primaria.</p>
<p>Hay dos formas de distinguir las emociones verdaderas de las falsas
  (Ekman, 1985).</p>
<ol>
  <li>En primer lugar, hay microexpresiones (expresiones faciales breves)
    de la emoción real que a menudo se manifiestan a la vez que la expresión
    falsa. Estas microexpresiones duran sólo alrededor de 0,05 segundos,
    pero con práctica pueden detectarse sin ayuda de la fotografía a cámara
    lenta.
  </li>
  <li>En segundo lugar, a menudo existen diferencias sutiles entre las
    expresiones faciales genuinas y las falsas, que un observador con
    pericia puede detectar.
  </li>
</ol>
<p>Dimberg, Thunberg y Elmehed (2000) realizaron un estudio en el que
  analizaron el efecto que tenía la visión de expresiones faciales sobre
  los músculos faciales del observador. Los investigadores hallaron que la
  gente tendía a imitar las expresiones faciales que observaban en los
  demás, incluso sin ser conscientes de lo que están viendo. Los
  investigadores presentaban caras de felicidad o de enfado durante 30
  milisegundos e inmediatamente las reemplazaban, en ambos casos, con una
  expresión neutra. Ninguno de los participantes dijo ser consciente de
  las expresiones emocionales presentadas brevemente, tan solo eran
  conscientes de las expresiones neutras. De este modo, el EMG facial
  mostró que aquellos a los que se les habían presentado caras de
  felicidad realizaron sutiles caras de felicidad, mientras que aquellos a
  los que se les habían presentado caras de enfado realizaron caras de
  enfado sutiles.</p>
<h2>Hipótesis de la
  retroalimentación facial</h2>
<p>¿Hay algo de cierto en la típica idea de que poner cara de felicidad
  puede hacer que uno se sienta mejor? La investigación indica que sí
  (véase Adelmann y Zajonc, 1989). La hipótesis de que las expresiones
  faciales influyen en la experiencia emocional se denomina hipótesis de
  la retroalimentación facial.</p>
<h2>Miedo, defensa y agresión</h2>
<p>El análisis de las conductas agresivas y defensivas ha llevado a la
  creación del concepto de zona objetivo —la idea de que las conductas
  agresivas y defensivas de un animal a menudo están diseñadas para atacar
  lugares concretos del cuerpo de otro animal, mientras se protegen
  lugares concretos del propio—. Por ejemplo, la conducta de una rata
  socialmente agresiva (por ejemplo, el ataque lateral) parece estar
  planeada para morder el lomo de la rata que se defiende y proteger la
  cara propia, objetivo probable de un ataque defensivo. Por el contrario,
  la mayoría de las maniobras de la rata que se defiende (por ejemplo, el
  boxeo) parecen estar diseñadas para proteger la zona objetivo de su
  lomo.</p>
<p>El descubrimiento de que las conductas agresivas y defensivas se
  producen de diversas formas estereotipadas comunes a una especie fue el
  primer paso necesario para la identificación de sus bases neurales.</p>
<h2>Agresión y testosterona</h2>
<p>El hecho de que la agresividad social en muchas especies se produzca
  con más frecuencia entre machos que entre hembras suele explicarse
  haciendo referencia a los efectos organizadores y activadores de la
  testosterona. Se piensa que el breve período de liberación de
  testosterona que tiene lugar en torno al nacimiento en machos genéticos
  organiza su sistema nervioso de forma masculina y, por tanto, crea la
  posibilidad de que se activen características masculinas de agresividad
  social, debido a los elevados niveles de testosterona que están
  presentes tras la pubertad. Estos efectos organizadores y activadores se
  han demostrado en muchas especies de mamíferos no primates. Por ejemplo,
  la castración neonatal de ratones macho suprime la capacidad que tienen
  las inyecciones de testosterona de provocar agresividad social durante
  la vida adulta, y la castración adulta suprime la agresividad social en
  machos que no reciben inyecciones sustitutivas de testosterona.</p>
<p>A diferencia de la investigación con no primates, los intentos de
  mostrar los efectos organizadores y activadores de la testosterona en la
  conducta agresiva de los seres humanos han sido contradictorios. En los
  varones, la conducta agresiva no aumenta en la pubertad a medida que
  aumentan los niveles de testosterona; no se elimina con la castración; y
  no se aumenta con inyecciones de testosterona que eleven la testosterona
  en sangre a niveles altos, aunque normales. No obstante, en algunos
  estudios se ha hallado que hombres delincuentes y violentos, y atletas
  varones agresivos tienden a tener niveles de testosterona ligeramente
  superiores a los normales (véase Bernhardt, 1997). Esta débil
  correlación podría reflejar que los choques agresivos aumentan la
  testosterona, en lugar de lo contrario (véase Archer, 1991).</p>
<p>El hecho de que la agresividad humana sea independiente de la
  testosterona podría significar que su regulación hormonal y neural se
  diferencia de la regulación en especies de mamíferos no primates. Sin
  embargo, Albert, Walsh y Jonik (1993) piensan que los datos favorecen
  una conclusión diferente. Defienden que se ha llegado a esta confusión
  porque los investigadores que estudian la agresividad humana a menudo no
  ven la diferencia entre la agresividad social, que está relacionada con
  los niveles de testosterona en muchas especies, y la agresividad
  defensiva, que no lo está. La mayoría de los arrebatos de agresividad en
  humanos son reacciones desmedidas a una amenaza real o percibida, y, por
  tanto, es más adecuado considerarlos como ataques defensivos que como
  agresión social. Por consiguiente, la incapacidad de encontrar
  correlaciones positivas entre la conducta agresiva humana y los niveles
  de testosterona es coherente con la incapacidad de encontrar
  correlaciones positivas entre el ataque defensivo y los niveles de
  testosterona en otras especies.</p>
<h2>Estrés y salud</h2>
<p>Selye atribuyó la respuesta al estrés a la activación del sistema
  hipofisario-suprarrenal (hipófisis anterior-corteza suprarrenal). Llegó
  a la conclusión de que los estímulos estresantes que actúan sobre los
  circuitos neurales estimulan la liberación de corticotropina
  (adrenocorticotropic hormone o ACTH) desde la hipófisis anterior; que la
  ACTH provoca a su vez la liberación de glucocorticoides por la corteza
  suprarrenal; y que los glucocorticoides producen muchos de los efectos
  de la respuesta al estrés (véase Erickson, Drevets y Schulkin, 2003;
  Korte, 2001). La medida fisiológica de estrés empleada con más
  frecuencia es el nivel de glucocorticoides.</p>
<p>Al
  hacer tanto hincapié en la función del sistema hipofisario-suprarrenal
  en el estrés, Selye ignoró en gran medida la implicación del sistema
  nervioso simpático. Los estímulos estresantes también activan el sistema
  nervioso simpático, lo cual da lugar a un aumento en la liberación de
  adrenalina y noradrenalina por la médula suprarrenal. Las teorías más
  modernas del estrés (véase Stanford y Salmon, 1993) reconocen el papel
  fundamental de ambos sistemas (véase la Figura 17.8).</p>
<p>Desde la perspectiva de la ciencia psicológica, la contribución
  fundamental del descubrimiento de Selye de la respuesta al estrés fue
  que ofreció un mecanismo por el cual los factores psicológicos pueden
  influir en la enfermedad física. Todos los estímulos estresantes
  psicológicos habituales (por ejemplo, perder el trabajo, preparar un
  examen, acabar una relación) se relacionan con niveles elevados de
  glucocorticoides, adrenalina y noradrenalina; éstos, a su vez,
  intervienen en muchas enfermedades físicas (Salovey et al., 2000). Por
  ejemplo, el miedo o estrés previo a una intervención quirúrgica se ha
  relacionado con una recuperación posquirúrgica más lenta, incluidos
  retrasos en la curación de las heridas (Kiecolt-Glaser et al.,
  1998).</p>
<p>La relación entre el miedo crónico, el estrés y la enfermedad es
  fácilmente observable e n animales bajo estrés por subordinación.
  Aparentemente todos los mamíferos, en especial particular los machos,
  experimentan miedo de sus congéneres (miembros de la misma especie) en
  determinados momentos de la vida. Cuando la amenaza de los congéneres se
  convierte en un hecho cotidiano de la vida diaria, el resultado es el
  estrés por subordinación. El estrés por subordinación se estudia más
  fácilmente en especies sociales que forman jerarquías de dominancia
  estables (órdenes a picotazos). ¿Qué cree que les ocurre a los roedores
  subordinados machos que son atacados continuamente por machos más
  dominantes? Muchos estudios (véase Blanchard et al., 1993; Delvile,
  Melloni y Ferris, 1998) han mostrado que los animales expuestos a estrés
  por subordinación es más probable que ataquen a los jóvenes, que tengan
  los testículos más pequeños, que tengan un ciclo vital más corto y que
  tengan bajos niveles de testosterona y elevados de corticosterona (un
  glucocorticoide).</p>
<p>Con el descubrimiento de que el estrés puede reducir la resistencia
  de una persona a las infecciones, se produjo un avance fundamental en el
  estudio del estrés y la salud. Este hallazgo tuvo una gran repercusión
  en el campo de la psicología, debido a que mostró que el estrés podía
  desempeñar un papel en las enfermedades infecciosas, que hasta ese
  momento se habían considerado «estrictamente físicas».</p>
<p>Segerstrom y Miller hallaron que los efectos el estrés sobre la
  función inmunitaria dependía del tipo de estrés. Así, encontraron que
  estímulos estresantes agudos o breves (por ejemplo, aquellos que duran
  menos de 100 minutos, como hablar en público, competiciones de atletismo
  o conciertos de música) realmente producían mejoras en la función
  inmunitaria. Como es lógico, las mejoras en la función inmunitaria a
  raíz del estrés agudo se daban principalmente en barreras no
  específicas, las cuales pueden formarse rápidamente. Por el contrario,
  los estímulos estresantes crónicos (aquellos que duran mucho tiempo),
  como cuidar de un familiar con demencia, ser discapacitado, o no tener
  empleo, alteraban de forma dramática procesos más complejos del sistema
  inmunitario.</p>
<p>Tomados en conjunto, los estudios correlacionales en seres humanos y
  los experimentos en animales de laboratorio han proporcionado un fuerte
  apoyo a los principios básicos de la psiconeuroinmunología.</p>
<h2>Experiencia temprana de
  estrés</h2>
<p>Puesto que en algunos casos la exposición temprana al estrés aumenta
  la intensidad de las subsiguientes respuestas de estrés (por ejemplo,
  aumento de la secreción de glucocorticoides en respuesta a estímulos
  estresantes), dicha exposición suele también amplificar los efectos
  adversos de los subsiguientes estímulos estresantes. Es importante
  entender que el plazo del desarrollo durante el cual el estrés temprano
  puede afectar de forma crítica el desarrollo neural y endocrino comienza
  antes del nacimiento. Muchos experimentos han demostrado los efectos
  adversos del estrés prenatal en animales de laboratorio. En estos
  experimentos sobre estrés prenatal se expone a las hembras preñadas a
  estímulos estresantes y a continuación se evalúan los efectos adversos a
  dicha exposición que aparecen en su prole (véase Avishai-Eliner et al.,
  2002; Kofman, 2002; Maccari et al., 2003).</p>
<p>Liou y colaboradores (1997) hallaron que las madres de crías de rata
  manipuladas las acicalan más (mediante lamidos) e hipotetizaron que los
  efectos saludables de la manipulación temprana podrían resultar del
  acicalamiento extra, más que de la manipulación por sí misma.
  Confirmaron esta hipótesis mostrando que las crías que no habían sido
  manipuladas pero que recibían mucho acicalamiento de sus madres
  desarrollaban el mismo patrón de incrementos de secreción de
  glucocorticoides que se podía observar en las crías manipuladas. La
  disminución de los niveles de glucocorticoides parece ser una
  consecuencia del aumento de la retroalimentación negativa resultante del
  aumento en el número de receptores de glucocorticoides en el
  hipocampo.</p>
<p>En general, la separación temprana de las crías de rata de sus madres
  parece que tiene efectos opuestos a los altos niveles de acicalamiento
  temprano (vease Cirulli, Berry y Alleva, 2003; Pryce y Feldon, 2003;
  Rhees, Lephart y Eliason, 2001). Aquellas ratas a las que se separa de
  sus madres durante la infancia, desarrollan cuando son adultas
  incrementos en las respuestas comportamentales y hormonales al
  estrés.</p>
<p>Aquellas ratas madres que son más reactivas al estrés proporcionan un
  peor cuidado maternal a su prole. Este pobre cuidado tiene efectos
  adversos duraderos en las respuestas de estrés de la prole (Meaney,
  2001). Piénsese en el significado de esta secuencia de eventos:
  constituye un mecanismo no genético por el cual tendencias
  comportamentales se pueden transmitir de generación en generación.</p>
<h2>Estrés e hipocampo</h2>
<p>El estudio de los efectos del estrés sobre el hipocampo es de gran
  relevancia dada su posible implicación en los problemas psiquiátricos
  relacionados con el estrés. Así, son de destacar cinco importantes
  hallazgos.</p>
<ol>
  <li>Primero, que los efectos del estrés sobre el hipocampo parecen estar
    mediados por incrementos, inducidos por el estrés, en la secreción de
    corticoesteroides –estos efectos pueden bloquearse mediante la
    extirpación de la corteza suprarrenal (Tanapat et al., 2001) y se pueden
    producir mediante inyecciones de corticoestroides (McEwen, 2000a).
  </li>
  <li>Segundo, que incluso periodos de estrés que duren unas pocas horas
    pueden producir cambios estructurales en el hipocampo que duren meses, o
    más (Kim y Diamond, 2000).
  </li>
  <li>Tercero, que los estímulos estresantes naturales (por ejemplo, el
    miedo hacia un coespecífico dominante o un depredador) tienden a
    producir más patologías en el hipocampo que los estímulos estresantes
    artificiales (por ejemplo, la contención física).
  </li>
  <li>Cuarto, que los efectos del estrés sobre el hipocampo son lo
    suficientemente potentes como para producir cambios en la conducta
    mediada por la actividad del hipocampo (por ejemplo, el rendimiento en
    un laberinto radial).
  </li>
  <li>Y quinto, que los efectos del estrés sobre el hipocampo tienden a
    ser mayores en los machos. Falconer y Galea (2003) hallaron que en las
    ratas macho se producían efectos inducidos por el estrés sobre la
    neurogénesis del hipocampo mientras que en las hembras esto no ocurría
    —la explicación a estas diferencias de género puede hallarse en que el
    estradiol interviene en la neurogénesis en adultos (Ormerod y Galea,
    2001) y en la recuperación del daños cerebral (Garcia-Segura, Azcoitia y
    DonCarlos, 2001)—.
  </li>
</ol>
<h2>Miedo condicionado</h2>
<p>El miedo condicionado consiste en la formación de una respuesta de
  miedo ante un estímulo que previamente era neutro (el estímulo
  condicional) presentándolo, convencionalmente en varias ocasiones, antes
  de la administración de un estímulo aversivo (el estímulo
  incondicional). El miedo condicionado ha sido el método preferido para
  estudiar el miedo porque con este método la fuente de miedo nunca es
  ambigua (el estímulo incondicional) y porque la respuesta de miedo se
  puede estudiar sistemáticamente (véase Maren, 2001).</p>
<p>Las lesiones de la amígdala, como las lesiones del núcleo geniculado
  medial, impiden el miedo condicionado. La amígdala recibe entradas de
  todos los sistemas sensoriales, y se piensa que es la estructura donde
  se aprende y se mantiene el significado emocional de las señales
  sensoriales.</p>
<p>Existen varias vías que transmiten señales de la amígdala a las
  estructuras que controlan las diversas respuestas emocionales. Por
  ejemplo, una vía que va a la sustancia gris periacueductal del encéfalo
  medio provoca respuestas defensivas (véase Bandler y Shipley, 1994),
  mientras que otra vía que va al hipotálamo lateral provoca respuestas
  simpáticas.</p>
<p>El hecho de que las lesiones de la corteza auditiva no alteren el
  miedo condicionado a tonos simples no significa que la corteza auditiva
  no intervenga en el condicionamiento auditivo del miedo. Existen dos
  vías que van del núcleo geniculado medial a la amígdala: una directa,
  que ya hemos visto, y una indirecta, que se proyecta a través de la
  corteza auditiva (Romanski y LeDoux, 1992). Ambas vías pueden mediar el miedo condicionado
  o a sonidos simples; si se destruye solamente una de ellas, el
  condicionamiento se produce de modo normal. Sin embargo, solamente la
  vía cortical es capaz de mediar el condicionamiento de miedo a sonidos
  complejos (Jarrell et al., 1987).</p>
<p>Probablemente el apartado previo haya dejado al lector con la
  impresión de que la amígdala es una estructura cerebral unitaria, pero
  no es así. De hecho es un grupo de muchos núcleos, al que normalmente se
  designa como complejo amigdalino. La amígdala está compuesta por una
  docena o más de regiones, que a su vez se dividen en subregiones. Cada
  una de estas subregiones es estructuralmente distinta de las otras y
  tiene diferentes conexiones. Para hacer las cosas aún más difíciles, se
  puede decir que la anatomía de la amígdala es tan compleja que no existe
  consenso para su división en componentes (véase LeDoux, 2000b).</p>
<p>Los ambientes, o contextos, en los que se encuentran los estímulos
  que producen miedo pueden llegar a inducir miedo por sí mismo. Por
  ejemplo, si uno se encuentra un oso repetidas veces en un camino
  específico del bosque, el camino por sí mismo le dará a uno miedo. El
  proceso mediante el cual contextos benignos llegan a producir miedo
  mediante su asociación a estímulos inductores de miedo se denomina
  <strong>miedo condicionado contextual.</strong></p>
<p>Si asumimos que el hipocampo desempeña un papel fundamental en los
  procesos de memoria para la localización espacial, es razonable pensar
  que puede estar implicado en el miedo condicionado contextual; y este
  parece ser el caso (véase Antoniadis y McDonald, 2000). Existen dos
  tipos de estudios mediante lesión cerebral en los que se implica al
  hipocampo en el miedo condicionado contextual.</p>
<ol>
  <li>En el primero, la lesión bilateral del hipocampo previa al
    condicionamiento bloquea el desarrollo de la respuesta de miedo al
    contexto sin bloquear el desarrollo de la respuesta de miedo al estímulo
    condicional explícito (por ejemplo, un tono).
  </li>
  <li>En el segundo, la lesión bilateral del hipocampo realizada poco
    después del condicionamiento bloquea el recuerdo de la respuesta de
    miedo al contexto sin modificar el recuerdo de la respuesta de miedo al
    estímulo condicional explícito.
  </li>
</ol>
<h2>Mecanismos
  cerebrales de la emoción en seres humanos</h2>
<p>Aunque las investigaciones recientes se han centrado en el papel que
  desempeña la amígdala en el reconocimiento de expresiones faciales
  negativas, los sujetos con lesión bilateral de la amígdala también
  presentan dificultades a la hora de reconocer una serie de estímulos
  (p.ej., dibujos, paisajes); en especial, aquellos estímulos que los
  sujetos dicen que les gustan menos (Adolphs y Tranel, 1999). También hay
  pruebas de que la amígdala participa en las emociones positivas (véase
  Hamann et al., 2002); varios experimentos realizados en animales no
  humanos sugieren que la amígdala interviene en el aprendizaje del valor
  provechoso de los estímulos y en la expresión de emociones positivas
  asociadas con tales juicios (Baxter y Murray, 2002).</p>
<p>Las investigaciones acerca de la corteza prefrontal también han
  aportado datos empíricos acerca de la implicación de estructuras
  cerebrales específicas en determinadas emociones. Por ejemplo, Northoff
  y sus colaboradores (2000) hallaron que la región medial y lateral de la
  corteza prefrontal responden de forma distinta a fotos diseñadas para
  provocar emociones diferentes. Los estudios con RM funcional indican que
  las emociones negativas producen una elevada activación de la corteza
  prefrontal medial, mientras que las emociones positivas producen una
  elevada activación de la corteza prefrontal lateral.</p>
<h2>El
  hemisferio derecho está más implicado que el izquierdo en la emoción
  humana</h2>
<p>La investigación del daño cerebral neuropsicológico permite estudiar
  la lateralización cerebral de la emoción en los seres humanos, como
  también lo hace la neuroimagen funcional de todo el encéfalo. Ambos
  tipos de investigación han encontrado como tendencia general una
  implicación en la emoción de las estructuras del hemisferio cerebral
  derecho mayor que la del izquierdo. Sin embargo, si existe o no una
  dominancia del hemisferio derecho dependerá de las estructuras que se
  consideren y de los aspectos específicos de la emoción en estudio.</p>
<p>Considérense las siguientes líneas de investigación. Hay muchos
  informes sobre la dominancia del hemisferio derecho en la percepción de
  la emoción —tanto mediante la expresión facial como mediante la prosodia
  (tono emocional de la voz)—. Sin embargo, esto no significa que el
  hemisferio izquierdo no desempeñe ningún papel en la emoción o que todas
  las estructuras del hemisferio derecho desempeñen un mayor papel que sus
  equivalentes del hemisferio izquierdo. Por ejemplo, Kolb y Taylor (1998)
  hallaron que la percepción de la emoción mediante expresiones faciales
  se veía dificultada por lesiones temporales derechas, pero no por
  lesiones temporales izquierdas; mientras que las lesiones frontales
  derechas e izquierdas producían dificultades equivalentes (véase la
  Figura 17.12). Asimismo parece que no existen diferencias en la
  contribución de la amígdala derecha e izquierda en el reconocimiento de
  expresiones faciales de miedo (Anderson y Phelps, 2002; Zald, 2003). El
  estudio de la lateralización en la producción de expresiones emocionales
  nos aporta una historia igualmente compleja: si existe o no una
  dominancia del hemisferio derecho dependerá de la parte del hemisferio
  que se haya considerado.</p>
<p>Por ejemplo, aunque hay una dominancia general del hemisferio derecho
  en la producción de expresiones faciales emocionales, se ha hallado que
  las lesiones frontales derechas e izquierdas tienen un efecto
  equivalente sobre las dificultades para dichas expresiones (Kolb y
  Taylor, 2000).</p>
<h2>Diferencias
  individuales en los mecanismos neurales de la emoción</h2>
<p>A diferencia de aquellas zonas del cerebro que desempeñan
  fundamentalmente papeles sensoriales y motores, las zonas que están
  involucradas en la emoción parecen variar sustancialmente de unas a
  otras personas. Esto hace que la búsqueda de los mecanismos neurales de
  la emoción sea muy complicada. Consideremos dos líneas de investigación
  y un estudio de caso que ilustran las diferencias individuales en la
  organización de los mecanismos neurales de la emoción.</p>
<ol>
  <li>En primer lugar, Adolphs y su colaboradores (1999) examinaron la
    capacidad de nueve pacientes neuropsicológicos con lesión bilateral de
    la amígdala para identificar correctamente las expresiones faciales de
    la emoción. Como han señalado otros investigadores, estos autores
    hallaron que, tomado en conjunto, el grupo de pacientes presentaba
    dificultades en la identificación de expresiones faciales de miedo. Sin
    embargo, se encontraron diferencias significativas entre los sujetos:
    algunos también presentaban dificultades a la hora de identificar otras
    emociones negativas, pero dos no mostraron en absoluto ninguna
    dificultad para identificar expresiones faciales. Además las imágenes de
    RM estructural revelaron que estos dos sujetos tenían una lesión total y
    bilateral de la amígdala. Estudios posteriores de estos dos sujetos
    mostraron que, además de no tener dificultades a la hora de identificar
    expresiones faciales de la emoción, tampoco tenían dificultades a la
    hora de juzgar la similitud entre pares de expresiones emocionales
    (Hamann y Adolphs, 1999).
  </li>
  <li>En segundo lugar, Canli y sus colaboradores (2001) utilizaron RM
    funcional para comparar las reacciones de sujetos sanos con altas
    puntuaciones en extraversión y sujetos sanos con altas puntuaciones en
    neuroticismo. Estas dos dimensiones de la personalidad se seleccionaron
    por su estrecha relación con la emoción —las personas con altas
    puntuaciones en la escala de extraversión tienden a tener reacciones
    emocionales positivas; las personas con altas puntuaciones en la escala
    de neuroticismo tienden a tener reacciones emocionales negativas—. Así,
    hallaron que la reactividad de varias zonas del cerebro a imágenes
    placenteras estaba correlacionada con el grado de extraversión; y que la
    reactividad a imágenes negativas se relacionaba con el grado de
    neuroticismo. En particular, aunque todos los sujetos presentaron un
    aumento de actividad en la amígdala cuando vieron caras atemorizadas,
    sólo los extravertidos presentaron un aumento de la actividad en la
    amígdala cuando vieron caras de felicidad (Canli et al., 2002). El
    hallazgo de que el cerebro de personas con distintas personalidades
    reacciona de forma diferente a los estímulos emocionales sugiere que los
    esfuerzos por identificar las reacciones cerebrales a los estímulos
    emocionales deben considerar las diferencias individuales de los
    sujetos.
  </li>
</ol>
<h1>Biopsicología de
  los trastornos psiquiátricos</h1>
<h2>Esquizofrenia</h2>
<p>El punto de vista actual es que algunas personas heredan la
  posibilidad de desarrollar la esquizofrenia, que puede activarse por la
  experiencia. En apoyo a esta idea hay una comparación reciente de los
  hijos de una muestra grande de gemelos univitelinos discordantes para la
  esquizofrenia (es decir, uno padecía el trastorno y el otro no): la
  incidencia de la esquizofrenia era tan grande en los hijos de los
  gemelos sin esquizofrenia como en los hijos de los gemelos con
  esquizofrenia (Gottesman y Bertelsen, 1989).</p>
<p>Está claro que la esquizofrenia tiene múltiples causas. Se ha
  demostrado que varias regiones de diferentes cromosomas están implicadas
  en la vulnerabilidad a la esquizofrenia (véase Cowan, Kopnisky y Hyman,
  2002; Kennedy et al., 2003; Torrey y Yoken, 2000). Además, se ha
  mostrado que una serie de factores de la experiencia están implicados en
  la evolución de la esquizofrenia —p.ej., infecciones tempranas,
  reacciones autoinmunitarias, toxinas, lesiones traumáticas y estrés. Se
  piensa que estas experiencias tempranas alteran el curso normal del
  desarrollo neural, desembocando en esquizofrenia en personas con
  predisposición genética (véase Conklin y Iacono, 2002; Lewis y Levitt,
  2002)</p>
<p>Una solución al enigma del haloperidol llegó con el descubrimiento de
  que la dopamina se une a más de un subtipo de receptor —en la actualidad
  se han identificado cinco— (Hartmann y Civelli, 1997). Resultó que la
  clorpromacina y los otros fármacos antipsicóticos de la misma categoría
  química (las fenotiacinas) se unían de forma efectiva con los receptores
  D1 y D2, mientras que el haloperidol y otros fármacos antipsicóticos de
  su categoría química (las butirofenonas) se unían de forma efectiva a
  los receptores D2, pero no a los receptores D1.</p>
<p>Este descubrimiento de la unión selectiva de las butirofenonas a los
  receptores D2 llevó a una revisión substancial de la teoría
  dopaminérgica de la esquizofrenia. Sugería que la esquizofrenia se debe
  a una hiperactividad específicamente en los receptores D2, más que en
  los receptores dopaminérgicos en general. Snyder y colaboradores (véase
  Snyder, 1978) confirmaron posteriormente que el grado en que los
  neurolépticos —fármacos antipsicóticos— se unen a los receptores D2 se
  relaciona estrechamente con su eficacia para suprimir los síntomas
  esquizofrénicos (véase la Figura 18.2). Por ejemplo, la butiferona
  espiroperidol tenía la mayor afinidad por los receptores D2 y el efecto
  antipsicótico más potente.</p>
<p>Si bien los datos apoyan de manera firme la intervención de los
  receptores D2 en la esquizofrenia, la teoría dopaminérgica, tal como
  está planteada actualmente implicando a los receptores D2, no permite
  explicar varios hallazgos clave. La apreciación de estas limitaciones ha
  llevado a la versión actual de dicha teoría. Ésta mantiene que la
  actividad excesiva en los receptores D2 está implicada en la
  esquizofrenia, pero que existen otros factores causales no identificados
  todavía. Los acontecimientos más importantes en la evolución de la
  teoría dopaminérgica se presentan en la Tabla 18.1.</p>
<h3>Otros
  receptores distintos de los receptores D2 están implicados en la
  esquizofrenia</h3>
<p>La investigación actual ha señalado la implicación en la
  esquizofrenia de otros neurotransmisores distintos de la dopamina (véase
  Tallman, 2000). Éstos incluyen al glutamato (Javitt y Coyle, 2004;
  Konradi y Heckers, 2003; Moghaddam, 2003), el GABA (Benes y Berretta,
  2001) y la serotonina (Sawa y Snyder, 2002). La puesta a punto de
  neurolépticos atípicos (fármacos antiesquizofrénicos que no son
  básicamente bloqueantes de los receptores D2) ha sido la prueba más
  convincente de que los receptores D2 no son el único mecanismo que
  subyace a la esquizofrenia. Por ejemplo, la clozapina —que es el
  neuroléptico atípico más eficaz en el tratamiento de la esquizofrenia—,
  tiene afinidad por los receptores D1, D4 y varios receptores
  serotoninérgicos; pero sólo una ligera afinidad por los receptores
  D2.</p>
<p>La efectividad de la clozapina y de otros neurolépticos atípicos
  sugiere, por lo tanto, que los receptores D2 no son los únicos
  receptores que intervienen en la esquizofrenia; la clozapina tiene una
  gran afinidad por los receptores D1, los receptores D4 y diversos
  receptores serotoninérgicos.</p>
<h3>El
  tratamiento con neurolépticos tarda varias semanas en aliviar los
  síntomas de esquizofrenia</h3>
<p>Como ese ha visto, el tratamiento con neurolépticos tarda varias
  semanas en aliviar los síntomas de la esquizofrenia. No obstante, los
  neurolépticos bloquean de forma efectiva la actividad de los receptores
  D2 en unas horas. Este lapso de tiempo indica que el bloqueo de los
  receptores D2 no es el mecanismo específico por el cual tiene efecto el
  tratamiento con neurolépticos. Parece que el bloqueo de los receptores
  D2 desencadena algún tipo de cambio lento y compensatorio en el cerebro
  que sería el factor clave de su efecto terapéutico. Una teoría reciente
  sostiene que el cambio lento y crítico es el bloqueo de la
  despolarización de las células dopaminérgicas (Grace et al., 1997).
  Inicialmente los neurolépticos incrementan el disparo de las neuronas
  dopaminérgicas, pero al final, cerca del momento en que se manifiestan
  los efectos terapéuticos, se produce una disminución general de su
  frecuencia de disparo. Este descenso es el bloqueo de la despolarización
  de las células dopaminérgicas.</p>
<h3>La
  esquizofrenia se asocia con un daño cerebral difuso</h3>
<p>Una pregunta fundamental sobre la patología cerebral en la
  esquizofrenia es si consiste en un trastorno evolutivo o no: ¿Se
  desarrollan anormalmente los cerebros de las personas con esquizofrenia,
  o se desarrollan normalmente y luego sufren algún tipo de daño? Un
  hallazgo importante sugiere que la esquizofrenia se debe a una
  alteración temprana del desarrollo cerebral: la patología cerebral que
  se asocia con la esquizofrenia suele ser extensa cuando la enfermedad se
  diagnostica por primera vez, y hay pocas pruebas de que se dé una lesión
  posterior (véase Wong, Buckle y Van Tol, 2000).</p>
<p>Varios estudios han sugerido que la lateralización cerebral no se
  desarrolla de forma normal en las personas con esquizofrenia (Rockstroh
  et al., 1998; Shapleske et al., 2001). De nuevo, la teoría dopaminérgica
  no proporciona una explicación para este efecto.</p>
<h3>Los
  neurolépticos sólo ayudan a algunos pacientes con esquizofrenia</h3>
<p>Los neurolépticos típicos (p.ej., los bloqueantes del receptor D2)
  no ayudan a todas las personas con esquizofrenia (véase Wong y Van Tol,
  2003): aproximadamente al 30% no le ayudan en absoluto, y al porcentaje
  restante sólo le mejoran algunos síntomas. En general, los neurolépticos
  son más eficaces para el tratamiento de los síntomas esquizofrénicos
  positivos (como la incoherencia, las alucinaciones y los delirios), los
  cuales se supone están provocados por un aumento de la actividad neural,
  que para el tratamiento de los síntomas esquizofrénicos negativos (como
  el embotamiento afectivo y la pobreza expresiva), los cuales se supone
  están provocados por una disminución de la actividad neural. Muchos
  pacientes a los que el tratamiento con neurolépticos les ayuda
  inicialmente desarrollan una rápida tolerancia al efecto terapéutico y
  recaen.</p>
<p>La cuestión es que si la esquizofrenia fuese resultado de una
  actividad excesiva en los receptores D2, entonces los bloqueantes de
  esos receptores deberían aliviar todos los síntomas en todas las
  personas con esquizofrenia. El hecho de que estos fármacos no hagan
  esto, supone un desafío a la estricta interpretación de la versión D2 de
  la teoría dopaminérgica de la esquizofrenia.</p>
<p>El hecho de que los neurolépticos sólo ayuden a algunos pacientes
  sugiere que el diagnóstico de esquizofrenia actualmente incluye a
  personas con distintos trastornos. De hecho, muchos investigadores de
  este campo prefieren utilizar el término «las esquizofrenias» para
  reconocer que la categoría diagnóstica actual sin ninguna duda incluye
  varios trastornos relacionados. Hasta que no se solucione este problema
  diagnóstico, será difícil desarrollar una teoría explicativa más
  adecuada y unos tratamientos más eficaces para quienes han sido
  diagnosticados de esquizofrenia.</p>
<h2>Trastornos afectivos:
  depresión y manía</h2>
<p>La depresión no es el único trastorno afectivo (trastorno psicótico
  de la emoción). El otro tipo principal es la manía, que en muchos
  aspectos es lo contrario a la depresión. La manía es un trastorno
  afectivo caracterizado por una elevada confianza en sí mismo,
  impulsividad, falta de atención y alto nivel de energía.</p>
<p>Durante los periodos de manía leve, la persona habla bastante, se
  siente llena de energía, es impulsiva, positiva y con mucha confianza en
  sí misma. En este estado, en algunos trabajos puede resultar muy eficaz
  y puede ser muy divertido estar con ella. Pero cuando la manía es
  extrema constituye un problema clínico muy serio. La persona con manía
  exuberante suele despertarse en un estado de entusiasmo desenfrenado,
  con una verborrea incesante que le hace cambiar de tema a tema. Ninguna
  tarea les resulta difícil. Ningún objetivo es inalcanzable. Esta
  confianza en sí mismo y grandiosidad, unida a una elevada energía, falta
  de atención e impulsividad del tipo «actuar antes de pensar» llevan a
  desastres continuos. La manía deja tras de sí proyectos sin terminar,
  facturas sin pagar, y relaciones rotas.</p>
<p>La alta incidencia de los trastornos afectivos en la sociedad
  industrializada occidental está muy bien documentada. Alrededor del 6%
  de la población sufre un trastorno afectivo unipolar en algún momento de
  su vida y alrededor del 1% sufre un trastorno afectivo bipolar. El
  trastorno afectivo unipolar suele ser el doble de prevalente en las
  mujeres que en los hombres; no existen diferencias de sexo en la
  incidencia del trastorno afectivo bipolar. Además, alrededor del 10% de
  quienes sufren trastornos afectivos se suicida (véase Culbertson, 1997;
  Weissman y Olfson, 1995).</p>
<p>Se suelen utilizar cuatro tipos de fármacos para tratar los
  trastornos afectivos: los inhibidores de la monoaminoxidasa, los
  antidepresivos tricíclicos, el litio y los inhibidores selectivos de la
  recaptación de las monoaminas.</p>
<p>La extraordinaria popularidad del Prozac y otros ISRS puede
  atribuirse a dos hechos: uno, que tienen pocos efectos secundarios;
  otro, que son eficaces en un amplio abanico de trastornos psicológicos
  además de la depresión. Ya que los ISRS han demostrado su eficacia en
  trastornos que tradicionalmente pertenecían al área de la psicoterapia
  (p.ej., la falta de autoestima, el miedo al fracaso, la sensibilidad
  excesiva a la crítica y la poca capacidad para experimentar placer), han
  tenido un impacto importante en la psiquiatría y la psicología
  clínica.</p>
<p>El éxito de los ISRS sembró la semilla para la elaboración de un tipo
  de fármaco similar: los inhibidores selectivos de la recaptación de la
  noradrenalina (ISRN). Éstos (p.ej., la Reboxetina) han demostrado ser
  igual de eficaces que los ISRS en el tratamiento de la depresión.
  También son eficaces en el tratamiento de la depresión fármacos que
  bloquean la recaptación de más de un neurotransmisor monoaminérgico
  (p.ej., Wellbutrin, Effexor).</p>
<h3>Teorías sobre la depresión</h3>
<ol>
  <li><strong>Teoría monoaminérgica de la depresión</strong> : La teoría
    más aceptada de la depresión es la teoría monoaminérgica. La teoría
    monoamínérgica de la depresión sostiene que la depresión se relaciona
    con una hipoactividad de las sinapsis serotoninérgicas y
    noradrenérgicas. Se basa en el hecho de que los inhibidores de la
    monoaminoxidasa, los antidepresivos tricíclicos, los inhibidores
    selectivos de la recaptación de la serotonina y los inhibidores
    selectivos de la recaptación de la noradrenalina, son todos agonistas de
    la serotonina, de la noradrenalina o de ambas.
  </li>
  <li><strong>Modelo diátesis-estrés de la depresión</strong> : Una
    segunda teoría de la depresión es el modelo diátesis-estrés. Según el
    modelo de diátesis-estrés de la depresión (véase Nemeroff, 1998),
    algunas personas heredan la diátesis (predisposición genética) a
    desarrollar la depresión la cual no es capaz de producir por sí misma el
    trastorno. La idea central del modelo de diátesis-estrés es que si las
    personas con predisposición son expuestas al estrés en etapas tempranas
    de la vida, sus sistemas se sensibilizarán permanentemente y
    reaccionarán de forma excesiva ante estímulos estresantes el resto de su
    vida.
  </li>
</ol>
<p>El apoyo que ha recibido el modelo de diátesis–estrés de la depresión
  es indirecto: se basa en el hallazgo de que las personas con depresión
  tienden a secretar más hormonas de estrés (véase Brown, Rus y McEwen,
  1999; Holsboer, 2000; Young et al., 2000). En los sujetos con depresión
  se produce una mayor síntesis de corticoliberina
  [corticotropin-releasing hormone] por el hipotálamo, una mayor
  liberación de corticotropina [adrenocorticotropic hormone o ACTH] por la
  hipófisis anterior así como una mayor liberación de glucocorticoides por
  la corteza suprarrenal. Además, las inyecciones de dexametasona,
  glucocorticoide sintético, no reducen la liberación de glucocorticoides
  mediante retroalimentación negativa en muchos de los pacientes
  deprimidos, como lo hace en los sujetos normales.</p>
<h3>Efectos
  antidepresivos de la privación de sueño</h3>
<p>Cometeríamos una negligencia si no resaltásemos uno de los hallazgos
  más extraños en el tratamiento de la depresión: más del 50% de los
  pacientes con depresión manifiestan una mejoría espectacular tras una
  noche de privación de sueño (Dement et al., 1999). La acción
  antidepresiva de la privación de sueño no puede explicarse mediante las
  teorías actuales de la depresión. Además, este hallazgo tiene poca
  relevancia terapéutica, ya que en cuanto el paciente vuelve a su patrón
  de sueño normal, reaparece la depresión. No obstante, el estudio de cómo
  la privación de sueño reduce la depresión puede llevar a un mejor
  conocimiento de sus mecanismos neurales y a la elaboración de nuevos
  fármacos antidepresivos.</p>
<p>Patología cerebral y trastornos afectivos</p>
<p>Las personas diagnosticadas de depresión presentan lesiones en varias
  zonas del cerebro (véase Kaufman et al., 2001); pero ese daño suele
  observarse en tres áreas (véase Drevets, 2001). Dos de estas tres áreas
  son la amígdala y la corteza prefrontal, las cuales, como se aprendió en
  el Capítulo 17, desempeñan un papel fundamental en la percepción y la
  experiencia de la emoción. La tercera área abarca varios de los puntos
  terminales del sistema dopaminérgico mesotelencefálico de la dopamina,
  el cual, como se explicó en el Capítulo 15, está involucrado en la
  experiencia del placer. No es de sorprender que los pacientes con
  depresión presenten anomalías en las estructuras estriadas y límbicas
  del sistema dopaminérgico mesotelencefálico, ya que muchos de ellos
  sufren de anhedonia, la incapacidad para experimentar placer.</p>
<p>El descubrimiento de cambios estructurales en el cerebro de personas
  con un trastorno afectivo unipolar —hecho posible gracias a la
  tecnología de neuroimagen— está cambiando el punto de vista sobre dicho
  trastorno (véase Drevets, 2001). Desde hace tiempo se ha asumido que los
  trastornos afectivos se asocian con una actividad cerebral anómala sin
  que haya daño en las estructuras cerebrales. Pero, a medida que se van
  acumulando pruebas de anomalías estructurales en el cerebro de las
  personas con depresión, cada vez es más difícil mantener esta
  opinión.</p>
<h2>Trastornos de ansiedad</h2>
<p>Los trastornos de ansiedad son los trastornos psiquiátricos con mayor
  prevalencia; p.ej., en el Reino Unido una de cada cinco mujeres y uno
  de cada diez hombres toman cada año medicación ansiolítica (Dunbar,
  Perera y Jenner, 1989). Aproximadamente el veinticinco por ciento de las
  personas sufre un trastorno de ansiedad en algún momento de su vida.</p>
<p>Los cinco trastornos de ansiedad principales son: el trastorno de
  ansiedad generalizada, los trastornos fóbicos de ansiedad, los
  trastornos de pánico, los trastornos obsesivo-compulsivos y el trastorno
  por estrés postraumático.</p>
<ol>
  <li>El trastorno de ansiedad generalizada se caracteriza por respuestas
    de estrés y sensaciones extremas de ansiedad, que se producen en
    ausencia de cualquier estímulo precipitante obvio.
  </li>
  <li>Los trastornos fóbicos de ansiedad se parecen al trastorno de
    ansiedad generalizada, excepto en que están provocados por la exposición
    a objetos determinados (p.ej., aves, arañas) o situaciones (p.ej.,
    muchedumbres. oscuridad).
  </li>
  <li>Los trastornos de pánico se caracterizan por crisis de miedo extremo
    que se inician rápidamente y síntomas graves de estrés (p.ej., ahogo,
    palpitaciones del corazón, falta de aliento); a menudo forman parte de
    los trastornos de ansiedad generalizada y fóbicos, pero también se
    producen como trastornos independientes.
  </li>
  <li>Los trastornos obsesivo-compulsivos se caracterizan por pensamientos
    recurrentes, incontrolables, que producen ansiedad (obsesiones) e
    impulsos (compulsiones). Responder a estos pensamientos e impulsos
    —p.ej., lavarse compulsivamente las manos repetidamente— es un medio de
    disipar la ansiedad que se relaciona con ellos.
  </li>
  <li>El trastorno por estrés postraumático consiste en un cuadro de
    malestar psicológico persistente tras haber estado sometido a una
    situación de excesivo estrés (McNally, 2003; McNally, Bryant y Ehlers,
    2003; Newport y Nemeroff, 2000).
  </li>
</ol>
<p>El hecho de que muchos fármacos ansiolíticos sean agonistas en los
  receptores de GABAA (p.ej., las benzodiacepinas) o en los receptores de
  serotonina (p.ej., la buspirona y el Prozac) ha centrado la atención en
  el posible papel en los trastornos de ansiedad de una alteración en
  ambas transmisiones, GABAérgica y serotoninérgica.</p>
<p>Recientemente, las especulaciones sobre las estructuras encefálicas
  que intervienen en los trastornos de ansiedad se han centrado en la
  amígdala, debido al papel fundamental que desempeña en el miedo y en la
  conducta defensiva (véase LeDoux, 1995). Hay varios hechos que apoyan la
  intervención de la amígdala en los trastornos de ansiedad: la amígdala
  tiene una concentración elevada de receptores GABAA; la infusión local
  de benzodiacepinas en la amígdala produce efectos ansiolíticos en los
  animales de laboratorio; y las inyecciones locales de antagonistas del
  GABA en la amígdala pueden impedir los efectos ansiolíticos de
  inyecciones sistémicas (en la circulación general) de benzodiacepinas
  (véase Davis, Rainnie y Cassell, 1994).</p>
<h2>Síndrome de Gilles de la
  Tourette</h2>
<p>La hipótesis actual es que el síndrome de Gilles de la Tourette es un
  trastorno del desarrollo neural, resultado de una inervación
  dopaminérgica excesiva del neoestriado y las áreas de corteza límbica
  asociadas (véase Jankovic, 2001).</p>
</body>
</html>
